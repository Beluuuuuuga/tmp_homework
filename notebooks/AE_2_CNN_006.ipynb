{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "modern-database",
   "metadata": {},
   "source": [
    "# Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "harmful-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "falling-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_randvalue(value):\n",
    "    # Set a seed value\n",
    "    seed_value= value \n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "set_randvalue(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-storage",
   "metadata": {},
   "source": [
    "## Dataset preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "based-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() # load data\n",
    "x_train,x_test = x_train.astype('float32')/255.0,x_test.astype('float32')/255.0 # normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "removed-underwear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "desirable-hollow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-stocks",
   "metadata": {},
   "source": [
    "#### Limit three class preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "collective-wrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird label num is 2500\n",
      "Deer label num is 2500\n",
      "Truck label num is 2500\n",
      "Other label num is 35000\n",
      "Train label num is 42500\n",
      "(42500, 32, 32, 3)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "# No method on keras to get cifar10 category label name by categoly label?\n",
    "cifar10_labels = np.array([\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'])\n",
    "\n",
    "bird_num = np.where(cifar10_labels=='bird')\n",
    "deer_num = np.where(cifar10_labels=='deer')\n",
    "truck_num = np.where(cifar10_labels=='truck')\n",
    "\n",
    "limit_num = 2500\n",
    "\n",
    "# get limit label indexes\n",
    "bird_indexes = [i for i, label in enumerate(y_train) if label == bird_num]\n",
    "deer_indexes = [i for i, label in enumerate(y_train) if label == deer_num] \n",
    "truck_indexes = [i for i, label in enumerate(y_train) if label == truck_num] \n",
    "other_indexes = [i for i, label in enumerate(y_train) if label not in [bird_num, deer_num, truck_num]]\n",
    "\n",
    "# limit\n",
    "bird_indexes = bird_indexes[:limit_num]\n",
    "deer_indexes = deer_indexes[:limit_num]\n",
    "truck_indexes = truck_indexes[:limit_num]\n",
    "print(f'Bird label num is {len(bird_indexes)}') # 2500\n",
    "print(f'Deer label num is {len(deer_indexes)}') # 2500\n",
    "print(f'Truck label num is {len(truck_indexes)}') # 2500\n",
    "print(f'Other label num is {len(other_indexes)}') # 35000; 5000*7\n",
    "\n",
    "# merge and sort\n",
    "merge_indexes = np.concatenate([other_indexes, bird_indexes, deer_indexes, truck_indexes], 0)\n",
    "merge_indexes.sort()\n",
    "print(f'Train label num is {len(merge_indexes)}') # 42500\n",
    "\n",
    "# create three labels removed train data\n",
    "x_train_removed =  np.zeros((len(merge_indexes), 32, 32, 3))\n",
    "y_train_removed =  np.zeros(len(merge_indexes))\n",
    "\n",
    "for i, train_index in enumerate(merge_indexes):\n",
    "    x_train_removed[i] = x_train[train_index]\n",
    "    y_train_removed[i] = y_train[train_index]\n",
    "    \n",
    "print(x_train_removed.shape)\n",
    "print(y_train_removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "elegant-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42500, 32, 32, 3)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_removed.shape)\n",
    "print(y_train_removed.shape)\n",
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "shaped-summer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    5000\n",
      "1.0    5000\n",
      "3.0    5000\n",
      "5.0    5000\n",
      "6.0    5000\n",
      "7.0    5000\n",
      "8.0    5000\n",
      "2.0    2500\n",
      "4.0    2500\n",
      "9.0    2500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(y_train_removed.flatten())\n",
    "print(df.value_counts())\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "appreciated-relations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5000., 5000., 2500., 5000., 2500., 5000., 5000., 5000., 5000.,\n",
       "        2500.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot data labels\n",
    "plt.hist(y_train_removed.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-brazilian",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-accordance",
   "metadata": {},
   "source": [
    "#### Load AE models weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cloudy-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Norm Model\n",
    "def create_AE01_model(k_size):\n",
    "    input_img = Input(shape=(32, 32, 3))  # 0\n",
    "    conv1 = Conv2D(64, (k_size, k_size), padding='same', name=\"Dense_AE01_1\")(input_img) # 1\n",
    "    conv1 = BatchNormalization(name=\"BN_AE01_1\")(conv1) # 2\n",
    "    conv1 = Activation('relu', name=\"Relu_AE01_1\")(conv1) # 3\n",
    "        \n",
    "    decoded = Conv2D(3, (k_size, k_size), padding='same', name=\"Dense_AE01_2\")(conv1) # 4\n",
    "    decoded = BatchNormalization(name=\"BN_AE01_2\")(decoded) # 5\n",
    "    decoded = Activation('relu', name=\"Relu_AE01_2\")(decoded) # 6\n",
    "    return Model(input_img, decoded)\n",
    "\n",
    "class AE01():\n",
    "    def __init__(self, ksize, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.autoencoder = create_AE01_model(ksize)\n",
    "        self.encoder = None\n",
    "\n",
    "    def compile(self, optimizer='adam', loss='binary_crossentropy'):\n",
    "        self.autoencoder.compile(optimizer=self.optimizer, loss=loss)\n",
    "\n",
    "    def train(self, x_train=None, x_test=None, epochs=1, batch_size=32, shuffle=True):\n",
    "        es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "        ae_model_path = '../models/AE/AE01_AE_Best.hdf5'\n",
    "        cp_cb = ModelCheckpoint(filepath = ae_model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "       \n",
    "        history = self.autoencoder.fit(x_train, x_train,\n",
    "                             epochs=epochs,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=shuffle,\n",
    "                             callbacks=[es_cb, cp_cb],\n",
    "                             validation_data=(x_test, x_test))\n",
    "        \n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        \n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        encode_model_path = '../models/AE/AE01_Encoder_Best.hdf5'\n",
    "        self.encoder.save(encode_model_path)\n",
    "        return history\n",
    "    \n",
    "    def load_weights(self, ae_model_path, encode_model_path):\n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        self.encoder.load_weights(encode_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "consecutive-hanging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "Dense_AE01_1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "BN_AE01_1 (BatchNormalizatio (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "Relu_AE01_1 (Activation)     (None, 32, 32, 64)        0         \n",
      "=================================================================\n",
      "Total params: 2,048\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_ksize = 3\n",
    "ae_optimizer = 'rmsprop'\n",
    "stack01 = AE01(ae_ksize, ae_optimizer)\n",
    "stack01.load_weights('../models/AE/AE01_AE_Best.hdf5', '../models/AE/AE01_Encoder_Best.hdf5')\n",
    "stack01.encoder.trainable = False\n",
    "stack01.encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-empty",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-machinery",
   "metadata": {},
   "source": [
    "#### Create Model AE to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "animated-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_StackedAE01_CNN01_model(encoder):\n",
    "    input_img = encoder.input\n",
    "    output = encoder.layers[-1].output # 32,32,64\n",
    "    x = Conv2D(64,(3,3),padding = \"same\",activation= \"relu\")(output)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x) # 16,16,64\n",
    "    \n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x) # 8,8,128\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    y = Dense(10,activation = \"softmax\")(x)\n",
    "\n",
    "    return Model(input_img, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-overview",
   "metadata": {},
   "source": [
    "#### Train without data augumentation & Class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "whole-medline",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koki inoue\\anaconda3\\envs\\tf2.3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], y=[6. 9. 9. ... 0. 0. 6.] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 1.4861 - accuracy: 0.4726\n",
      "Epoch 00001: val_loss improved from inf to 1.74187, saving model to ../models/CNN\\Model_0011_1_Best.hdf5\n",
      "886/886 [==============================] - 70s 79ms/step - loss: 1.4860 - accuracy: 0.4726 - val_loss: 1.7419 - val_accuracy: 0.4277\n",
      "Epoch 2/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 1.0941 - accuracy: 0.6200\n",
      "Epoch 00002: val_loss improved from 1.74187 to 1.24031, saving model to ../models/CNN\\Model_0011_1_Best.hdf5\n",
      "886/886 [==============================] - 70s 79ms/step - loss: 1.0939 - accuracy: 0.6201 - val_loss: 1.2403 - val_accuracy: 0.5759\n",
      "Epoch 3/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.9059 - accuracy: 0.6874\n",
      "Epoch 00003: val_loss improved from 1.24031 to 1.07375, saving model to ../models/CNN\\Model_0011_1_Best.hdf5\n",
      "886/886 [==============================] - 70s 79ms/step - loss: 0.9059 - accuracy: 0.6874 - val_loss: 1.0737 - val_accuracy: 0.6387\n",
      "Epoch 4/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.7749 - accuracy: 0.7297\n",
      "Epoch 00004: val_loss improved from 1.07375 to 0.86468, saving model to ../models/CNN\\Model_0011_1_Best.hdf5\n",
      "886/886 [==============================] - 71s 80ms/step - loss: 0.7748 - accuracy: 0.7298 - val_loss: 0.8647 - val_accuracy: 0.7000\n",
      "Epoch 5/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.6719 - accuracy: 0.7638\n",
      "Epoch 00005: val_loss improved from 0.86468 to 0.83080, saving model to ../models/CNN\\Model_0011_1_Best.hdf5\n",
      "886/886 [==============================] - 73s 82ms/step - loss: 0.6719 - accuracy: 0.7639 - val_loss: 0.8308 - val_accuracy: 0.7171\n",
      "Epoch 6/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.5609 - accuracy: 0.8039\n",
      "Epoch 00006: val_loss did not improve from 0.83080\n",
      "886/886 [==============================] - 72s 81ms/step - loss: 0.5609 - accuracy: 0.8038 - val_loss: 0.8446 - val_accuracy: 0.7203\n",
      "Epoch 7/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.4913 - accuracy: 0.8256\n",
      "Epoch 00007: val_loss did not improve from 0.83080\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.4914 - accuracy: 0.8256 - val_loss: 0.9171 - val_accuracy: 0.7093\n",
      "Epoch 8/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.4161 - accuracy: 0.8498\n",
      "Epoch 00008: val_loss did not improve from 0.83080\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.4161 - accuracy: 0.8497 - val_loss: 0.9062 - val_accuracy: 0.7093\n",
      "Epoch 00008: early stopping\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.9116 - accuracy: 0.6916\n",
      "Score for fold 1: loss of 0.9116305708885193; accuracy of 69.16000247001648%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koki inoue\\anaconda3\\envs\\tf2.3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], y=[9. 9. 4. ... 6. 1. 1.] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 1.4705 - accuracy: 0.4766\n",
      "Epoch 00001: val_loss improved from inf to 1.41314, saving model to ../models/CNN\\Model_0011_2_Best.hdf5\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 1.4703 - accuracy: 0.4767 - val_loss: 1.4131 - val_accuracy: 0.5134\n",
      "Epoch 2/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 1.0891 - accuracy: 0.6238\n",
      "Epoch 00002: val_loss improved from 1.41314 to 1.18230, saving model to ../models/CNN\\Model_0011_2_Best.hdf5\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 1.0891 - accuracy: 0.6238 - val_loss: 1.1823 - val_accuracy: 0.5838\n",
      "Epoch 3/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.8918 - accuracy: 0.6893\n",
      "Epoch 00003: val_loss improved from 1.18230 to 1.01027, saving model to ../models/CNN\\Model_0011_2_Best.hdf5\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.8918 - accuracy: 0.6892 - val_loss: 1.0103 - val_accuracy: 0.6476\n",
      "Epoch 4/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.7536 - accuracy: 0.7381\n",
      "Epoch 00004: val_loss did not improve from 1.01027\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.7537 - accuracy: 0.7380 - val_loss: 1.0991 - val_accuracy: 0.6307\n",
      "Epoch 5/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.6494 - accuracy: 0.7731\n",
      "Epoch 00005: val_loss did not improve from 1.01027\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.6494 - accuracy: 0.7731 - val_loss: 1.0177 - val_accuracy: 0.6514\n",
      "Epoch 6/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.5609 - accuracy: 0.8006\n",
      "Epoch 00006: val_loss improved from 1.01027 to 0.96411, saving model to ../models/CNN\\Model_0011_2_Best.hdf5\n",
      "886/886 [==============================] - 70s 79ms/step - loss: 0.5608 - accuracy: 0.8006 - val_loss: 0.9641 - val_accuracy: 0.6994\n",
      "Epoch 7/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.4800 - accuracy: 0.8299\n",
      "Epoch 00007: val_loss improved from 0.96411 to 0.87581, saving model to ../models/CNN\\Model_0011_2_Best.hdf5\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.4802 - accuracy: 0.8297 - val_loss: 0.8758 - val_accuracy: 0.7251\n",
      "Epoch 8/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.4057 - accuracy: 0.8524\n",
      "Epoch 00008: val_loss improved from 0.87581 to 0.82701, saving model to ../models/CNN\\Model_0011_2_Best.hdf5\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.4058 - accuracy: 0.8524 - val_loss: 0.8270 - val_accuracy: 0.7447\n",
      "Epoch 9/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.8745\n",
      "Epoch 00009: val_loss did not improve from 0.82701\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.3401 - accuracy: 0.8746 - val_loss: 0.8368 - val_accuracy: 0.7470\n",
      "Epoch 10/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.2963 - accuracy: 0.8909\n",
      "Epoch 00010: val_loss did not improve from 0.82701\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.2966 - accuracy: 0.8909 - val_loss: 0.9339 - val_accuracy: 0.7391\n",
      "Epoch 11/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.2546 - accuracy: 0.9052\n",
      "Epoch 00011: val_loss did not improve from 0.82701\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.2546 - accuracy: 0.9052 - val_loss: 1.1192 - val_accuracy: 0.7178\n",
      "Epoch 00011: early stopping\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.8457 - accuracy: 0.7431\n",
      "Score for fold 2: loss of 0.8457248210906982; accuracy of 74.30999875068665%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koki inoue\\anaconda3\\envs\\tf2.3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], y=[6. 4. 1. ... 0. 1. 1.] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 1.4812 - accuracy: 0.4761\n",
      "Epoch 00001: val_loss improved from inf to 1.47447, saving model to ../models/CNN\\Model_0011_3_Best.hdf5\n",
      "886/886 [==============================] - 69s 77ms/step - loss: 1.4812 - accuracy: 0.4761 - val_loss: 1.4745 - val_accuracy: 0.4912\n",
      "Epoch 2/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 1.1003 - accuracy: 0.6177\n",
      "Epoch 00002: val_loss improved from 1.47447 to 1.22268, saving model to ../models/CNN\\Model_0011_3_Best.hdf5\n",
      "886/886 [==============================] - 71s 80ms/step - loss: 1.1005 - accuracy: 0.6176 - val_loss: 1.2227 - val_accuracy: 0.5730\n",
      "Epoch 3/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.9028 - accuracy: 0.6820\n",
      "Epoch 00003: val_loss improved from 1.22268 to 0.92061, saving model to ../models/CNN\\Model_0011_3_Best.hdf5\n",
      "886/886 [==============================] - 71s 80ms/step - loss: 0.9027 - accuracy: 0.6819 - val_loss: 0.9206 - val_accuracy: 0.6820\n",
      "Epoch 4/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.7738 - accuracy: 0.7313\n",
      "Epoch 00004: val_loss did not improve from 0.92061\n",
      "886/886 [==============================] - 72s 82ms/step - loss: 0.7738 - accuracy: 0.7312 - val_loss: 1.0292 - val_accuracy: 0.6523\n",
      "Epoch 5/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.6685 - accuracy: 0.7668\n",
      "Epoch 00005: val_loss improved from 0.92061 to 0.85254, saving model to ../models/CNN\\Model_0011_3_Best.hdf5\n",
      "886/886 [==============================] - 73s 82ms/step - loss: 0.6683 - accuracy: 0.7669 - val_loss: 0.8525 - val_accuracy: 0.7087\n",
      "Epoch 6/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.5797 - accuracy: 0.7961\n",
      "Epoch 00006: val_loss did not improve from 0.85254\n",
      "886/886 [==============================] - 72s 82ms/step - loss: 0.5803 - accuracy: 0.7960 - val_loss: 1.0299 - val_accuracy: 0.6711\n",
      "Epoch 7/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.4984 - accuracy: 0.8221\n",
      "Epoch 00007: val_loss improved from 0.85254 to 0.82879, saving model to ../models/CNN\\Model_0011_3_Best.hdf5\n",
      "886/886 [==============================] - 73s 83ms/step - loss: 0.4987 - accuracy: 0.8220 - val_loss: 0.8288 - val_accuracy: 0.7318\n",
      "Epoch 8/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.4208 - accuracy: 0.8477\n",
      "Epoch 00008: val_loss improved from 0.82879 to 0.81722, saving model to ../models/CNN\\Model_0011_3_Best.hdf5\n",
      "886/886 [==============================] - 73s 82ms/step - loss: 0.4209 - accuracy: 0.8477 - val_loss: 0.8172 - val_accuracy: 0.7443\n",
      "Epoch 9/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.3652 - accuracy: 0.8679\n",
      "Epoch 00009: val_loss did not improve from 0.81722\n",
      "886/886 [==============================] - 73s 82ms/step - loss: 0.3652 - accuracy: 0.8679 - val_loss: 0.9105 - val_accuracy: 0.7394\n",
      "Epoch 10/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.3095 - accuracy: 0.8879\n",
      "Epoch 00010: val_loss did not improve from 0.81722\n",
      "886/886 [==============================] - 71s 81ms/step - loss: 0.3097 - accuracy: 0.8879 - val_loss: 0.9127 - val_accuracy: 0.7341\n",
      "Epoch 11/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.2672 - accuracy: 0.9011\n",
      "Epoch 00011: val_loss did not improve from 0.81722\n",
      "886/886 [==============================] - 73s 82ms/step - loss: 0.2672 - accuracy: 0.9011 - val_loss: 0.9637 - val_accuracy: 0.7439\n",
      "Epoch 00011: early stopping\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.9189 - accuracy: 0.7197\n",
      "Score for fold 3: loss of 0.9188668727874756; accuracy of 71.96999788284302%\n",
      "Wall time: 35min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "class_weights_arr = [] # for calc class weight \n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model01 = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model01.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "\n",
    "    x_train_ = x_train_removed[train_index]\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "\n",
    "    # calculate class weights\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                     np.unique(y_train_),\n",
    "                                                     y_train_)\n",
    "    class_weights_arr.append(class_weights)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # one hot encoding\n",
    "    y_train_onehot = to_categorical(y_train_, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_011_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    model01_history = model01.fit(x_train_, y_train_onehot,\n",
    "                          batch_size=32,\n",
    "                          epochs=400,\n",
    "                          verbose=1,\n",
    "                          validation_data=(x_valid_, y_valid_onehot),\n",
    "                          callbacks=[es_cb, cp_cb],\n",
    "                          class_weight=class_weights,\n",
    "                          shuffle=True)\n",
    "    \n",
    "    # inference\n",
    "    model01.load_weights(chkpt)\n",
    "    scores = model01.evaluate(x_test, y_test_onehot)\n",
    "    print(f'Score for fold {fold_no}: {model01.metrics_names[0]} of {scores[0]}; {model01.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    predict = model01.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model01_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "suited-virtue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.85007500750075, 1: 0.8498200359928014, 2: 1.7006602641056423, 3: 0.85007500750075, 4: 1.7006602641056423, 5: 0.8498200359928014, 6: 0.85007500750075, 7: 0.8498200359928014, 8: 0.85007500750075, 9: 1.6996400719856029}\n",
      "{0: 0.85007500750075, 1: 0.85007500750075, 2: 1.6996400719856029, 3: 0.8498200359928014, 4: 1.6996400719856029, 5: 0.85007500750075, 6: 0.85007500750075, 7: 0.85007500750075, 8: 0.85007500750075, 9: 1.6996400719856029}\n",
      "{0: 0.8498500299940012, 1: 0.8501050105010501, 2: 1.6997000599880023, 3: 0.8501050105010501, 4: 1.6997000599880023, 5: 0.8501050105010501, 6: 0.8498500299940012, 7: 0.8501050105010501, 8: 0.8498500299940012, 9: 1.7007202881152461}\n"
     ]
    }
   ],
   "source": [
    "# print classs weight\n",
    "ensemble_class_weights_arr = class_weights_arr\n",
    "for class_weight_ in ensemble_class_weights_arr:\n",
    "    print(dict(enumerate(class_weight_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "framed-doctor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1000\n",
      "           1       0.86      0.92      0.89      1000\n",
      "           2       0.62      0.74      0.67      1000\n",
      "           3       0.58      0.71      0.64      1000\n",
      "           4       0.84      0.59      0.69      1000\n",
      "           5       0.75      0.71      0.73      1000\n",
      "           6       0.80      0.82      0.81      1000\n",
      "           7       0.85      0.83      0.84      1000\n",
      "           8       0.91      0.85      0.88      1000\n",
      "           9       0.93      0.79      0.85      1000\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.79      0.78      0.78     10000\n",
      "weighted avg       0.79      0.78      0.78     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_histories = histories\n",
    "ensemble_predicts = predicts\n",
    "ensemble_predicts_ = ensemble_predicts / n_splits\n",
    "y_pred = np.argmax(ensemble_predicts_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-married",
   "metadata": {},
   "source": [
    "#### Train with data augumentation & Class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "blind-bikini",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koki inoue\\anaconda3\\envs\\tf2.3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], y=[6. 9. 9. ... 0. 6. 1.] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.5395 - accuracy: 0.4619 ETA: 5s - l\n",
      "Epoch 00001: val_loss improved from inf to 1.54529, saving model to ../models/CNN\\Model_0012_1_Best.hdf5\n",
      "885/885 [==============================] - 86s 97ms/step - loss: 1.5395 - accuracy: 0.4619 - val_loss: 1.5453 - val_accuracy: 0.4864\n",
      "Epoch 2/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.1773 - accuracy: 0.5906\n",
      "Epoch 00002: val_loss improved from 1.54529 to 1.08471, saving model to ../models/CNN\\Model_0012_1_Best.hdf5\n",
      "885/885 [==============================] - 82s 93ms/step - loss: 1.1773 - accuracy: 0.5906 - val_loss: 1.0847 - val_accuracy: 0.6174\n",
      "Epoch 3/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.0015 - accuracy: 0.6509\n",
      "Epoch 00003: val_loss did not improve from 1.08471\n",
      "885/885 [==============================] - 82s 92ms/step - loss: 1.0015 - accuracy: 0.6509 - val_loss: 1.1786 - val_accuracy: 0.6010\n",
      "Epoch 4/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8814 - accuracy: 0.6971\n",
      "Epoch 00004: val_loss improved from 1.08471 to 0.95517, saving model to ../models/CNN\\Model_0012_1_Best.hdf5\n",
      "885/885 [==============================] - 83s 94ms/step - loss: 0.8814 - accuracy: 0.6971 - val_loss: 0.9552 - val_accuracy: 0.6721\n",
      "Epoch 5/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8131 - accuracy: 0.7209\n",
      "Epoch 00005: val_loss did not improve from 0.95517\n",
      "885/885 [==============================] - 83s 94ms/step - loss: 0.8131 - accuracy: 0.7209 - val_loss: 1.0275 - val_accuracy: 0.6557\n",
      "Epoch 6/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7389 - accuracy: 0.7445\n",
      "Epoch 00006: val_loss improved from 0.95517 to 0.92423, saving model to ../models/CNN\\Model_0012_1_Best.hdf5\n",
      "885/885 [==============================] - 83s 94ms/step - loss: 0.7389 - accuracy: 0.7445 - val_loss: 0.9242 - val_accuracy: 0.6907\n",
      "Epoch 7/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6793 - accuracy: 0.7687\n",
      "Epoch 00007: val_loss improved from 0.92423 to 0.74120, saving model to ../models/CNN\\Model_0012_1_Best.hdf5\n",
      "885/885 [==============================] - 83s 94ms/step - loss: 0.6793 - accuracy: 0.7687 - val_loss: 0.7412 - val_accuracy: 0.7410\n",
      "Epoch 8/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.7803\n",
      "Epoch 00008: val_loss did not improve from 0.74120\n",
      "885/885 [==============================] - 83s 94ms/step - loss: 0.6355 - accuracy: 0.7803 - val_loss: 0.7457 - val_accuracy: 0.7487\n",
      "Epoch 9/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5966 - accuracy: 0.7934\n",
      "Epoch 00009: val_loss did not improve from 0.74120\n",
      "885/885 [==============================] - 81s 92ms/step - loss: 0.5966 - accuracy: 0.7934 - val_loss: 0.8407 - val_accuracy: 0.7182\n",
      "Epoch 10/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5572 - accuracy: 0.8043\n",
      "Epoch 00010: val_loss did not improve from 0.74120\n",
      "885/885 [==============================] - 82s 93ms/step - loss: 0.5572 - accuracy: 0.8043 - val_loss: 0.7838 - val_accuracy: 0.7402\n",
      "Epoch 00010: early stopping\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.7751 - accuracy: 0.7337\n",
      "Score for fold 1: loss of 0.7751016616821289; accuracy of 73.36999773979187%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koki inoue\\anaconda3\\envs\\tf2.3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], y=[6. 9. 4. ... 0. 6. 1.] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.5459 - accuracy: 0.4550\n",
      "Epoch 00001: val_loss improved from inf to 1.43595, saving model to ../models/CNN\\Model_0012_2_Best.hdf5\n",
      "885/885 [==============================] - 72s 81ms/step - loss: 1.5459 - accuracy: 0.4550 - val_loss: 1.4360 - val_accuracy: 0.5185\n",
      "Epoch 2/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.1895 - accuracy: 0.5848\n",
      "Epoch 00002: val_loss did not improve from 1.43595\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 1.1895 - accuracy: 0.5848 - val_loss: 1.6055 - val_accuracy: 0.5050\n",
      "Epoch 3/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.0125 - accuracy: 0.6485\n",
      "Epoch 00003: val_loss improved from 1.43595 to 1.09172, saving model to ../models/CNN\\Model_0012_2_Best.hdf5\n",
      "885/885 [==============================] - 70s 80ms/step - loss: 1.0125 - accuracy: 0.6485 - val_loss: 1.0917 - val_accuracy: 0.6326\n",
      "Epoch 4/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.9000 - accuracy: 0.6876\n",
      "Epoch 00004: val_loss did not improve from 1.09172\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 0.9000 - accuracy: 0.6876 - val_loss: 1.2175 - val_accuracy: 0.6214\n",
      "Epoch 5/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8108 - accuracy: 0.7170\n",
      "Epoch 00005: val_loss improved from 1.09172 to 0.97309, saving model to ../models/CNN\\Model_0012_2_Best.hdf5\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 0.8108 - accuracy: 0.7170 - val_loss: 0.9731 - val_accuracy: 0.6709\n",
      "Epoch 6/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7444 - accuracy: 0.7423\n",
      "Epoch 00006: val_loss improved from 0.97309 to 0.95096, saving model to ../models/CNN\\Model_0012_2_Best.hdf5\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 0.7444 - accuracy: 0.7423 - val_loss: 0.9510 - val_accuracy: 0.6734\n",
      "Epoch 7/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6771 - accuracy: 0.7651\n",
      "Epoch 00007: val_loss did not improve from 0.95096\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 0.6771 - accuracy: 0.7651 - val_loss: 0.9566 - val_accuracy: 0.6929\n",
      "Epoch 8/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6455 - accuracy: 0.7775\n",
      "Epoch 00008: val_loss did not improve from 0.95096\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 0.6455 - accuracy: 0.7775 - val_loss: 0.9833 - val_accuracy: 0.6850\n",
      "Epoch 9/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5950 - accuracy: 0.7910\n",
      "Epoch 00009: val_loss improved from 0.95096 to 0.70910, saving model to ../models/CNN\\Model_0012_2_Best.hdf5\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 0.5950 - accuracy: 0.7910 - val_loss: 0.7091 - val_accuracy: 0.7595\n",
      "Epoch 10/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5619 - accuracy: 0.8041\n",
      "Epoch 00010: val_loss did not improve from 0.70910\n",
      "885/885 [==============================] - 71s 81ms/step - loss: 0.5619 - accuracy: 0.8041 - val_loss: 0.7744 - val_accuracy: 0.7419\n",
      "Epoch 11/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.8147\n",
      "Epoch 00011: val_loss did not improve from 0.70910\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 0.5287 - accuracy: 0.8147 - val_loss: 0.7394 - val_accuracy: 0.7595\n",
      "Epoch 12/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5018 - accuracy: 0.8256\n",
      "Epoch 00012: val_loss did not improve from 0.70910\n",
      "885/885 [==============================] - 71s 81ms/step - loss: 0.5018 - accuracy: 0.8256 - val_loss: 0.7640 - val_accuracy: 0.7653\n",
      "Epoch 00012: early stopping\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.7859 - accuracy: 0.7404\n",
      "Score for fold 2: loss of 0.7858844995498657; accuracy of 74.04000163078308%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koki inoue\\anaconda3\\envs\\tf2.3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], y=[9. 1. 2. ... 1. 1. 1.] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.5345 - accuracy: 0.4577\n",
      "Epoch 00001: val_loss improved from inf to 1.42552, saving model to ../models/CNN\\Model_0012_3_Best.hdf5\n",
      "885/885 [==============================] - 72s 82ms/step - loss: 1.5345 - accuracy: 0.4577 - val_loss: 1.4255 - val_accuracy: 0.4982\n",
      "Epoch 2/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.1779 - accuracy: 0.5887\n",
      "Epoch 00002: val_loss did not improve from 1.42552\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 1.1779 - accuracy: 0.5887 - val_loss: 1.5431 - val_accuracy: 0.4834\n",
      "Epoch 3/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.9975 - accuracy: 0.6549\n",
      "Epoch 00003: val_loss improved from 1.42552 to 1.20448, saving model to ../models/CNN\\Model_0012_3_Best.hdf5\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 0.9975 - accuracy: 0.6549 - val_loss: 1.2045 - val_accuracy: 0.6094\n",
      "Epoch 4/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8749 - accuracy: 0.6968\n",
      "Epoch 00004: val_loss improved from 1.20448 to 1.06793, saving model to ../models/CNN\\Model_0012_3_Best.hdf5\n",
      "885/885 [==============================] - 71s 81ms/step - loss: 0.8749 - accuracy: 0.6968 - val_loss: 1.0679 - val_accuracy: 0.6490\n",
      "Epoch 5/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7874 - accuracy: 0.7274\n",
      "Epoch 00005: val_loss improved from 1.06793 to 0.97323, saving model to ../models/CNN\\Model_0012_3_Best.hdf5\n",
      "885/885 [==============================] - 71s 81ms/step - loss: 0.7874 - accuracy: 0.7274 - val_loss: 0.9732 - val_accuracy: 0.6901\n",
      "Epoch 6/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7320 - accuracy: 0.7504\n",
      "Epoch 00006: val_loss improved from 0.97323 to 0.89948, saving model to ../models/CNN\\Model_0012_3_Best.hdf5\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 0.7320 - accuracy: 0.7504 - val_loss: 0.8995 - val_accuracy: 0.7009\n",
      "Epoch 7/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6774 - accuracy: 0.7650\n",
      "Epoch 00007: val_loss improved from 0.89948 to 0.86485, saving model to ../models/CNN\\Model_0012_3_Best.hdf5\n",
      "885/885 [==============================] - 71s 81ms/step - loss: 0.6774 - accuracy: 0.7650 - val_loss: 0.8648 - val_accuracy: 0.7130\n",
      "Epoch 8/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.7836\n",
      "Epoch 00008: val_loss improved from 0.86485 to 0.73363, saving model to ../models/CNN\\Model_0012_3_Best.hdf5\n",
      "885/885 [==============================] - 71s 81ms/step - loss: 0.6254 - accuracy: 0.7836 - val_loss: 0.7336 - val_accuracy: 0.7553\n",
      "Epoch 9/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5850 - accuracy: 0.7982\n",
      "Epoch 00009: val_loss did not improve from 0.73363\n",
      "885/885 [==============================] - 72s 81ms/step - loss: 0.5850 - accuracy: 0.7982 - val_loss: 0.8107 - val_accuracy: 0.7388\n",
      "Epoch 10/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.8077\n",
      "Epoch 00010: val_loss improved from 0.73363 to 0.69948, saving model to ../models/CNN\\Model_0012_3_Best.hdf5\n",
      "885/885 [==============================] - 72s 82ms/step - loss: 0.5486 - accuracy: 0.8077 - val_loss: 0.6995 - val_accuracy: 0.7644\n",
      "Epoch 11/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5156 - accuracy: 0.8172\n",
      "Epoch 00011: val_loss improved from 0.69948 to 0.69709, saving model to ../models/CNN\\Model_0012_3_Best.hdf5\n",
      "885/885 [==============================] - 72s 82ms/step - loss: 0.5156 - accuracy: 0.8172 - val_loss: 0.6971 - val_accuracy: 0.7760\n",
      "Epoch 12/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.8292\n",
      "Epoch 00012: val_loss did not improve from 0.69709\n",
      "885/885 [==============================] - 72s 81ms/step - loss: 0.4834 - accuracy: 0.8292 - val_loss: 0.7658 - val_accuracy: 0.7547\n",
      "Epoch 13/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4628 - accuracy: 0.8361\n",
      "Epoch 00013: val_loss did not improve from 0.69709\n",
      "885/885 [==============================] - 72s 81ms/step - loss: 0.4628 - accuracy: 0.8361 - val_loss: 0.7048 - val_accuracy: 0.7726\n",
      "Epoch 14/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.8491\n",
      "Epoch 00014: val_loss did not improve from 0.69709\n",
      "885/885 [==============================] - 72s 81ms/step - loss: 0.4298 - accuracy: 0.8491 - val_loss: 0.7464 - val_accuracy: 0.7680\n",
      "Epoch 00014: early stopping\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.7391 - accuracy: 0.7668\n",
      "Score for fold 3: loss of 0.7391113638877869; accuracy of 76.67999863624573%\n",
      "Wall time: 45min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "class_weights_arr = [] # for calc class weight \n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model02 = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model02.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "\n",
    "    x_train_ = x_train_removed[train_index]\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "\n",
    "    # calculate class weights\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                     np.unique(y_train_),\n",
    "                                                     y_train_)\n",
    "    class_weights_arr.append(class_weights)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    # one hot encoding\n",
    "    y_train_onehot = to_categorical(y_train_, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_012_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    # create generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=10,\n",
    "#     shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    "#     channel_shift_range=0.2\n",
    "    )\n",
    "\n",
    "    batch_size = 32\n",
    "    train_datagenerator = train_datagen.flow(x_train_, y_train_onehot, batch_size)\n",
    "    valid_datagenerator = ImageDataGenerator().flow(x_valid_, y_valid_onehot, batch_size)\n",
    "\n",
    "    model02_history = model02.fit_generator(train_datagenerator,\n",
    "                                  steps_per_epoch=int(len(x_train_)//batch_size),\n",
    "                                  epochs=400,\n",
    "                                  validation_data=valid_datagenerator,\n",
    "                                  validation_steps=int(len(x_valid_)//batch_size),\n",
    "                                  verbose=1,\n",
    "                                  shuffle=True,\n",
    "                                  class_weight=class_weights,\n",
    "                                  callbacks=[es_cb, cp_cb])\n",
    "\n",
    "    # inference\n",
    "    model02.load_weights(chkpt)\n",
    "    scores = model02.evaluate(x_test, y_test_onehot)\n",
    "    print(f'Score for fold {fold_no}: {model02.metrics_names[0]} of {scores[0]}; {model02.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    predict = model02.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model02_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "superior-pickup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.85007500750075, 1: 0.8498200359928014, 2: 1.7006602641056423, 3: 0.85007500750075, 4: 1.7006602641056423, 5: 0.8498200359928014, 6: 0.85007500750075, 7: 0.8498200359928014, 8: 0.85007500750075, 9: 1.6996400719856029}\n",
      "{0: 0.85007500750075, 1: 0.85007500750075, 2: 1.6996400719856029, 3: 0.8498200359928014, 4: 1.6996400719856029, 5: 0.85007500750075, 6: 0.85007500750075, 7: 0.85007500750075, 8: 0.85007500750075, 9: 1.6996400719856029}\n",
      "{0: 0.8498500299940012, 1: 0.8501050105010501, 2: 1.6997000599880023, 3: 0.8501050105010501, 4: 1.6997000599880023, 5: 0.8501050105010501, 6: 0.8498500299940012, 7: 0.8501050105010501, 8: 0.8498500299940012, 9: 1.7007202881152461}\n"
     ]
    }
   ],
   "source": [
    "# print classs weight\n",
    "ensemble_dataaug_class_weights_arr = class_weights_arr\n",
    "for class_weight_ in ensemble_dataaug_class_weights_arr:\n",
    "    print(dict(enumerate(class_weight_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "helpful-imagination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1000\n",
      "           1       0.87      0.94      0.91      1000\n",
      "           2       0.81      0.64      0.71      1000\n",
      "           3       0.66      0.67      0.66      1000\n",
      "           4       0.86      0.67      0.76      1000\n",
      "           5       0.80      0.71      0.75      1000\n",
      "           6       0.74      0.91      0.82      1000\n",
      "           7       0.78      0.90      0.84      1000\n",
      "           8       0.85      0.93      0.89      1000\n",
      "           9       0.90      0.86      0.88      1000\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.81      0.81      0.80     10000\n",
      "weighted avg       0.81      0.81      0.80     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_dataaug_histories = histories\n",
    "ensemble_dataaug_predicts = predicts\n",
    "ensemble_dataaug_predicts_ = ensemble_dataaug_predicts / n_splits\n",
    "y_pred = np.argmax(ensemble_dataaug_predicts_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-server",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
