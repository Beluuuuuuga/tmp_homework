{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_randvalue(value):\n",
    "    # Set a seed value\n",
    "    seed_value= value \n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "set_randvalue(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() # load data\n",
    "x_train,x_test = x_train.astype('float32')/255.0,x_test.astype('float32')/255.0 # normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit three class preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird label num is 2500\n",
      "Deer label num is 2500\n",
      "Truck label num is 2500\n",
      "Other label num is 35000\n",
      "Train label num is 42500\n",
      "(42500, 32, 32, 3)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "# No method on keras to get cifar10 category label name by categoly label?\n",
    "cifar10_labels = np.array([\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'])\n",
    "\n",
    "bird_num = np.where(cifar10_labels=='bird')\n",
    "deer_num = np.where(cifar10_labels=='deer')\n",
    "truck_num = np.where(cifar10_labels=='truck')\n",
    "\n",
    "limit_num = 2500\n",
    "\n",
    "# get limit label indexes\n",
    "bird_indexes = [i for i, label in enumerate(y_train) if label == bird_num]\n",
    "deer_indexes = [i for i, label in enumerate(y_train) if label == deer_num] \n",
    "truck_indexes = [i for i, label in enumerate(y_train) if label == truck_num] \n",
    "other_indexes = [i for i, label in enumerate(y_train) if label not in [bird_num, deer_num, truck_num]]\n",
    "\n",
    "# limit\n",
    "bird_indexes = bird_indexes[:limit_num]\n",
    "deer_indexes = deer_indexes[:limit_num]\n",
    "truck_indexes = truck_indexes[:limit_num]\n",
    "print(f'Bird label num is {len(bird_indexes)}') # 2500\n",
    "print(f'Deer label num is {len(deer_indexes)}') # 2500\n",
    "print(f'Truck label num is {len(truck_indexes)}') # 2500\n",
    "print(f'Other label num is {len(other_indexes)}') # 35000; 5000*7\n",
    "\n",
    "# merge and sort\n",
    "merge_indexes = np.concatenate([other_indexes, bird_indexes, deer_indexes, truck_indexes], 0)\n",
    "merge_indexes.sort()\n",
    "print(f'Train label num is {len(merge_indexes)}') # 42500\n",
    "\n",
    "# create three labels removed train data\n",
    "x_train_removed =  np.zeros((len(merge_indexes), 32, 32, 3))\n",
    "y_train_removed =  np.zeros(len(merge_indexes))\n",
    "\n",
    "for i, train_index in enumerate(merge_indexes):\n",
    "    x_train_removed[i] = x_train[train_index]\n",
    "    y_train_removed[i] = y_train[train_index]\n",
    "    \n",
    "print(x_train_removed.shape)\n",
    "print(y_train_removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42500, 32, 32, 3)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_removed.shape)\n",
    "print(y_train_removed.shape)\n",
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0    5000\n",
      "7.0    5000\n",
      "6.0    5000\n",
      "5.0    5000\n",
      "3.0    5000\n",
      "1.0    5000\n",
      "0.0    5000\n",
      "9.0    2500\n",
      "4.0    2500\n",
      "2.0    2500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(y_train_removed.flatten())\n",
    "print(df.value_counts())\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5000., 5000., 2500., 5000., 2500., 5000., 5000., 5000., 5000.,\n",
       "        2500.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot data labels\n",
    "plt.hist(y_train_removed.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load AE models weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Norm Model\n",
    "def create_AE01_model(k_size):\n",
    "    input_img = Input(shape=(32, 32, 3))  # 0\n",
    "    conv1 = Conv2D(64, (k_size, k_size), padding='same', name=\"Dense_AE01_1\")(input_img) # 1\n",
    "    conv1 = BatchNormalization(name=\"BN_AE01_1\")(conv1) # 2\n",
    "    conv1 = Activation('relu', name=\"Relu_AE01_1\")(conv1) # 3\n",
    "        \n",
    "    decoded = Conv2D(3, (k_size, k_size), padding='same', name=\"Dense_AE01_2\")(conv1) # 4\n",
    "    decoded = BatchNormalization(name=\"BN_AE01_2\")(decoded) # 5\n",
    "    decoded = Activation('relu', name=\"Relu_AE01_2\")(decoded) # 6\n",
    "    return Model(input_img, decoded)\n",
    "\n",
    "class AE01():\n",
    "    def __init__(self, ksize, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.autoencoder = create_AE01_model(ksize)\n",
    "        self.encoder = None\n",
    "\n",
    "    def compile(self, optimizer='adam', loss='binary_crossentropy'):\n",
    "        self.autoencoder.compile(optimizer=self.optimizer, loss=loss)\n",
    "\n",
    "    def train(self, x_train=None, x_test=None, epochs=1, batch_size=32, shuffle=True):\n",
    "        es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "        ae_model_path = '../models/AE/AE01_AE_Best.hdf5'\n",
    "        cp_cb = ModelCheckpoint(filepath = ae_model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "       \n",
    "        history = self.autoencoder.fit(x_train, x_train,\n",
    "                             epochs=epochs,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=shuffle,\n",
    "                             callbacks=[es_cb, cp_cb],\n",
    "                             validation_data=(x_test, x_test))\n",
    "        \n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        \n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        encode_model_path = '../models/AE/AE01_Encoder_Best.hdf5'\n",
    "        self.encoder.save(encode_model_path)\n",
    "        return history\n",
    "    \n",
    "    def load_weights(self, ae_model_path, encode_model_path):\n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        self.encoder.load_weights(encode_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "Dense_AE01_1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "BN_AE01_1 (BatchNormalizatio (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "Relu_AE01_1 (Activation)     (None, 32, 32, 64)        0         \n",
      "=================================================================\n",
      "Total params: 2,048\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_ksize = 3\n",
    "ae_optimizer = 'rmsprop'\n",
    "stack01 = AE01(ae_ksize, ae_optimizer)\n",
    "stack01.load_weights('../models/AE/AE01_AE_Best.hdf5', '../models/AE/AE01_Encoder_Best.hdf5')\n",
    "stack01.encoder.trainable = False\n",
    "stack01.encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model AE to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_StackedAE01_CNN01_model(encoder):\n",
    "    input_img = encoder.input\n",
    "    output = encoder.layers[-1].output # 32,32,64\n",
    "    x = Conv2D(64,(3,3),padding = \"same\",activation= \"relu\")(output)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) # 16,16,64\n",
    "    \n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) # 8,8,128\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    y = Dense(10,activation = \"softmax\")(x)\n",
    "\n",
    "    return Model(input_img, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train without data augumentation & Class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12810649\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.1-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass classes=[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], y=[9. 9. 4. ... 0. 1. 1.] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 1.4815 - accuracy: 0.4740\n",
      "Epoch 00001: val_loss improved from inf to 1.18299, saving model to ../models/CNN\\Model_011_1_Best.hdf5\n",
      "886/886 [==============================] - 6s 7ms/step - loss: 1.4815 - accuracy: 0.4740 - val_loss: 1.1830 - val_accuracy: 0.5738\n",
      "Epoch 2/400\n",
      "878/886 [============================>.] - ETA: 0s - loss: 1.0968 - accuracy: 0.6174\n",
      "Epoch 00002: val_loss improved from 1.18299 to 1.13400, saving model to ../models/CNN\\Model_011_1_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 1.0954 - accuracy: 0.6176 - val_loss: 1.1340 - val_accuracy: 0.5925\n",
      "Epoch 3/400\n",
      "876/886 [============================>.] - ETA: 0s - loss: 0.8961 - accuracy: 0.6881\n",
      "Epoch 00003: val_loss improved from 1.13400 to 0.95631, saving model to ../models/CNN\\Model_011_1_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.8959 - accuracy: 0.6880 - val_loss: 0.9563 - val_accuracy: 0.6682\n",
      "Epoch 4/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.7578 - accuracy: 0.7368\n",
      "Epoch 00004: val_loss improved from 0.95631 to 0.93384, saving model to ../models/CNN\\Model_011_1_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.7577 - accuracy: 0.7368 - val_loss: 0.9338 - val_accuracy: 0.6855\n",
      "Epoch 5/400\n",
      "882/886 [============================>.] - ETA: 0s - loss: 0.6447 - accuracy: 0.7749\n",
      "Epoch 00005: val_loss improved from 0.93384 to 0.80568, saving model to ../models/CNN\\Model_011_1_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.6447 - accuracy: 0.7750 - val_loss: 0.8057 - val_accuracy: 0.7216\n",
      "Epoch 6/400\n",
      "884/886 [============================>.] - ETA: 0s - loss: 0.5526 - accuracy: 0.8045\n",
      "Epoch 00006: val_loss did not improve from 0.80568\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.5528 - accuracy: 0.8046 - val_loss: 0.8559 - val_accuracy: 0.7205\n",
      "Epoch 7/400\n",
      "880/886 [============================>.] - ETA: 0s - loss: 0.4770 - accuracy: 0.8295\n",
      "Epoch 00007: val_loss improved from 0.80568 to 0.80210, saving model to ../models/CNN\\Model_011_1_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.4775 - accuracy: 0.8296 - val_loss: 0.8021 - val_accuracy: 0.7493\n",
      "Epoch 8/400\n",
      "875/886 [============================>.] - ETA: 0s - loss: 0.4004 - accuracy: 0.8534\n",
      "Epoch 00008: val_loss did not improve from 0.80210\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.4007 - accuracy: 0.8535 - val_loss: 0.8711 - val_accuracy: 0.7286\n",
      "Epoch 9/400\n",
      "880/886 [============================>.] - ETA: 0s - loss: 0.3392 - accuracy: 0.8764\n",
      "Epoch 00009: val_loss did not improve from 0.80210\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.3395 - accuracy: 0.8762 - val_loss: 0.8504 - val_accuracy: 0.7465\n",
      "Epoch 10/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.2798 - accuracy: 0.8969\n",
      "Epoch 00010: val_loss did not improve from 0.80210\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.2798 - accuracy: 0.8969 - val_loss: 0.9133 - val_accuracy: 0.7381\n",
      "Epoch 00010: early stopping\n",
      "443/443 [==============================] - 1s 2ms/step - loss: 0.8021 - accuracy: 0.7493\n",
      "Score for fold 1: loss of 0.8021000027656555; accuracy of 74.92764592170715%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12810649\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.1-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass classes=[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], y=[6. 1. 1. ... 0. 1. 6.] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "877/886 [============================>.] - ETA: 0s - loss: 1.4769 - accuracy: 0.4762\n",
      "Epoch 00001: val_loss improved from inf to 1.49876, saving model to ../models/CNN\\Model_011_2_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 1.4735 - accuracy: 0.4772 - val_loss: 1.4988 - val_accuracy: 0.4958\n",
      "Epoch 2/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 1.0977 - accuracy: 0.6180\n",
      "Epoch 00002: val_loss improved from 1.49876 to 1.23893, saving model to ../models/CNN\\Model_011_2_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 1.0979 - accuracy: 0.6180 - val_loss: 1.2389 - val_accuracy: 0.5712\n",
      "Epoch 3/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.9003 - accuracy: 0.6879\n",
      "Epoch 00003: val_loss improved from 1.23893 to 0.94874, saving model to ../models/CNN\\Model_011_2_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.9003 - accuracy: 0.6879 - val_loss: 0.9487 - val_accuracy: 0.6791\n",
      "Epoch 4/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.7666 - accuracy: 0.7325\n",
      "Epoch 00004: val_loss improved from 0.94874 to 0.79845, saving model to ../models/CNN\\Model_011_2_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.7666 - accuracy: 0.7325 - val_loss: 0.7984 - val_accuracy: 0.7188\n",
      "Epoch 5/400\n",
      "880/886 [============================>.] - ETA: 0s - loss: 0.6571 - accuracy: 0.7686\n",
      "Epoch 00005: val_loss did not improve from 0.79845\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.6578 - accuracy: 0.7683 - val_loss: 0.9580 - val_accuracy: 0.6872\n",
      "Epoch 6/400\n",
      "875/886 [============================>.] - ETA: 0s - loss: 0.5531 - accuracy: 0.8049\n",
      "Epoch 00006: val_loss did not improve from 0.79845\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.5540 - accuracy: 0.8049 - val_loss: 0.9387 - val_accuracy: 0.7012\n",
      "Epoch 7/400\n",
      "879/886 [============================>.] - ETA: 0s - loss: 0.4775 - accuracy: 0.8297\n",
      "Epoch 00007: val_loss did not improve from 0.79845\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.4777 - accuracy: 0.8294 - val_loss: 0.8152 - val_accuracy: 0.7347\n",
      "Epoch 00007: early stopping\n",
      "443/443 [==============================] - 1s 2ms/step - loss: 0.7984 - accuracy: 0.7188\n",
      "Score for fold 2: loss of 0.7984474301338196; accuracy of 71.87830805778503%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12810649\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.1-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass classes=[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], y=[6. 9. 9. ... 6. 1. 1.] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 1.4927 - accuracy: 0.4730\n",
      "Epoch 00001: val_loss improved from inf to 1.96921, saving model to ../models/CNN\\Model_011_3_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 1.4927 - accuracy: 0.4730 - val_loss: 1.9692 - val_accuracy: 0.4049\n",
      "Epoch 2/400\n",
      "884/886 [============================>.] - ETA: 0s - loss: 1.0955 - accuracy: 0.6164\n",
      "Epoch 00002: val_loss improved from 1.96921 to 1.21233, saving model to ../models/CNN\\Model_011_3_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 1.0952 - accuracy: 0.6166 - val_loss: 1.2123 - val_accuracy: 0.6117\n",
      "Epoch 3/400\n",
      "882/886 [============================>.] - ETA: 0s - loss: 0.9175 - accuracy: 0.6805\n",
      "Epoch 00003: val_loss improved from 1.21233 to 1.09126, saving model to ../models/CNN\\Model_011_3_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.9174 - accuracy: 0.6805 - val_loss: 1.0913 - val_accuracy: 0.6243\n",
      "Epoch 4/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.7737 - accuracy: 0.7331\n",
      "Epoch 00004: val_loss improved from 1.09126 to 0.94036, saving model to ../models/CNN\\Model_011_3_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.7735 - accuracy: 0.7332 - val_loss: 0.9404 - val_accuracy: 0.6770\n",
      "Epoch 5/400\n",
      "884/886 [============================>.] - ETA: 0s - loss: 0.6559 - accuracy: 0.7702\n",
      "Epoch 00005: val_loss did not improve from 0.94036\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.6558 - accuracy: 0.7701 - val_loss: 0.9989 - val_accuracy: 0.6577\n",
      "Epoch 6/400\n",
      "878/886 [============================>.] - ETA: 0s - loss: 0.5563 - accuracy: 0.8034\n",
      "Epoch 00006: val_loss improved from 0.94036 to 0.83603, saving model to ../models/CNN\\Model_011_3_Best.hdf5\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.5564 - accuracy: 0.8032 - val_loss: 0.8360 - val_accuracy: 0.7189\n",
      "Epoch 7/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.4706 - accuracy: 0.8337\n",
      "Epoch 00007: val_loss did not improve from 0.83603\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.4706 - accuracy: 0.8337 - val_loss: 0.8917 - val_accuracy: 0.7204\n",
      "Epoch 8/400\n",
      "881/886 [============================>.] - ETA: 0s - loss: 0.4035 - accuracy: 0.8535\n",
      "Epoch 00008: val_loss did not improve from 0.83603\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.4038 - accuracy: 0.8533 - val_loss: 0.9106 - val_accuracy: 0.7181\n",
      "Epoch 9/400\n",
      "884/886 [============================>.] - ETA: 0s - loss: 0.3424 - accuracy: 0.8761\n",
      "Epoch 00009: val_loss did not improve from 0.83603\n",
      "886/886 [==============================] - 5s 6ms/step - loss: 0.3424 - accuracy: 0.8761 - val_loss: 0.9721 - val_accuracy: 0.7134\n",
      "Epoch 00009: early stopping\n",
      "443/443 [==============================] - 1s 2ms/step - loss: 0.8360 - accuracy: 0.7189\n",
      "Score for fold 3: loss of 0.8360266089439392; accuracy of 71.8904435634613%\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "class_weights_arr = [] # for calc class weight \n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "cv_acc = 0\n",
    "cv_f1 = 0 \n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model01 = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model01.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "\n",
    "    x_train_ = x_train_removed[train_index]\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "\n",
    "    # calculate class weights\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                     np.unique(y_train_),\n",
    "                                                     y_train_)\n",
    "    class_weights_arr.append(class_weights)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # one hot encoding\n",
    "    y_train_onehot = to_categorical(y_train_, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_011_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    model01_history = model01.fit(x_train_, y_train_onehot,\n",
    "                          batch_size=32,\n",
    "                          epochs=400,\n",
    "                          verbose=1,\n",
    "                          validation_data=(x_valid_, y_valid_onehot),\n",
    "                          callbacks=[es_cb, cp_cb],\n",
    "                          class_weight=class_weights,\n",
    "                          shuffle=True)\n",
    "    \n",
    "    # inference\n",
    "    model01.load_weights(chkpt)\n",
    "    scores = model01.evaluate(x_valid_, y_valid_onehot)\n",
    "    \n",
    "    # CV value\n",
    "    cv_acc += scores[1]*100\n",
    "    y_valid_pred =  model01.predict(x_valid_)\n",
    "    y_valid_pred = np.argmax(y_valid_pred, axis=1)\n",
    "    cv_f1 += f1_score(y_valid_, y_valid_pred, average='macro')*100\n",
    "    \n",
    "    print(f'Score for fold {fold_no}: {model01.metrics_names[0]} of {scores[0]}; {model01.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    predict = model01.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model01_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.85007500750075, 1: 0.8498200359928014, 2: 1.7006602641056423, 3: 0.85007500750075, 4: 1.7006602641056423, 5: 0.8498200359928014, 6: 0.85007500750075, 7: 0.8498200359928014, 8: 0.85007500750075, 9: 1.6996400719856029}\n",
      "{0: 0.85007500750075, 1: 0.85007500750075, 2: 1.6996400719856029, 3: 0.8498200359928014, 4: 1.6996400719856029, 5: 0.85007500750075, 6: 0.85007500750075, 7: 0.85007500750075, 8: 0.85007500750075, 9: 1.6996400719856029}\n",
      "{0: 0.8498500299940012, 1: 0.8501050105010501, 2: 1.6997000599880023, 3: 0.8501050105010501, 4: 1.6997000599880023, 5: 0.8501050105010501, 6: 0.8498500299940012, 7: 0.8501050105010501, 8: 0.8498500299940012, 9: 1.7007202881152461}\n"
     ]
    }
   ],
   "source": [
    "# print classs weight\n",
    "ensemble_class_weights_arr = class_weights_arr\n",
    "for class_weight_ in ensemble_class_weights_arr:\n",
    "    print(dict(enumerate(class_weight_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1000\n",
      "           1       0.86      0.92      0.89      1000\n",
      "           2       0.62      0.74      0.67      1000\n",
      "           3       0.58      0.71      0.64      1000\n",
      "           4       0.84      0.59      0.69      1000\n",
      "           5       0.75      0.71      0.73      1000\n",
      "           6       0.80      0.82      0.81      1000\n",
      "           7       0.85      0.83      0.84      1000\n",
      "           8       0.91      0.85      0.88      1000\n",
      "           9       0.93      0.79      0.85      1000\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.79      0.78      0.78     10000\n",
      "weighted avg       0.79      0.78      0.78     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_histories = histories\n",
    "ensemble_predicts = predicts\n",
    "ensemble_predicts_ = ensemble_predicts / n_splits\n",
    "y_pred = np.argmax(ensemble_predicts_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ACC is 72.0,n_splits CV macro F1 is 71.0\n"
     ]
    }
   ],
   "source": [
    "print(f'CV ACC is {cv_acc//n_splits},n_splits CV macro F1 is {cv_f1//n_splits}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with data augumentation & Class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <timed exec>:69: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12810649\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.1-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass classes=[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], y=[6. 9. 9. ... 6. 1. 1.] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 1.5489 - accuracy: 0.4511\n",
      "Epoch 00001: val_loss improved from inf to 1.40215, saving model to ../models/CNN\\Model_012_1_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 1.5483 - accuracy: 0.4514 - val_loss: 1.4022 - val_accuracy: 0.5147\n",
      "Epoch 2/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 1.2052 - accuracy: 0.5762\n",
      "Epoch 00002: val_loss improved from 1.40215 to 1.24829, saving model to ../models/CNN\\Model_012_1_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 1.2040 - accuracy: 0.5767 - val_loss: 1.2483 - val_accuracy: 0.5706\n",
      "Epoch 3/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 1.0280 - accuracy: 0.6433\n",
      "Epoch 00003: val_loss improved from 1.24829 to 1.01831, saving model to ../models/CNN\\Model_012_1_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 1.0278 - accuracy: 0.6432 - val_loss: 1.0183 - val_accuracy: 0.6431\n",
      "Epoch 4/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.9072 - accuracy: 0.6867\n",
      "Epoch 00004: val_loss improved from 1.01831 to 0.87337, saving model to ../models/CNN\\Model_012_1_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.9072 - accuracy: 0.6867 - val_loss: 0.8734 - val_accuracy: 0.6981\n",
      "Epoch 5/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.8141 - accuracy: 0.7179\n",
      "Epoch 00005: val_loss did not improve from 0.87337\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.8137 - accuracy: 0.7180 - val_loss: 0.9042 - val_accuracy: 0.6851\n",
      "Epoch 6/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.7433 - accuracy: 0.7402\n",
      "Epoch 00006: val_loss improved from 0.87337 to 0.81790, saving model to ../models/CNN\\Model_012_1_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.7435 - accuracy: 0.7401 - val_loss: 0.8179 - val_accuracy: 0.7127\n",
      "Epoch 7/400\n",
      "879/885 [============================>.] - ETA: 0s - loss: 0.6895 - accuracy: 0.7603\n",
      "Epoch 00007: val_loss did not improve from 0.81790\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.6898 - accuracy: 0.7603 - val_loss: 0.9097 - val_accuracy: 0.7002\n",
      "Epoch 8/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.6479 - accuracy: 0.7774\n",
      "Epoch 00008: val_loss did not improve from 0.81790\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.6482 - accuracy: 0.7772 - val_loss: 1.0165 - val_accuracy: 0.6832\n",
      "Epoch 9/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.6059 - accuracy: 0.7875\n",
      "Epoch 00009: val_loss improved from 0.81790 to 0.77206, saving model to ../models/CNN\\Model_012_1_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.6057 - accuracy: 0.7876 - val_loss: 0.7721 - val_accuracy: 0.7484\n",
      "Epoch 10/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.5610 - accuracy: 0.8063\n",
      "Epoch 00010: val_loss improved from 0.77206 to 0.75999, saving model to ../models/CNN\\Model_012_1_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.5604 - accuracy: 0.8064 - val_loss: 0.7600 - val_accuracy: 0.7472\n",
      "Epoch 11/400\n",
      "879/885 [============================>.] - ETA: 0s - loss: 0.5310 - accuracy: 0.8148 ETA: 0s - loss: 0.5313 - accuracy: 0.\n",
      "Epoch 00011: val_loss improved from 0.75999 to 0.73857, saving model to ../models/CNN\\Model_012_1_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.5309 - accuracy: 0.8148 - val_loss: 0.7386 - val_accuracy: 0.7638\n",
      "Epoch 12/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.5039 - accuracy: 0.8230\n",
      "Epoch 00012: val_loss did not improve from 0.73857\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.5043 - accuracy: 0.8228 - val_loss: 0.8035 - val_accuracy: 0.7385\n",
      "Epoch 13/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.4770 - accuracy: 0.8311\n",
      "Epoch 00013: val_loss did not improve from 0.73857\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.4766 - accuracy: 0.8312 - val_loss: 0.7624 - val_accuracy: 0.7574\n",
      "Epoch 14/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.4521 - accuracy: 0.8411\n",
      "Epoch 00014: val_loss improved from 0.73857 to 0.67501, saving model to ../models/CNN\\Model_012_1_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.4519 - accuracy: 0.8410 - val_loss: 0.6750 - val_accuracy: 0.7835\n",
      "Epoch 15/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.4282 - accuracy: 0.8454\n",
      "Epoch 00015: val_loss did not improve from 0.67501\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.4284 - accuracy: 0.8454 - val_loss: 0.7138 - val_accuracy: 0.7793\n",
      "Epoch 16/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.4160 - accuracy: 0.8540\n",
      "Epoch 00016: val_loss improved from 0.67501 to 0.65187, saving model to ../models/CNN\\Model_012_1_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.4161 - accuracy: 0.8539 - val_loss: 0.6519 - val_accuracy: 0.7948\n",
      "Epoch 17/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8640\n",
      "Epoch 00017: val_loss did not improve from 0.65187\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.3811 - accuracy: 0.8640 - val_loss: 0.8046 - val_accuracy: 0.7646\n",
      "Epoch 18/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.3691 - accuracy: 0.8670\n",
      "Epoch 00018: val_loss did not improve from 0.65187\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.3693 - accuracy: 0.8669 - val_loss: 0.7025 - val_accuracy: 0.7851\n",
      "Epoch 19/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.3590 - accuracy: 0.8709\n",
      "Epoch 00019: val_loss did not improve from 0.65187\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.3590 - accuracy: 0.8709 - val_loss: 0.7891 - val_accuracy: 0.7760\n",
      "Epoch 00019: early stopping\n",
      "443/443 [==============================] - 1s 3ms/step - loss: 0.6512 - accuracy: 0.7949\n",
      "Score for fold 1: loss of 0.6512315273284912; accuracy of 79.487544298172%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12810649\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.1-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass classes=[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], y=[6. 9. 9. ... 5. 1. 0.] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 1.5519 - accuracy: 0.4482\n",
      "Epoch 00001: val_loss improved from inf to 1.52417, saving model to ../models/CNN\\Model_012_2_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 1.5508 - accuracy: 0.4488 - val_loss: 1.5242 - val_accuracy: 0.4839\n",
      "Epoch 2/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 1.1827 - accuracy: 0.5871\n",
      "Epoch 00002: val_loss improved from 1.52417 to 1.10951, saving model to ../models/CNN\\Model_012_2_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 1.1812 - accuracy: 0.5876 - val_loss: 1.1095 - val_accuracy: 0.6212\n",
      "Epoch 3/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.9933 - accuracy: 0.6542\n",
      "Epoch 00003: val_loss did not improve from 1.10951\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.9933 - accuracy: 0.6541 - val_loss: 1.4825 - val_accuracy: 0.5308\n",
      "Epoch 4/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.8721 - accuracy: 0.6981\n",
      "Epoch 00004: val_loss improved from 1.10951 to 0.95850, saving model to ../models/CNN\\Model_012_2_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.8722 - accuracy: 0.6981 - val_loss: 0.9585 - val_accuracy: 0.6589\n",
      "Epoch 5/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7941 - accuracy: 0.7239\n",
      "Epoch 00005: val_loss improved from 0.95850 to 0.79923, saving model to ../models/CNN\\Model_012_2_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.7941 - accuracy: 0.7239 - val_loss: 0.7992 - val_accuracy: 0.7267\n",
      "Epoch 6/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.7147 - accuracy: 0.7525\n",
      "Epoch 00006: val_loss did not improve from 0.79923\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.7146 - accuracy: 0.7525 - val_loss: 0.9879 - val_accuracy: 0.6760\n",
      "Epoch 7/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.6772 - accuracy: 0.7656\n",
      "Epoch 00007: val_loss did not improve from 0.79923\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.6767 - accuracy: 0.7657 - val_loss: 0.9983 - val_accuracy: 0.6955\n",
      "Epoch 8/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.6240 - accuracy: 0.7825\n",
      "Epoch 00008: val_loss improved from 0.79923 to 0.79403, saving model to ../models/CNN\\Model_012_2_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.6239 - accuracy: 0.7823 - val_loss: 0.7940 - val_accuracy: 0.7368\n",
      "Epoch 9/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.5904 - accuracy: 0.7960\n",
      "Epoch 00009: val_loss did not improve from 0.79403\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.5905 - accuracy: 0.7959 - val_loss: 0.9546 - val_accuracy: 0.6987\n",
      "Epoch 10/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.5511 - accuracy: 0.8071\n",
      "Epoch 00010: val_loss improved from 0.79403 to 0.78005, saving model to ../models/CNN\\Model_012_2_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.5502 - accuracy: 0.8074 - val_loss: 0.7801 - val_accuracy: 0.7496\n",
      "Epoch 11/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.5261 - accuracy: 0.8160\n",
      "Epoch 00011: val_loss did not improve from 0.78005\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.5256 - accuracy: 0.8162 - val_loss: 0.8201 - val_accuracy: 0.7461\n",
      "Epoch 12/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.4888 - accuracy: 0.8281\n",
      "Epoch 00012: val_loss improved from 0.78005 to 0.71472, saving model to ../models/CNN\\Model_012_2_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.4888 - accuracy: 0.8281 - val_loss: 0.7147 - val_accuracy: 0.7671\n",
      "Epoch 13/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.4691 - accuracy: 0.8339\n",
      "Epoch 00013: val_loss did not improve from 0.71472\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.4695 - accuracy: 0.8340 - val_loss: 0.7330 - val_accuracy: 0.7698\n",
      "Epoch 14/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.4462 - accuracy: 0.8411\n",
      "Epoch 00014: val_loss improved from 0.71472 to 0.68133, saving model to ../models/CNN\\Model_012_2_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.4462 - accuracy: 0.8411 - val_loss: 0.6813 - val_accuracy: 0.7809\n",
      "Epoch 15/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.4209 - accuracy: 0.8492\n",
      "Epoch 00015: val_loss improved from 0.68133 to 0.67032, saving model to ../models/CNN\\Model_012_2_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.4211 - accuracy: 0.8492 - val_loss: 0.6703 - val_accuracy: 0.7840\n",
      "Epoch 16/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.3987 - accuracy: 0.8587\n",
      "Epoch 00016: val_loss did not improve from 0.67032\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.3989 - accuracy: 0.8588 - val_loss: 0.8150 - val_accuracy: 0.7482\n",
      "Epoch 17/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.3785 - accuracy: 0.8653\n",
      "Epoch 00017: val_loss did not improve from 0.67032\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.3780 - accuracy: 0.8656 - val_loss: 0.7007 - val_accuracy: 0.7909\n",
      "Epoch 18/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.3687 - accuracy: 0.8663\n",
      "Epoch 00018: val_loss did not improve from 0.67032\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.3688 - accuracy: 0.8663 - val_loss: 0.8255 - val_accuracy: 0.7590\n",
      "Epoch 00018: early stopping\n",
      "443/443 [==============================] - 1s 3ms/step - loss: 0.6704 - accuracy: 0.7839\n",
      "Score for fold 2: loss of 0.6704140305519104; accuracy of 78.386390209198%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12810649\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.1-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass classes=[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], y=[1. 1. 2. ... 6. 1. 1.] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 1.5337 - accuracy: 0.4617\n",
      "Epoch 00001: val_loss improved from inf to 1.58783, saving model to ../models/CNN\\Model_012_3_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 1.5339 - accuracy: 0.4620 - val_loss: 1.5878 - val_accuracy: 0.4253\n",
      "Epoch 2/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 1.1742 - accuracy: 0.5890\n",
      "Epoch 00002: val_loss improved from 1.58783 to 1.38599, saving model to ../models/CNN\\Model_012_3_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 1.1726 - accuracy: 0.5896 - val_loss: 1.3860 - val_accuracy: 0.5477\n",
      "Epoch 3/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.9945 - accuracy: 0.6538\n",
      "Epoch 00003: val_loss improved from 1.38599 to 0.97897, saving model to ../models/CNN\\Model_012_3_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.9940 - accuracy: 0.6542 - val_loss: 0.9790 - val_accuracy: 0.6647\n",
      "Epoch 4/400\n",
      "879/885 [============================>.] - ETA: 0s - loss: 0.8838 - accuracy: 0.6921\n",
      "Epoch 00004: val_loss improved from 0.97897 to 0.93198, saving model to ../models/CNN\\Model_012_3_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.8842 - accuracy: 0.6922 - val_loss: 0.9320 - val_accuracy: 0.6776\n",
      "Epoch 5/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.8030 - accuracy: 0.7213\n",
      "Epoch 00005: val_loss did not improve from 0.93198\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.8026 - accuracy: 0.7213 - val_loss: 1.0132 - val_accuracy: 0.6584\n",
      "Epoch 6/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.7272 - accuracy: 0.7474\n",
      "Epoch 00006: val_loss did not improve from 0.93198\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.7271 - accuracy: 0.7475 - val_loss: 0.9505 - val_accuracy: 0.7026\n",
      "Epoch 7/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.6665 - accuracy: 0.7667\n",
      "Epoch 00007: val_loss improved from 0.93198 to 0.79581, saving model to ../models/CNN\\Model_012_3_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.6664 - accuracy: 0.7667 - val_loss: 0.7958 - val_accuracy: 0.7327\n",
      "Epoch 8/400\n",
      "879/885 [============================>.] - ETA: 0s - loss: 0.6220 - accuracy: 0.7836\n",
      "Epoch 00008: val_loss improved from 0.79581 to 0.75958, saving model to ../models/CNN\\Model_012_3_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.6223 - accuracy: 0.7834 - val_loss: 0.7596 - val_accuracy: 0.7482\n",
      "Epoch 9/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.5848 - accuracy: 0.7958\n",
      "Epoch 00009: val_loss did not improve from 0.75958\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.5853 - accuracy: 0.7956 - val_loss: 0.8013 - val_accuracy: 0.7376\n",
      "Epoch 10/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.5505 - accuracy: 0.8050\n",
      "Epoch 00010: val_loss improved from 0.75958 to 0.73168, saving model to ../models/CNN\\Model_012_3_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.5500 - accuracy: 0.8053 - val_loss: 0.7317 - val_accuracy: 0.7559\n",
      "Epoch 11/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.5185 - accuracy: 0.8163\n",
      "Epoch 00011: val_loss did not improve from 0.73168\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.5184 - accuracy: 0.8164 - val_loss: 0.8514 - val_accuracy: 0.7446\n",
      "Epoch 12/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.4875 - accuracy: 0.8294\n",
      "Epoch 00012: val_loss improved from 0.73168 to 0.68453, saving model to ../models/CNN\\Model_012_3_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.4879 - accuracy: 0.8294 - val_loss: 0.6845 - val_accuracy: 0.7722\n",
      "Epoch 13/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.4664 - accuracy: 0.8340\n",
      "Epoch 00013: val_loss did not improve from 0.68453\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.4664 - accuracy: 0.8341 - val_loss: 0.8152 - val_accuracy: 0.7361\n",
      "Epoch 14/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.4402 - accuracy: 0.8433\n",
      "Epoch 00014: val_loss did not improve from 0.68453\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.4405 - accuracy: 0.8433 - val_loss: 0.7935 - val_accuracy: 0.7610\n",
      "Epoch 15/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.4211 - accuracy: 0.8507\n",
      "Epoch 00015: val_loss improved from 0.68453 to 0.66469, saving model to ../models/CNN\\Model_012_3_Best.hdf5\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.4207 - accuracy: 0.8507 - val_loss: 0.6647 - val_accuracy: 0.7863\n",
      "Epoch 16/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.3977 - accuracy: 0.8560\n",
      "Epoch 00016: val_loss did not improve from 0.66469\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.3973 - accuracy: 0.8562 - val_loss: 0.8655 - val_accuracy: 0.7537\n",
      "Epoch 17/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.3788 - accuracy: 0.8643\n",
      "Epoch 00017: val_loss did not improve from 0.66469\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.3790 - accuracy: 0.8641 - val_loss: 0.7642 - val_accuracy: 0.7763\n",
      "Epoch 18/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.3656 - accuracy: 0.8674\n",
      "Epoch 00018: val_loss did not improve from 0.66469\n",
      "885/885 [==============================] - 8s 9ms/step - loss: 0.3656 - accuracy: 0.8674 - val_loss: 0.6673 - val_accuracy: 0.7934\n",
      "Epoch 00018: early stopping\n",
      "443/443 [==============================] - 1s 3ms/step - loss: 0.6648 - accuracy: 0.7864\n",
      "Score for fold 3: loss of 0.6647743582725525; accuracy of 78.6389946937561%\n",
      "Wall time: 7min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "class_weights_arr = [] # for calc class weight \n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "cv_acc = 0\n",
    "cv_f1 = 0 \n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model02 = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model02.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "\n",
    "    x_train_ = x_train_removed[train_index]\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "\n",
    "    # calculate class weights\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                     np.unique(y_train_),\n",
    "                                                     y_train_)\n",
    "    class_weights_arr.append(class_weights)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    # one hot encoding\n",
    "    y_train_onehot = to_categorical(y_train_, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_012_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    # create generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=10,\n",
    "#     shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    "#     channel_shift_range=0.2\n",
    "    )\n",
    "\n",
    "    batch_size = 32\n",
    "    train_datagenerator = train_datagen.flow(x_train_, y_train_onehot, batch_size)\n",
    "    valid_datagenerator = ImageDataGenerator().flow(x_valid_, y_valid_onehot, batch_size)\n",
    "\n",
    "    model02_history = model02.fit_generator(train_datagenerator,\n",
    "                                  steps_per_epoch=int(len(x_train_)//batch_size),\n",
    "                                  epochs=400,\n",
    "                                  validation_data=valid_datagenerator,\n",
    "                                  validation_steps=int(len(x_valid_)//batch_size),\n",
    "                                  verbose=1,\n",
    "                                  shuffle=True,\n",
    "                                  class_weight=class_weights,\n",
    "                                  callbacks=[es_cb, cp_cb])\n",
    "\n",
    "    # inference\n",
    "    model02.load_weights(chkpt)\n",
    "    scores = model02.evaluate(x_valid_, y_valid_onehot)\n",
    "    \n",
    "    # CV value\n",
    "    cv_acc += scores[1]*100\n",
    "    y_valid_pred =  model02.predict(x_valid_)\n",
    "    y_valid_pred = np.argmax(y_valid_pred, axis=1)\n",
    "    cv_f1 += f1_score(y_valid_, y_valid_pred, average='macro')*100\n",
    "    \n",
    "    print(f'Score for fold {fold_no}: {model02.metrics_names[0]} of {scores[0]}; {model02.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    predict = model02.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model02_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.85007500750075, 1: 0.8498200359928014, 2: 1.7006602641056423, 3: 0.85007500750075, 4: 1.7006602641056423, 5: 0.8498200359928014, 6: 0.85007500750075, 7: 0.8498200359928014, 8: 0.85007500750075, 9: 1.6996400719856029}\n",
      "{0: 0.85007500750075, 1: 0.85007500750075, 2: 1.6996400719856029, 3: 0.8498200359928014, 4: 1.6996400719856029, 5: 0.85007500750075, 6: 0.85007500750075, 7: 0.85007500750075, 8: 0.85007500750075, 9: 1.6996400719856029}\n",
      "{0: 0.8498500299940012, 1: 0.8501050105010501, 2: 1.6997000599880023, 3: 0.8501050105010501, 4: 1.6997000599880023, 5: 0.8501050105010501, 6: 0.8498500299940012, 7: 0.8501050105010501, 8: 0.8498500299940012, 9: 1.7007202881152461}\n"
     ]
    }
   ],
   "source": [
    "# print classs weight\n",
    "ensemble_dataaug_class_weights_arr = class_weights_arr\n",
    "for class_weight_ in ensemble_dataaug_class_weights_arr:\n",
    "    print(dict(enumerate(class_weight_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1000\n",
      "           1       0.87      0.94      0.91      1000\n",
      "           2       0.81      0.64      0.71      1000\n",
      "           3       0.66      0.67      0.66      1000\n",
      "           4       0.86      0.67      0.76      1000\n",
      "           5       0.80      0.71      0.75      1000\n",
      "           6       0.74      0.91      0.82      1000\n",
      "           7       0.78      0.90      0.84      1000\n",
      "           8       0.85      0.93      0.89      1000\n",
      "           9       0.90      0.86      0.88      1000\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.81      0.81      0.80     10000\n",
      "weighted avg       0.81      0.81      0.80     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_dataaug_histories = histories\n",
    "ensemble_dataaug_predicts = predicts\n",
    "ensemble_dataaug_predicts_ = ensemble_dataaug_predicts / n_splits\n",
    "y_pred = np.argmax(ensemble_dataaug_predicts_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ACC is 78.0,n_splits CV macro F1 is 77.0\n"
     ]
    }
   ],
   "source": [
    "print(f'CV ACC is {cv_acc//n_splits},n_splits CV macro F1 is {cv_f1//n_splits}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
