{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_randvalue(value):\n",
    "    # Set a seed value\n",
    "    seed_value= value \n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "set_randvalue(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() # load data\n",
    "x_train,x_test = x_train.astype('float32')/255.0,x_test.astype('float32')/255.0 # normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit three class preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird label num is 2500\n",
      "Deer label num is 2500\n",
      "Truck label num is 2500\n",
      "Other label num is 35000\n",
      "Train label num is 42500\n",
      "(42500, 32, 32, 3)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "# No method on keras to get cifar10 category label name by categoly label?\n",
    "cifar10_labels = np.array([\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'])\n",
    "\n",
    "bird_num = np.where(cifar10_labels=='bird')\n",
    "deer_num = np.where(cifar10_labels=='deer')\n",
    "truck_num = np.where(cifar10_labels=='truck')\n",
    "\n",
    "limit_num = 2500\n",
    "\n",
    "# get limit label indexes\n",
    "bird_indexes = [i for i, label in enumerate(y_train) if label == bird_num]\n",
    "deer_indexes = [i for i, label in enumerate(y_train) if label == deer_num] \n",
    "truck_indexes = [i for i, label in enumerate(y_train) if label == truck_num] \n",
    "other_indexes = [i for i, label in enumerate(y_train) if label not in [bird_num, deer_num, truck_num]]\n",
    "\n",
    "# limit\n",
    "bird_indexes = bird_indexes[:limit_num]\n",
    "deer_indexes = deer_indexes[:limit_num]\n",
    "truck_indexes = truck_indexes[:limit_num]\n",
    "print(f'Bird label num is {len(bird_indexes)}') # 2500\n",
    "print(f'Deer label num is {len(deer_indexes)}') # 2500\n",
    "print(f'Truck label num is {len(truck_indexes)}') # 2500\n",
    "print(f'Other label num is {len(other_indexes)}') # 35000; 5000*7\n",
    "\n",
    "# merge and sort\n",
    "merge_indexes = np.concatenate([other_indexes, bird_indexes, deer_indexes, truck_indexes], 0)\n",
    "merge_indexes.sort()\n",
    "print(f'Train label num is {len(merge_indexes)}') # 42500\n",
    "\n",
    "# create three labels removed train data\n",
    "x_train_removed =  np.zeros((len(merge_indexes), 32, 32, 3))\n",
    "y_train_removed =  np.zeros(len(merge_indexes))\n",
    "\n",
    "for i, train_index in enumerate(merge_indexes):\n",
    "    x_train_removed[i] = x_train[train_index]\n",
    "    y_train_removed[i] = y_train[train_index]\n",
    "    \n",
    "print(x_train_removed.shape)\n",
    "print(y_train_removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42500, 32, 32, 3)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_removed.shape)\n",
    "print(y_train_removed.shape)\n",
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0    5000\n",
      "7.0    5000\n",
      "6.0    5000\n",
      "5.0    5000\n",
      "3.0    5000\n",
      "1.0    5000\n",
      "0.0    5000\n",
      "9.0    2500\n",
      "4.0    2500\n",
      "2.0    2500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(y_train_removed.flatten())\n",
    "print(df.value_counts())\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5000., 5000., 2500., 5000., 2500., 5000., 5000., 5000., 5000.,\n",
       "        2500.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot data labels\n",
    "plt.hist(y_train_removed.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load AE models weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Norm Model\n",
    "def create_AE01_model(k_size):\n",
    "    input_img = Input(shape=(32, 32, 3))  # 0\n",
    "    conv1 = Conv2D(64, (k_size, k_size), padding='same', name=\"Dense_AE01_1\")(input_img) # 1\n",
    "    conv1 = BatchNormalization(name=\"BN_AE01_1\")(conv1) # 2\n",
    "    conv1 = Activation('relu', name=\"Relu_AE01_1\")(conv1) # 3\n",
    "        \n",
    "    decoded = Conv2D(3, (k_size, k_size), padding='same', name=\"Dense_AE01_2\")(conv1) # 4\n",
    "    decoded = BatchNormalization(name=\"BN_AE01_2\")(decoded) # 5\n",
    "    decoded = Activation('relu', name=\"Relu_AE01_2\")(decoded) # 6\n",
    "    return Model(input_img, decoded)\n",
    "\n",
    "class AE01():\n",
    "    def __init__(self, ksize, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.autoencoder = create_AE01_model(ksize)\n",
    "        self.encoder = None\n",
    "\n",
    "    def compile(self, optimizer='adam', loss='binary_crossentropy'):\n",
    "        self.autoencoder.compile(optimizer=self.optimizer, loss=loss)\n",
    "\n",
    "    def train(self, x_train=None, x_test=None, epochs=1, batch_size=32, shuffle=True):\n",
    "        es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "        ae_model_path = '../models/AE/AE01_AE_Best.hdf5'\n",
    "        cp_cb = ModelCheckpoint(filepath = ae_model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "       \n",
    "        history = self.autoencoder.fit(x_train, x_train,\n",
    "                             epochs=epochs,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=shuffle,\n",
    "                             callbacks=[es_cb, cp_cb],\n",
    "                             validation_data=(x_test, x_test))\n",
    "        \n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        \n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        encode_model_path = '../models/AE/AE01_Encoder_Best.hdf5'\n",
    "        self.encoder.save(encode_model_path)\n",
    "        return history\n",
    "    \n",
    "    def load_weights(self, ae_model_path, encode_model_path):\n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        self.encoder.load_weights(encode_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "Dense_AE01_1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "BN_AE01_1 (BatchNormalizatio (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "Relu_AE01_1 (Activation)     (None, 32, 32, 64)        0         \n",
      "=================================================================\n",
      "Total params: 2,048\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_ksize = 3\n",
    "ae_optimizer = 'rmsprop'\n",
    "stack01 = AE01(ae_ksize, ae_optimizer)\n",
    "stack01.load_weights('../models/AE/AE01_AE_Best.hdf5', '../models/AE/AE01_Encoder_Best.hdf5')\n",
    "stack01.encoder.trainable = False\n",
    "stack01.encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model AE to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_StackedAE01_CNN01_model(encoder):\n",
    "    input_img = encoder.input\n",
    "    output = encoder.layers[-1].output # 32,32,64\n",
    "    x = Conv2D(64,(3,3),padding = \"same\",activation= \"relu\")(output) # 2\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64,(3,3),padding = \"same\",activation= \"relu\")(x) # 3\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64,(3,3),padding = \"same\",activation= \"relu\")(x) # 4\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) # 16,16,64\n",
    "    \n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x) # 5\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x) # 6\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x) # 7\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) # 8,8,128\n",
    "\n",
    "    x = Conv2D(256,(3,3),padding = \"same\",activation= \"relu\")(x) # 8\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(256,(3,3),padding = \"same\",activation= \"relu\")(x) # 9\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(256,(3,3),padding = \"same\",activation= \"relu\")(x) # 10\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256)(x) # 11\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    y = Dense(10,activation = \"softmax\")(x) # 12\n",
    "\n",
    "    return Model(input_img, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with data augumentation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixupGenerator():\n",
    "    def __init__(self, X_train, y_train, batch_size=32, alpha=0.2, shuffle=True, datagen=None):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.shuffle = shuffle\n",
    "        self.sample_num = len(X_train)\n",
    "        self.datagen = datagen\n",
    "\n",
    "    def __call__(self):\n",
    "        while True:\n",
    "            indexes = self.__get_exploration_order()\n",
    "            itr_num = int(len(indexes) // (self.batch_size * 2))\n",
    "\n",
    "            for i in range(itr_num):\n",
    "                batch_ids = indexes[i * self.batch_size * 2:(i + 1) * self.batch_size * 2]\n",
    "                X, y = self.__data_generation(batch_ids)\n",
    "\n",
    "                yield X, y\n",
    "\n",
    "    def __get_exploration_order(self):\n",
    "        indexes = np.arange(self.sample_num)\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(indexes)\n",
    "\n",
    "        return indexes\n",
    "\n",
    "    def __data_generation(self, batch_ids):\n",
    "        _, h, w, c = self.X_train.shape\n",
    "        l = np.random.beta(self.alpha, self.alpha, self.batch_size)\n",
    "        X_l = l.reshape(self.batch_size, 1, 1, 1)\n",
    "        y_l = l.reshape(self.batch_size, 1)\n",
    "\n",
    "        X1 = self.X_train[batch_ids[:self.batch_size]]\n",
    "        X2 = self.X_train[batch_ids[self.batch_size:]]\n",
    "        X = X1 * X_l + X2 * (1 - X_l)\n",
    "\n",
    "        if self.datagen:\n",
    "            for i in range(self.batch_size):\n",
    "                X[i] = self.datagen.random_transform(X[i])\n",
    "                X[i] = self.datagen.standardize(X[i])\n",
    "\n",
    "        if isinstance(self.y_train, list):\n",
    "            y = []\n",
    "\n",
    "            for y_train_ in self.y_train:\n",
    "                y1 = y_train_[batch_ids[:self.batch_size]]\n",
    "                y2 = y_train_[batch_ids[self.batch_size:]]\n",
    "                y.append(y1 * y_l + y2 * (1 - y_l))\n",
    "        else:\n",
    "            y1 = self.y_train[batch_ids[:self.batch_size]]\n",
    "            y2 = self.y_train[batch_ids[self.batch_size:]]\n",
    "            y = y1 * y_l + y2 * (1 - y_l)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-d2d330a94622>:72: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 1.7231 - accuracy: 0.4147\n",
      "Epoch 00001: val_loss improved from inf to 1.58918, saving model to ../models/CNN\\Model_032_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.7223 - accuracy: 0.4150 - val_loss: 1.5892 - val_accuracy: 0.4797\n",
      "Epoch 2/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 1.4110 - accuracy: 0.5594\n",
      "Epoch 00002: val_loss improved from 1.58918 to 1.08451, saving model to ../models/CNN\\Model_032_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.4112 - accuracy: 0.5595 - val_loss: 1.0845 - val_accuracy: 0.6173\n",
      "Epoch 3/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 1.2210 - accuracy: 0.6391\n",
      "Epoch 00003: val_loss did not improve from 1.08451\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.2210 - accuracy: 0.6391 - val_loss: 1.4739 - val_accuracy: 0.5450\n",
      "Epoch 4/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 1.1080 - accuracy: 0.6926\n",
      "Epoch 00004: val_loss improved from 1.08451 to 0.97327, saving model to ../models/CNN\\Model_032_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.1079 - accuracy: 0.6928 - val_loss: 0.9733 - val_accuracy: 0.6819\n",
      "Epoch 5/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 1.0149 - accuracy: 0.7301\n",
      "Epoch 00005: val_loss improved from 0.97327 to 0.84460, saving model to ../models/CNN\\Model_032_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.0148 - accuracy: 0.7299 - val_loss: 0.8446 - val_accuracy: 0.7159\n",
      "Epoch 6/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.9615 - accuracy: 0.7511\n",
      "Epoch 00006: val_loss did not improve from 0.84460\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.9611 - accuracy: 0.7512 - val_loss: 0.8468 - val_accuracy: 0.7173\n",
      "Epoch 7/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.9069 - accuracy: 0.7747\n",
      "Epoch 00007: val_loss improved from 0.84460 to 0.76592, saving model to ../models/CNN\\Model_032_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.9068 - accuracy: 0.7748 - val_loss: 0.7659 - val_accuracy: 0.7535\n",
      "Epoch 8/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.8737 - accuracy: 0.7904\n",
      "Epoch 00008: val_loss improved from 0.76592 to 0.63573, saving model to ../models/CNN\\Model_032_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.8735 - accuracy: 0.7905 - val_loss: 0.6357 - val_accuracy: 0.7919\n",
      "Epoch 9/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.8329 - accuracy: 0.8032\n",
      "Epoch 00009: val_loss improved from 0.63573 to 0.57382, saving model to ../models/CNN\\Model_032_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.8330 - accuracy: 0.8031 - val_loss: 0.5738 - val_accuracy: 0.8061\n",
      "Epoch 10/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.8062 - accuracy: 0.8179\n",
      "Epoch 00010: val_loss improved from 0.57382 to 0.55725, saving model to ../models/CNN\\Model_032_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.8062 - accuracy: 0.8180 - val_loss: 0.5572 - val_accuracy: 0.8137\n",
      "Epoch 11/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.7745 - accuracy: 0.8294\n",
      "Epoch 00011: val_loss improved from 0.55725 to 0.53916, saving model to ../models/CNN\\Model_032_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7752 - accuracy: 0.8294 - val_loss: 0.5392 - val_accuracy: 0.8223\n",
      "Epoch 12/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.7542 - accuracy: 0.8374\n",
      "Epoch 00012: val_loss improved from 0.53916 to 0.51849, saving model to ../models/CNN\\Model_032_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7544 - accuracy: 0.8374 - val_loss: 0.5185 - val_accuracy: 0.8297\n",
      "Epoch 13/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.7286 - accuracy: 0.8485\n",
      "Epoch 00013: val_loss improved from 0.51849 to 0.48749, saving model to ../models/CNN\\Model_032_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7284 - accuracy: 0.8485 - val_loss: 0.4875 - val_accuracy: 0.8438\n",
      "Epoch 14/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.7075 - accuracy: 0.8557\n",
      "Epoch 00014: val_loss improved from 0.48749 to 0.46600, saving model to ../models/CNN\\Model_032_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7077 - accuracy: 0.8556 - val_loss: 0.4660 - val_accuracy: 0.8470\n",
      "Epoch 15/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.8670\n",
      "Epoch 00015: val_loss did not improve from 0.46600\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6828 - accuracy: 0.8670 - val_loss: 0.4894 - val_accuracy: 0.8445\n",
      "Epoch 16/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.6692 - accuracy: 0.8729\n",
      "Epoch 00016: val_loss did not improve from 0.46600\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6687 - accuracy: 0.8731 - val_loss: 0.4884 - val_accuracy: 0.8424\n",
      "Epoch 17/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.6551 - accuracy: 0.8780\n",
      "Epoch 00017: val_loss did not improve from 0.46600\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6549 - accuracy: 0.8779 - val_loss: 0.4785 - val_accuracy: 0.8493\n",
      "Epoch 00017: early stopping\n",
      "443/443 [==============================] - 2s 4ms/step - loss: 0.4667 - accuracy: 0.8468\n",
      "Score for fold 1: loss of 0.4667494297027588; accuracy of 84.68271493911743%\n",
      "Epoch 1/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 1.7167 - accuracy: 0.4160\n",
      "Epoch 00001: val_loss improved from inf to 1.40278, saving model to ../models/CNN\\Model_032_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 12ms/step - loss: 1.7163 - accuracy: 0.4162 - val_loss: 1.4028 - val_accuracy: 0.5072\n",
      "Epoch 2/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 1.4079 - accuracy: 0.5546\n",
      "Epoch 00002: val_loss improved from 1.40278 to 1.39564, saving model to ../models/CNN\\Model_032_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.4078 - accuracy: 0.5544 - val_loss: 1.3956 - val_accuracy: 0.5090\n",
      "Epoch 3/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.2179 - accuracy: 0.6395\n",
      "Epoch 00003: val_loss improved from 1.39564 to 1.09668, saving model to ../models/CNN\\Model_032_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.2179 - accuracy: 0.6395 - val_loss: 1.0967 - val_accuracy: 0.6312\n",
      "Epoch 4/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.0930 - accuracy: 0.6955\n",
      "Epoch 00004: val_loss improved from 1.09668 to 0.86043, saving model to ../models/CNN\\Model_032_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.0930 - accuracy: 0.6955 - val_loss: 0.8604 - val_accuracy: 0.6970\n",
      "Epoch 5/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 1.0134 - accuracy: 0.7304\n",
      "Epoch 00005: val_loss did not improve from 0.86043\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.0136 - accuracy: 0.7303 - val_loss: 0.8670 - val_accuracy: 0.7124\n",
      "Epoch 6/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.9551 - accuracy: 0.7572\n",
      "Epoch 00006: val_loss improved from 0.86043 to 0.65915, saving model to ../models/CNN\\Model_032_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.9546 - accuracy: 0.7575 - val_loss: 0.6592 - val_accuracy: 0.7767\n",
      "Epoch 7/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8998 - accuracy: 0.7769\n",
      "Epoch 00007: val_loss did not improve from 0.65915\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.8998 - accuracy: 0.7769 - val_loss: 0.7511 - val_accuracy: 0.7591\n",
      "Epoch 8/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "883/885 [============================>.] - ETA: 0s - loss: 0.8560 - accuracy: 0.7973\n",
      "Epoch 00008: val_loss improved from 0.65915 to 0.62550, saving model to ../models/CNN\\Model_032_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.8558 - accuracy: 0.7973 - val_loss: 0.6255 - val_accuracy: 0.7926\n",
      "Epoch 9/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.8223 - accuracy: 0.8101\n",
      "Epoch 00009: val_loss improved from 0.62550 to 0.58816, saving model to ../models/CNN\\Model_032_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.8224 - accuracy: 0.8101 - val_loss: 0.5882 - val_accuracy: 0.8042\n",
      "Epoch 10/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.8091 - accuracy: 0.8165\n",
      "Epoch 00010: val_loss did not improve from 0.58816\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.8084 - accuracy: 0.8168 - val_loss: 0.6422 - val_accuracy: 0.7981\n",
      "Epoch 11/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.7758 - accuracy: 0.8286\n",
      "Epoch 00011: val_loss did not improve from 0.58816\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7750 - accuracy: 0.8288 - val_loss: 0.7307 - val_accuracy: 0.7639\n",
      "Epoch 12/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7418 - accuracy: 0.8428\n",
      "Epoch 00012: val_loss improved from 0.58816 to 0.52673, saving model to ../models/CNN\\Model_032_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7418 - accuracy: 0.8428 - val_loss: 0.5267 - val_accuracy: 0.8297\n",
      "Epoch 13/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.7195 - accuracy: 0.8522\n",
      "Epoch 00013: val_loss did not improve from 0.52673\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7192 - accuracy: 0.8523 - val_loss: 0.5831 - val_accuracy: 0.8112\n",
      "Epoch 14/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.7122 - accuracy: 0.8564\n",
      "Epoch 00014: val_loss improved from 0.52673 to 0.46798, saving model to ../models/CNN\\Model_032_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7121 - accuracy: 0.8566 - val_loss: 0.4680 - val_accuracy: 0.8448\n",
      "Epoch 15/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.8669\n",
      "Epoch 00015: val_loss did not improve from 0.46798\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6880 - accuracy: 0.8669 - val_loss: 0.5019 - val_accuracy: 0.8365\n",
      "Epoch 16/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6686 - accuracy: 0.8731\n",
      "Epoch 00016: val_loss did not improve from 0.46798\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6686 - accuracy: 0.8731 - val_loss: 0.4739 - val_accuracy: 0.8493\n",
      "Epoch 17/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.6560 - accuracy: 0.8777\n",
      "Epoch 00017: val_loss did not improve from 0.46798\n",
      "885/885 [==============================] - 11s 12ms/step - loss: 0.6558 - accuracy: 0.8778 - val_loss: 0.6590 - val_accuracy: 0.7977\n",
      "Epoch 00017: early stopping\n",
      "443/443 [==============================] - 2s 4ms/step - loss: 0.4683 - accuracy: 0.8446\n",
      "Score for fold 2: loss of 0.46829721331596375; accuracy of 84.46389436721802%\n",
      "Epoch 1/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 1.7298 - accuracy: 0.4074\n",
      "Epoch 00001: val_loss improved from inf to 1.64175, saving model to ../models/CNN\\Model_032_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.7297 - accuracy: 0.4074 - val_loss: 1.6417 - val_accuracy: 0.4555\n",
      "Epoch 2/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 1.4310 - accuracy: 0.5424\n",
      "Epoch 00002: val_loss improved from 1.64175 to 1.33768, saving model to ../models/CNN\\Model_032_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.4299 - accuracy: 0.5426 - val_loss: 1.3377 - val_accuracy: 0.5409\n",
      "Epoch 3/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 1.2264 - accuracy: 0.6354\n",
      "Epoch 00003: val_loss did not improve from 1.33768\n",
      "885/885 [==============================] - 10s 12ms/step - loss: 1.2267 - accuracy: 0.6353 - val_loss: 1.4882 - val_accuracy: 0.5355\n",
      "Epoch 4/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.1130 - accuracy: 0.6860\n",
      "Epoch 00004: val_loss improved from 1.33768 to 0.85327, saving model to ../models/CNN\\Model_032_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 12ms/step - loss: 1.1130 - accuracy: 0.6860 - val_loss: 0.8533 - val_accuracy: 0.7156\n",
      "Epoch 5/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 1.0170 - accuracy: 0.7294\n",
      "Epoch 00005: val_loss improved from 0.85327 to 0.77529, saving model to ../models/CNN\\Model_032_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.0168 - accuracy: 0.7296 - val_loss: 0.7753 - val_accuracy: 0.7421\n",
      "Epoch 6/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.9532 - accuracy: 0.7561\n",
      "Epoch 00006: val_loss did not improve from 0.77529\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.9525 - accuracy: 0.7563 - val_loss: 0.8383 - val_accuracy: 0.7197\n",
      "Epoch 7/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.9109 - accuracy: 0.7715\n",
      "Epoch 00007: val_loss improved from 0.77529 to 0.61777, saving model to ../models/CNN\\Model_032_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 12ms/step - loss: 0.9110 - accuracy: 0.7716 - val_loss: 0.6178 - val_accuracy: 0.7979\n",
      "Epoch 8/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.8639 - accuracy: 0.7913\n",
      "Epoch 00008: val_loss did not improve from 0.61777\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.8638 - accuracy: 0.7913 - val_loss: 0.6872 - val_accuracy: 0.7750\n",
      "Epoch 9/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.8319 - accuracy: 0.8047\n",
      "Epoch 00009: val_loss improved from 0.61777 to 0.57928, saving model to ../models/CNN\\Model_032_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.8316 - accuracy: 0.8047 - val_loss: 0.5793 - val_accuracy: 0.8138\n",
      "Epoch 10/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8001 - accuracy: 0.8195\n",
      "Epoch 00010: val_loss improved from 0.57928 to 0.56163, saving model to ../models/CNN\\Model_032_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 12ms/step - loss: 0.8001 - accuracy: 0.8195 - val_loss: 0.5616 - val_accuracy: 0.8182\n",
      "Epoch 11/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.7787 - accuracy: 0.8271\n",
      "Epoch 00011: val_loss improved from 0.56163 to 0.51243, saving model to ../models/CNN\\Model_032_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7787 - accuracy: 0.8271 - val_loss: 0.5124 - val_accuracy: 0.8349\n",
      "Epoch 12/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.7460 - accuracy: 0.8400\n",
      "Epoch 00012: val_loss did not improve from 0.51243\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7463 - accuracy: 0.8398 - val_loss: 0.5591 - val_accuracy: 0.8153\n",
      "Epoch 13/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.7243 - accuracy: 0.8488\n",
      "Epoch 00013: val_loss improved from 0.51243 to 0.47554, saving model to ../models/CNN\\Model_032_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 12ms/step - loss: 0.7245 - accuracy: 0.8487 - val_loss: 0.4755 - val_accuracy: 0.8495\n",
      "Epoch 14/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.7035 - accuracy: 0.8586\n",
      "Epoch 00014: val_loss improved from 0.47554 to 0.44506, saving model to ../models/CNN\\Model_032_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7039 - accuracy: 0.8586 - val_loss: 0.4451 - val_accuracy: 0.8544\n",
      "Epoch 15/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.6873 - accuracy: 0.8663\n",
      "Epoch 00015: val_loss did not improve from 0.44506\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6871 - accuracy: 0.8664 - val_loss: 0.4794 - val_accuracy: 0.8433\n",
      "Epoch 16/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.6699 - accuracy: 0.8726\n",
      "Epoch 00016: val_loss did not improve from 0.44506\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6702 - accuracy: 0.8725 - val_loss: 0.4563 - val_accuracy: 0.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.6511 - accuracy: 0.8794\n",
      "Epoch 00017: val_loss did not improve from 0.44506\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6511 - accuracy: 0.8795 - val_loss: 0.4593 - val_accuracy: 0.8548\n",
      "Epoch 00017: early stopping\n",
      "443/443 [==============================] - 2s 4ms/step - loss: 0.4449 - accuracy: 0.8544\n",
      "Score for fold 3: loss of 0.4448539912700653; accuracy of 85.43696403503418%\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "cv_acc = 0\n",
    "cv_f1 = 0\n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "\n",
    "    x_train_ = x_train_removed[train_index]\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "\n",
    "    # one hot encoding\n",
    "    y_train_onehot = to_categorical(y_train_, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_032_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    # create generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         rotation_range=10,\n",
    "#         shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "#         vertical_flip=True,\n",
    "#         width_shift_range=0.1,\n",
    "#         height_shift_range=0.1,\n",
    "        zoom_range=0.1\n",
    "#         channel_shift_range=0.2\n",
    "        )\n",
    "    \n",
    "    #Mixup augumentation\n",
    "    batch_size = 32\n",
    "    train_datagenerator = MixupGenerator(x_train_, y_train_onehot, batch_size=batch_size, \n",
    "                                        alpha=0.2, datagen=train_datagen)()    \n",
    "#     train_datagenerator = train_datagen.flow(x_train_, y_train_onehot, batch_size)\n",
    "    valid_datagenerator = ImageDataGenerator().flow(x_valid_, y_valid_onehot, batch_size)\n",
    "\n",
    "    model_history = model.fit_generator(train_datagenerator,\n",
    "                                  steps_per_epoch=int(len(x_train_)//batch_size),\n",
    "                                  epochs=400,\n",
    "                                  validation_data=valid_datagenerator,\n",
    "                                  validation_steps=int(len(x_valid_)//batch_size),\n",
    "                                  verbose=1,\n",
    "                                  shuffle=True,\n",
    "                                  callbacks=[es_cb, cp_cb])\n",
    "\n",
    "    # inference\n",
    "    model.load_weights(chkpt)\n",
    "    scores = model.evaluate(x_valid_, y_valid_onehot)\n",
    "    \n",
    "    # CV value\n",
    "    cv_acc += scores[1]*100\n",
    "    y_valid_pred =  model.predict(x_valid_)\n",
    "    y_valid_pred = np.argmax(y_valid_pred, axis=1)\n",
    "    cv_f1 += f1_score(y_valid_, y_valid_pred, average='macro')*100\n",
    "    \n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    predict = model.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      1000\n",
      "           1       0.94      0.95      0.95      1000\n",
      "           2       0.91      0.71      0.80      1000\n",
      "           3       0.78      0.78      0.78      1000\n",
      "           4       0.87      0.83      0.85      1000\n",
      "           5       0.85      0.80      0.82      1000\n",
      "           6       0.80      0.96      0.87      1000\n",
      "           7       0.90      0.93      0.91      1000\n",
      "           8       0.94      0.94      0.94      1000\n",
      "           9       0.95      0.90      0.92      1000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.88      0.87      0.87     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_dataaug_histories = histories\n",
    "ensemble_dataaug_predicts = predicts\n",
    "ensemble_dataaug_predicts_ = ensemble_dataaug_predicts / n_splits\n",
    "y_pred = np.argmax(ensemble_dataaug_predicts_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ACC is 84.0,n_splits CV macro F1 is 83.0\n"
     ]
    }
   ],
   "source": [
    "print(f'CV ACC is {cv_acc//n_splits},n_splits CV macro F1 is {cv_f1//n_splits}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with data augumentation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 1.6005 - accuracy: 0.4238\n",
      "Epoch 00001: val_loss improved from inf to 1.67438, saving model to ../models/CNN\\Model_033_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 12ms/step - loss: 1.6002 - accuracy: 0.4239 - val_loss: 1.6744 - val_accuracy: 0.4445\n",
      "Epoch 2/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.2228 - accuracy: 0.5654\n",
      "Epoch 00002: val_loss improved from 1.67438 to 1.46659, saving model to ../models/CNN\\Model_033_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.2228 - accuracy: 0.5654 - val_loss: 1.4666 - val_accuracy: 0.5279\n",
      "Epoch 3/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.0036 - accuracy: 0.6503\n",
      "Epoch 00003: val_loss improved from 1.46659 to 1.02725, saving model to ../models/CNN\\Model_033_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.0036 - accuracy: 0.6503 - val_loss: 1.0273 - val_accuracy: 0.6442\n",
      "Epoch 4/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.8576 - accuracy: 0.7063\n",
      "Epoch 00004: val_loss improved from 1.02725 to 0.95766, saving model to ../models/CNN\\Model_033_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.8576 - accuracy: 0.7064 - val_loss: 0.9577 - val_accuracy: 0.6758\n",
      "Epoch 5/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7546 - accuracy: 0.7429\n",
      "Epoch 00005: val_loss did not improve from 0.95766\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7546 - accuracy: 0.7429 - val_loss: 1.1148 - val_accuracy: 0.6544\n",
      "Epoch 6/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.7702\n",
      "Epoch 00006: val_loss improved from 0.95766 to 0.77509, saving model to ../models/CNN\\Model_033_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6696 - accuracy: 0.7704 - val_loss: 0.7751 - val_accuracy: 0.7438\n",
      "Epoch 7/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.6173 - accuracy: 0.7903\n",
      "Epoch 00007: val_loss improved from 0.77509 to 0.65039, saving model to ../models/CNN\\Model_033_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6171 - accuracy: 0.7903 - val_loss: 0.6504 - val_accuracy: 0.7874\n",
      "Epoch 8/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.5594 - accuracy: 0.8089\n",
      "Epoch 00008: val_loss improved from 0.65039 to 0.56560, saving model to ../models/CNN\\Model_033_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.5592 - accuracy: 0.8090 - val_loss: 0.5656 - val_accuracy: 0.8071\n",
      "Epoch 9/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.5210 - accuracy: 0.8212\n",
      "Epoch 00009: val_loss improved from 0.56560 to 0.54966, saving model to ../models/CNN\\Model_033_1_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.5205 - accuracy: 0.8214 - val_loss: 0.5497 - val_accuracy: 0.8162\n",
      "Epoch 10/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.4836 - accuracy: 0.8332\n",
      "Epoch 00010: val_loss did not improve from 0.54966\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.4834 - accuracy: 0.8334 - val_loss: 0.6347 - val_accuracy: 0.7947\n",
      "Epoch 11/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.4490 - accuracy: 0.8443\n",
      "Epoch 00011: val_loss did not improve from 0.54966\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.4486 - accuracy: 0.8444 - val_loss: 0.6002 - val_accuracy: 0.8124\n",
      "Epoch 12/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.4200 - accuracy: 0.8564\n",
      "Epoch 00012: val_loss did not improve from 0.54966\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.4198 - accuracy: 0.8564 - val_loss: 0.5893 - val_accuracy: 0.8063\n",
      "Epoch 00012: early stopping\n",
      "443/443 [==============================] - 2s 4ms/step - loss: 0.5498 - accuracy: 0.8161\n",
      "Score for fold 1: loss of 0.5497989058494568; accuracy of 81.61219954490662%\n",
      "Epoch 1/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 1.6347 - accuracy: 0.4114\n",
      "Epoch 00001: val_loss improved from inf to 1.49826, saving model to ../models/CNN\\Model_033_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 12ms/step - loss: 1.6347 - accuracy: 0.4114 - val_loss: 1.4983 - val_accuracy: 0.4834\n",
      "Epoch 2/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 1.2607 - accuracy: 0.5519\n",
      "Epoch 00002: val_loss improved from 1.49826 to 1.28295, saving model to ../models/CNN\\Model_033_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.2601 - accuracy: 0.5521 - val_loss: 1.2830 - val_accuracy: 0.5757\n",
      "Epoch 3/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 1.0247 - accuracy: 0.6438\n",
      "Epoch 00003: val_loss improved from 1.28295 to 0.99657, saving model to ../models/CNN\\Model_033_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.0248 - accuracy: 0.6438 - val_loss: 0.9966 - val_accuracy: 0.6582\n",
      "Epoch 4/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.8624 - accuracy: 0.7032\n",
      "Epoch 00004: val_loss improved from 0.99657 to 0.92867, saving model to ../models/CNN\\Model_033_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.8612 - accuracy: 0.7038 - val_loss: 0.9287 - val_accuracy: 0.6909\n",
      "Epoch 5/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.7583 - accuracy: 0.7428\n",
      "Epoch 00005: val_loss improved from 0.92867 to 0.85669, saving model to ../models/CNN\\Model_033_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7582 - accuracy: 0.7428 - val_loss: 0.8567 - val_accuracy: 0.7015\n",
      "Epoch 6/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.7680\n",
      "Epoch 00006: val_loss improved from 0.85669 to 0.73907, saving model to ../models/CNN\\Model_033_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6709 - accuracy: 0.7683 - val_loss: 0.7391 - val_accuracy: 0.7513\n",
      "Epoch 7/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.6084 - accuracy: 0.7901\n",
      "Epoch 00007: val_loss improved from 0.73907 to 0.72525, saving model to ../models/CNN\\Model_033_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6085 - accuracy: 0.7900 - val_loss: 0.7253 - val_accuracy: 0.7576\n",
      "Epoch 8/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.5542 - accuracy: 0.8077\n",
      "Epoch 00008: val_loss improved from 0.72525 to 0.55682, saving model to ../models/CNN\\Model_033_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.5537 - accuracy: 0.8079 - val_loss: 0.5568 - val_accuracy: 0.8086\n",
      "Epoch 9/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.5125 - accuracy: 0.8230\n",
      "Epoch 00009: val_loss did not improve from 0.55682\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.5126 - accuracy: 0.8228 - val_loss: 0.6238 - val_accuracy: 0.7911\n",
      "Epoch 10/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.4763 - accuracy: 0.8349\n",
      "Epoch 00010: val_loss improved from 0.55682 to 0.52272, saving model to ../models/CNN\\Model_033_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.4760 - accuracy: 0.8350 - val_loss: 0.5227 - val_accuracy: 0.8278\n",
      "Epoch 11/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.4512 - accuracy: 0.8457\n",
      "Epoch 00011: val_loss did not improve from 0.52272\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.4508 - accuracy: 0.8459 - val_loss: 0.5694 - val_accuracy: 0.8150\n",
      "Epoch 12/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.4187 - accuracy: 0.8576\n",
      "Epoch 00012: val_loss did not improve from 0.52272\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.4183 - accuracy: 0.8576 - val_loss: 0.6783 - val_accuracy: 0.7839\n",
      "Epoch 13/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8649\n",
      "Epoch 00013: val_loss improved from 0.52272 to 0.51759, saving model to ../models/CNN\\Model_033_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.3875 - accuracy: 0.8653 - val_loss: 0.5176 - val_accuracy: 0.8287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.8729\n",
      "Epoch 00014: val_loss improved from 0.51759 to 0.48697, saving model to ../models/CNN\\Model_033_2_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.3731 - accuracy: 0.8729 - val_loss: 0.4870 - val_accuracy: 0.8384\n",
      "Epoch 15/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.3478 - accuracy: 0.8812\n",
      "Epoch 00015: val_loss did not improve from 0.48697\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.3478 - accuracy: 0.8812 - val_loss: 0.5677 - val_accuracy: 0.8170\n",
      "Epoch 16/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.3220 - accuracy: 0.8877\n",
      "Epoch 00016: val_loss did not improve from 0.48697\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.3226 - accuracy: 0.8876 - val_loss: 0.5685 - val_accuracy: 0.8243\n",
      "Epoch 17/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.3145 - accuracy: 0.8914\n",
      "Epoch 00017: val_loss did not improve from 0.48697\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.3146 - accuracy: 0.8913 - val_loss: 0.4967 - val_accuracy: 0.8396\n",
      "Epoch 00017: early stopping\n",
      "443/443 [==============================] - 2s 4ms/step - loss: 0.4869 - accuracy: 0.8383\n",
      "Score for fold 2: loss of 0.48693573474884033; accuracy of 83.82861614227295%\n",
      "Epoch 1/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 1.6136 - accuracy: 0.4168\n",
      "Epoch 00001: val_loss improved from inf to 1.56114, saving model to ../models/CNN\\Model_033_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 12ms/step - loss: 1.6131 - accuracy: 0.4171 - val_loss: 1.5611 - val_accuracy: 0.4821\n",
      "Epoch 2/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.2311 - accuracy: 0.5660\n",
      "Epoch 00002: val_loss improved from 1.56114 to 1.35563, saving model to ../models/CNN\\Model_033_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 1.2311 - accuracy: 0.5660 - val_loss: 1.3556 - val_accuracy: 0.5775\n",
      "Epoch 3/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.9939 - accuracy: 0.6520\n",
      "Epoch 00003: val_loss improved from 1.35563 to 0.88118, saving model to ../models/CNN\\Model_033_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.9937 - accuracy: 0.6520 - val_loss: 0.8812 - val_accuracy: 0.6941\n",
      "Epoch 4/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.8399 - accuracy: 0.7100\n",
      "Epoch 00004: val_loss did not improve from 0.88118\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.8404 - accuracy: 0.7098 - val_loss: 0.8962 - val_accuracy: 0.6856\n",
      "Epoch 5/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.7367 - accuracy: 0.7458\n",
      "Epoch 00005: val_loss improved from 0.88118 to 0.73274, saving model to ../models/CNN\\Model_033_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.7361 - accuracy: 0.7458 - val_loss: 0.7327 - val_accuracy: 0.7482\n",
      "Epoch 6/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.6526 - accuracy: 0.7740\n",
      "Epoch 00006: val_loss did not improve from 0.73274\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6528 - accuracy: 0.7739 - val_loss: 0.8190 - val_accuracy: 0.7437\n",
      "Epoch 7/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.6015 - accuracy: 0.7920\n",
      "Epoch 00007: val_loss improved from 0.73274 to 0.70569, saving model to ../models/CNN\\Model_033_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.6010 - accuracy: 0.7922 - val_loss: 0.7057 - val_accuracy: 0.7610\n",
      "Epoch 8/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.5525 - accuracy: 0.8105\n",
      "Epoch 00008: val_loss improved from 0.70569 to 0.70013, saving model to ../models/CNN\\Model_033_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.5526 - accuracy: 0.8106 - val_loss: 0.7001 - val_accuracy: 0.7668\n",
      "Epoch 9/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.5099 - accuracy: 0.8234\n",
      "Epoch 00009: val_loss improved from 0.70013 to 0.64011, saving model to ../models/CNN\\Model_033_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.5102 - accuracy: 0.8232 - val_loss: 0.6401 - val_accuracy: 0.7917\n",
      "Epoch 10/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.8344\n",
      "Epoch 00010: val_loss improved from 0.64011 to 0.56605, saving model to ../models/CNN\\Model_033_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.4732 - accuracy: 0.8344 - val_loss: 0.5661 - val_accuracy: 0.8114\n",
      "Epoch 11/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.8477\n",
      "Epoch 00011: val_loss did not improve from 0.56605\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.4390 - accuracy: 0.8477 - val_loss: 0.5982 - val_accuracy: 0.8021\n",
      "Epoch 12/400\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.4137 - accuracy: 0.8569\n",
      "Epoch 00012: val_loss improved from 0.56605 to 0.51365, saving model to ../models/CNN\\Model_033_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.4139 - accuracy: 0.8568 - val_loss: 0.5137 - val_accuracy: 0.8324\n",
      "Epoch 13/400\n",
      "882/885 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.8647\n",
      "Epoch 00013: val_loss improved from 0.51365 to 0.46724, saving model to ../models/CNN\\Model_033_3_Best.hdf5\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.3910 - accuracy: 0.8646 - val_loss: 0.4672 - val_accuracy: 0.8463\n",
      "Epoch 14/400\n",
      "883/885 [============================>.] - ETA: 0s - loss: 0.3592 - accuracy: 0.8747\n",
      "Epoch 00014: val_loss did not improve from 0.46724\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.3590 - accuracy: 0.8749 - val_loss: 0.5236 - val_accuracy: 0.8294\n",
      "Epoch 15/400\n",
      "880/885 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.8813\n",
      "Epoch 00015: val_loss did not improve from 0.46724\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.3410 - accuracy: 0.8812 - val_loss: 0.5019 - val_accuracy: 0.8370\n",
      "Epoch 16/400\n",
      "881/885 [============================>.] - ETA: 0s - loss: 0.3181 - accuracy: 0.8889\n",
      "Epoch 00016: val_loss did not improve from 0.46724\n",
      "885/885 [==============================] - 10s 11ms/step - loss: 0.3181 - accuracy: 0.8889 - val_loss: 0.4970 - val_accuracy: 0.8430\n",
      "Epoch 00016: early stopping\n",
      "443/443 [==============================] - 2s 4ms/step - loss: 0.4676 - accuracy: 0.8461\n",
      "Score for fold 3: loss of 0.46758896112442017; accuracy of 84.61104035377502%\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "cv_acc = 0\n",
    "cv_f1 = 0\n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "\n",
    "    x_train_ = x_train_removed[train_index]\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "\n",
    "    # one hot encoding\n",
    "    y_train_onehot = to_categorical(y_train_, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_033_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    # create generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         rotation_range=10,\n",
    "#         shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "#         vertical_flip=True,\n",
    "        width_shift_range=4.0/32, # 4 pix\n",
    "        height_shift_range=4.0/32, # 4 pix\n",
    "        zoom_range=0.1\n",
    "#         channel_shift_range=0.2\n",
    "        )\n",
    "\n",
    "    batch_size = 32\n",
    "    train_datagenerator = train_datagen.flow(x_train_, y_train_onehot, batch_size)\n",
    "    valid_datagenerator = ImageDataGenerator().flow(x_valid_, y_valid_onehot, batch_size)\n",
    "\n",
    "    model_history = model.fit_generator(train_datagenerator,\n",
    "                                  steps_per_epoch=int(len(x_train_)//batch_size),\n",
    "                                  epochs=400,\n",
    "                                  validation_data=valid_datagenerator,\n",
    "                                  validation_steps=int(len(x_valid_)//batch_size),\n",
    "                                  verbose=1,\n",
    "                                  shuffle=True,\n",
    "                                  callbacks=[es_cb, cp_cb])\n",
    "\n",
    "    # inference\n",
    "    model.load_weights(chkpt)\n",
    "    scores = model.evaluate(x_valid_, y_valid_onehot)\n",
    "    \n",
    "    # CV value\n",
    "    cv_acc += scores[1]*100\n",
    "    y_valid_pred =  model.predict(x_valid_)\n",
    "    y_valid_pred = np.argmax(y_valid_pred, axis=1)\n",
    "    cv_f1 += f1_score(y_valid_, y_valid_pred, average='macro')*100\n",
    "    \n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    predict = model.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85      1000\n",
      "           1       0.89      0.98      0.93      1000\n",
      "           2       0.92      0.64      0.75      1000\n",
      "           3       0.79      0.73      0.76      1000\n",
      "           4       0.88      0.80      0.84      1000\n",
      "           5       0.86      0.78      0.82      1000\n",
      "           6       0.79      0.95      0.86      1000\n",
      "           7       0.83      0.95      0.88      1000\n",
      "           8       0.93      0.94      0.93      1000\n",
      "           9       0.97      0.86      0.91      1000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.85     10000\n",
      "weighted avg       0.86      0.86      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_dataaug_histories = histories\n",
    "ensemble_dataaug_predicts = predicts\n",
    "ensemble_dataaug_predicts_ = ensemble_dataaug_predicts / n_splits\n",
    "y_pred = np.argmax(ensemble_dataaug_predicts_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ACC is 83.0,n_splits CV macro F1 is 82.0\n"
     ]
    }
   ],
   "source": [
    "print(f'CV ACC is {cv_acc//n_splits},n_splits CV macro F1 is {cv_f1//n_splits}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
