{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "entire-hudson",
   "metadata": {},
   "source": [
    "# Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "featured-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-syria",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "amber-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() # load data\n",
    "x_train,x_test = x_train/255.0,x_test/255.0 # normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "surrounded-booth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "hired-michael",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "north-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No method on keras to get cifar10 category label name by categoly label?\n",
    "cifar10_labels = np.array([\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'])\n",
    "\n",
    "bird_ind = np.where(cifar10_labels=='bird')\n",
    "deer_ind = np.where(cifar10_labels=='deer')\n",
    "truck_ind = np.where(cifar10_labels=='truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "vertical-robin",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 42500 is out of bounds for axis 0 with size 42500",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-c8fc41b4df64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mx_train_removed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0my_train_removed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 42500 is out of bounds for axis 0 with size 42500"
     ]
    }
   ],
   "source": [
    "remove_num = 2500\n",
    "train_num = len(y_train) - remove_num * 3\n",
    "x_train_removed =  np.zeros(x_train.shape)[:train_num]\n",
    "y_train_removed =  np.zeros(y_train.shape)[:train_num]\n",
    "\n",
    "bird_limit, deer_limit, truck_limit = 0, 0, 0\n",
    "for i, label in enumerate(y_train):\n",
    "    if label == bird_ind:\n",
    "        if bird_limit < 2500:\n",
    "            bird_limit += 1\n",
    "            x_train_removed[i] = x_train[i]\n",
    "            y_train_removed[i] = y_train[i]\n",
    "            continue\n",
    "        else: continue\n",
    "    if label == deer_ind:\n",
    "        if deer_limit < 2500:\n",
    "            deer_limit += 1\n",
    "            x_train_removed[i] = x_train[i]\n",
    "            y_train_removed[i] = y_train[i]\n",
    "            continue\n",
    "        else: continue\n",
    "    if label == truck_ind:\n",
    "        if truck_limit < 2500:\n",
    "            truck_limit += 1\n",
    "            x_train_removed[i] = x_train[i]\n",
    "            y_train_removed[i] = y_train[i]\n",
    "            continue\n",
    "        else: continue\n",
    "    \n",
    "    x_train_removed[i] = y_train[i]\n",
    "    y_train_removed[i] = y_train[i]\n",
    "\n",
    "y_train_removed = np.array(y_train_removed, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "korean-iceland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42500, 32, 32, 3)\n",
      "(42500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_removed.shape)\n",
    "print(y_train_removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "earned-photographer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    35000\n",
       "2     2500\n",
       "4     2500\n",
       "9     2500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(y_train_removed.flatten())\n",
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "pharmaceutical-fifty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.249e+04, 2.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 0.000e+00,\n",
       "        1.000e+00, 1.000e+00, 1.000e+00, 2.000e+00]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ヒストグラムを描画する\n",
    "plt.hist(y_train_removed.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "invisible-vanilla",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.4-cp38-cp38-win_amd64.whl (8.5 MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp38-cp38-win_amd64.whl (51 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\koki inoue\\anaconda3\\envs\\tf2.3\\lib\\site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\koki inoue\\anaconda3\\envs\\tf2.3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\koki inoue\\anaconda3\\envs\\tf2.3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.1.0-cp38-cp38-win_amd64.whl (2.2 MB)\n",
      "Requirement already satisfied: six in c:\\users\\koki inoue\\anaconda3\\envs\\tf2.3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Installing collected packages: pillow, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.4 pillow-8.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baking-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = tf.keras.Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = tf.keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-arthritis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
