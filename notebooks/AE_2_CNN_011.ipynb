{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_randvalue(value):\n",
    "    # Set a seed value\n",
    "    seed_value= value \n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "set_randvalue(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() # load data\n",
    "x_train,x_test = x_train.astype('float32')/255.0,x_test.astype('float32')/255.0 # normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit three class preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird label num is 2500\n",
      "Deer label num is 2500\n",
      "Truck label num is 2500\n",
      "Other label num is 35000\n",
      "Train label num is 42500\n",
      "(42500, 32, 32, 3)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "# No method on keras to get cifar10 category label name by categoly label?\n",
    "cifar10_labels = np.array([\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'])\n",
    "\n",
    "bird_num = np.where(cifar10_labels=='bird')\n",
    "deer_num = np.where(cifar10_labels=='deer')\n",
    "truck_num = np.where(cifar10_labels=='truck')\n",
    "\n",
    "limit_num = 2500\n",
    "\n",
    "# get limit label indexes\n",
    "bird_indexes = [i for i, label in enumerate(y_train) if label == bird_num]\n",
    "deer_indexes = [i for i, label in enumerate(y_train) if label == deer_num] \n",
    "truck_indexes = [i for i, label in enumerate(y_train) if label == truck_num] \n",
    "other_indexes = [i for i, label in enumerate(y_train) if label not in [bird_num, deer_num, truck_num]]\n",
    "\n",
    "# limit\n",
    "bird_indexes = bird_indexes[:limit_num]\n",
    "deer_indexes = deer_indexes[:limit_num]\n",
    "truck_indexes = truck_indexes[:limit_num]\n",
    "print(f'Bird label num is {len(bird_indexes)}') # 2500\n",
    "print(f'Deer label num is {len(deer_indexes)}') # 2500\n",
    "print(f'Truck label num is {len(truck_indexes)}') # 2500\n",
    "print(f'Other label num is {len(other_indexes)}') # 35000; 5000*7\n",
    "\n",
    "# merge and sort\n",
    "merge_indexes = np.concatenate([other_indexes, bird_indexes, deer_indexes, truck_indexes], 0)\n",
    "merge_indexes.sort()\n",
    "print(f'Train label num is {len(merge_indexes)}') # 42500\n",
    "\n",
    "# create three labels removed train data\n",
    "x_train_removed =  np.zeros((len(merge_indexes), 32, 32, 3))\n",
    "y_train_removed =  np.zeros(len(merge_indexes))\n",
    "\n",
    "for i, train_index in enumerate(merge_indexes):\n",
    "    x_train_removed[i] = x_train[train_index]\n",
    "    y_train_removed[i] = y_train[train_index]\n",
    "    \n",
    "print(x_train_removed.shape)\n",
    "print(y_train_removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42500, 32, 32, 3)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_removed.shape)\n",
    "print(y_train_removed.shape)\n",
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    5000\n",
      "1.0    5000\n",
      "3.0    5000\n",
      "5.0    5000\n",
      "6.0    5000\n",
      "7.0    5000\n",
      "8.0    5000\n",
      "2.0    2500\n",
      "4.0    2500\n",
      "9.0    2500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(y_train_removed.flatten())\n",
    "print(df.value_counts())\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5000., 5000., 2500., 5000., 2500., 5000., 5000., 5000., 5000.,\n",
       "        2500.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot data labels\n",
    "plt.hist(y_train_removed.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load AE models weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Norm Model\n",
    "def create_AE01_model(k_size):\n",
    "    input_img = Input(shape=(32, 32, 3))  # 0\n",
    "    conv1 = Conv2D(64, (k_size, k_size), padding='same', name=\"Dense_AE01_1\")(input_img) # 1\n",
    "    conv1 = BatchNormalization(name=\"BN_AE01_1\")(conv1) # 2\n",
    "    conv1 = Activation('relu', name=\"Relu_AE01_1\")(conv1) # 3\n",
    "        \n",
    "    decoded = Conv2D(3, (k_size, k_size), padding='same', name=\"Dense_AE01_2\")(conv1) # 4\n",
    "    decoded = BatchNormalization(name=\"BN_AE01_2\")(decoded) # 5\n",
    "    decoded = Activation('relu', name=\"Relu_AE01_2\")(decoded) # 6\n",
    "    return Model(input_img, decoded)\n",
    "\n",
    "class AE01():\n",
    "    def __init__(self, ksize, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.autoencoder = create_AE01_model(ksize)\n",
    "        self.encoder = None\n",
    "\n",
    "    def compile(self, optimizer='adam', loss='binary_crossentropy'):\n",
    "        self.autoencoder.compile(optimizer=self.optimizer, loss=loss)\n",
    "\n",
    "    def train(self, x_train=None, x_test=None, epochs=1, batch_size=32, shuffle=True):\n",
    "        es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "        ae_model_path = '../models/AE/AE01_AE_Best.hdf5'\n",
    "        cp_cb = ModelCheckpoint(filepath = ae_model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "       \n",
    "        history = self.autoencoder.fit(x_train, x_train,\n",
    "                             epochs=epochs,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=shuffle,\n",
    "                             callbacks=[es_cb, cp_cb],\n",
    "                             validation_data=(x_test, x_test))\n",
    "        \n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        \n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        encode_model_path = '../models/AE/AE01_Encoder_Best.hdf5'\n",
    "        self.encoder.save(encode_model_path)\n",
    "        return history\n",
    "    \n",
    "    def load_weights(self, ae_model_path, encode_model_path):\n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        self.encoder.load_weights(encode_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "Dense_AE01_1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "BN_AE01_1 (BatchNormalizatio (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "Relu_AE01_1 (Activation)     (None, 32, 32, 64)        0         \n",
      "=================================================================\n",
      "Total params: 2,048\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_ksize = 3\n",
    "ae_optimizer = 'rmsprop'\n",
    "stack01 = AE01(ae_ksize, ae_optimizer)\n",
    "stack01.load_weights('../models/AE/AE01_AE_Best.hdf5', '../models/AE/AE01_Encoder_Best.hdf5')\n",
    "stack01.encoder.trainable = False\n",
    "stack01.encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model AE to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_StackedAE01_CNN01_model(encoder):\n",
    "    input_img = encoder.input\n",
    "    output = encoder.layers[-1].output # 32,32,64\n",
    "    x = Conv2D(64,(3,3),padding = \"same\",activation= \"relu\")(output)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x) # 16,16,64\n",
    "    \n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x) # 8,8,128\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    y = Dense(10,activation = \"softmax\")(x)\n",
    "\n",
    "    return Model(input_img, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train without data augumentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 1.3957 - accuracy: 0.5031\n",
      "Epoch 00001: val_loss improved from inf to 1.32373, saving model to ../models/CNN\\Model_007_1_Best.hdf5\n",
      "886/886 [==============================] - 141s 159ms/step - loss: 1.3957 - accuracy: 0.5031 - val_loss: 1.3237 - val_accuracy: 0.5218\n",
      "Epoch 2/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 1.0348 - accuracy: 0.6357\n",
      "Epoch 00002: val_loss improved from 1.32373 to 1.00844, saving model to ../models/CNN\\Model_007_1_Best.hdf5\n",
      "886/886 [==============================] - 134s 151ms/step - loss: 1.0348 - accuracy: 0.6357 - val_loss: 1.0084 - val_accuracy: 0.6454\n",
      "Epoch 3/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.8569 - accuracy: 0.7003\n",
      "Epoch 00003: val_loss did not improve from 1.00844\n",
      "886/886 [==============================] - 134s 151ms/step - loss: 0.8569 - accuracy: 0.7003 - val_loss: 1.0585 - val_accuracy: 0.6327\n",
      "Epoch 4/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.7263 - accuracy: 0.7454\n",
      "Epoch 00004: val_loss improved from 1.00844 to 0.99699, saving model to ../models/CNN\\Model_007_1_Best.hdf5\n",
      "886/886 [==============================] - 133s 150ms/step - loss: 0.7263 - accuracy: 0.7454 - val_loss: 0.9970 - val_accuracy: 0.6701\n",
      "Epoch 5/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.7809\n",
      "Epoch 00005: val_loss improved from 0.99699 to 0.79707, saving model to ../models/CNN\\Model_007_1_Best.hdf5\n",
      "886/886 [==============================] - 133s 150ms/step - loss: 0.6254 - accuracy: 0.7809 - val_loss: 0.7971 - val_accuracy: 0.7248\n",
      "Epoch 6/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.5357 - accuracy: 0.8119\n",
      "Epoch 00006: val_loss did not improve from 0.79707\n",
      "886/886 [==============================] - 129s 145ms/step - loss: 0.5357 - accuracy: 0.8119 - val_loss: 0.8936 - val_accuracy: 0.7079\n",
      "Epoch 7/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.4611 - accuracy: 0.8401\n",
      "Epoch 00007: val_loss did not improve from 0.79707\n",
      "886/886 [==============================] - 128s 145ms/step - loss: 0.4611 - accuracy: 0.8401 - val_loss: 0.9413 - val_accuracy: 0.7078\n",
      "Epoch 8/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.8649\n",
      "Epoch 00008: val_loss improved from 0.79707 to 0.77535, saving model to ../models/CNN\\Model_007_1_Best.hdf5\n",
      "886/886 [==============================] - 129s 145ms/step - loss: 0.3877 - accuracy: 0.8649 - val_loss: 0.7753 - val_accuracy: 0.7527\n",
      "Epoch 9/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.3183 - accuracy: 0.8894\n",
      "Epoch 00009: val_loss did not improve from 0.77535\n",
      "886/886 [==============================] - 128s 145ms/step - loss: 0.3183 - accuracy: 0.8894 - val_loss: 1.0154 - val_accuracy: 0.7308\n",
      "Epoch 10/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.2777 - accuracy: 0.9026\n",
      "Epoch 00010: val_loss did not improve from 0.77535\n",
      "886/886 [==============================] - 127s 143ms/step - loss: 0.2777 - accuracy: 0.9026 - val_loss: 1.2364 - val_accuracy: 0.6897\n",
      "Epoch 11/400\n",
      "886/886 [==============================] - ETA: 0s - loss: 0.2330 - accuracy: 0.9173\n",
      "Epoch 00011: val_loss did not improve from 0.77535\n",
      "886/886 [==============================] - 126s 142ms/step - loss: 0.2330 - accuracy: 0.9173 - val_loss: 0.9264 - val_accuracy: 0.7420\n",
      "Epoch 00011: early stopping\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 0.8780 - accuracy: 0.7262\n",
      "Score for fold 1: loss of 0.8780476450920105; accuracy of 72.61999845504761%\n",
      "Epoch 1/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 1.3959 - accuracy: 0.5034\n",
      "Epoch 00001: val_loss improved from inf to 1.29869, saving model to ../models/CNN\\Model_007_2_Best.hdf5\n",
      "886/886 [==============================] - 83s 93ms/step - loss: 1.3958 - accuracy: 0.5034 - val_loss: 1.2987 - val_accuracy: 0.5422\n",
      "Epoch 2/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 1.0254 - accuracy: 0.6361\n",
      "Epoch 00002: val_loss improved from 1.29869 to 1.05555, saving model to ../models/CNN\\Model_007_2_Best.hdf5\n",
      "886/886 [==============================] - 71s 80ms/step - loss: 1.0258 - accuracy: 0.6360 - val_loss: 1.0556 - val_accuracy: 0.6244\n",
      "Epoch 3/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.8338 - accuracy: 0.7088\n",
      "Epoch 00003: val_loss improved from 1.05555 to 1.05499, saving model to ../models/CNN\\Model_007_2_Best.hdf5\n",
      "886/886 [==============================] - 70s 79ms/step - loss: 0.8338 - accuracy: 0.7088 - val_loss: 1.0550 - val_accuracy: 0.6489\n",
      "Epoch 4/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.7131 - accuracy: 0.7500\n",
      "Epoch 00004: val_loss improved from 1.05499 to 0.87177, saving model to ../models/CNN\\Model_007_2_Best.hdf5\n",
      "886/886 [==============================] - 70s 79ms/step - loss: 0.7131 - accuracy: 0.7500 - val_loss: 0.8718 - val_accuracy: 0.7006\n",
      "Epoch 5/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.6129 - accuracy: 0.7832\n",
      "Epoch 00005: val_loss did not improve from 0.87177\n",
      "886/886 [==============================] - 70s 79ms/step - loss: 0.6129 - accuracy: 0.7832 - val_loss: 0.9572 - val_accuracy: 0.6882\n",
      "Epoch 6/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.5215 - accuracy: 0.8180\n",
      "Epoch 00006: val_loss improved from 0.87177 to 0.80890, saving model to ../models/CNN\\Model_007_2_Best.hdf5\n",
      "886/886 [==============================] - 71s 80ms/step - loss: 0.5214 - accuracy: 0.8181 - val_loss: 0.8089 - val_accuracy: 0.7326\n",
      "Epoch 7/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.4434 - accuracy: 0.8425\n",
      "Epoch 00007: val_loss did not improve from 0.80890\n",
      "886/886 [==============================] - 71s 80ms/step - loss: 0.4434 - accuracy: 0.8425 - val_loss: 0.8238 - val_accuracy: 0.7354\n",
      "Epoch 8/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.3743 - accuracy: 0.8680\n",
      "Epoch 00008: val_loss did not improve from 0.80890\n",
      "886/886 [==============================] - 70s 79ms/step - loss: 0.3742 - accuracy: 0.8680 - val_loss: 0.8632 - val_accuracy: 0.7357\n",
      "Epoch 9/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.3089 - accuracy: 0.8920\n",
      "Epoch 00009: val_loss did not improve from 0.80890\n",
      "886/886 [==============================] - 72s 81ms/step - loss: 0.3089 - accuracy: 0.8920 - val_loss: 0.9473 - val_accuracy: 0.7269\n",
      "Epoch 00009: early stopping\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.9127 - accuracy: 0.7081\n",
      "Score for fold 2: loss of 0.9126646518707275; accuracy of 70.81000208854675%\n",
      "Epoch 1/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 1.3774 - accuracy: 0.5104\n",
      "Epoch 00001: val_loss improved from inf to 1.29720, saving model to ../models/CNN\\Model_007_3_Best.hdf5\n",
      "886/886 [==============================] - 72s 82ms/step - loss: 1.3775 - accuracy: 0.5103 - val_loss: 1.2972 - val_accuracy: 0.5421\n",
      "Epoch 2/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 1.0132 - accuracy: 0.6411\n",
      "Epoch 00002: val_loss improved from 1.29720 to 1.03659, saving model to ../models/CNN\\Model_007_3_Best.hdf5\n",
      "886/886 [==============================] - 70s 79ms/step - loss: 1.0131 - accuracy: 0.6411 - val_loss: 1.0366 - val_accuracy: 0.6431\n",
      "Epoch 3/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.8420 - accuracy: 0.7055\n",
      "Epoch 00003: val_loss improved from 1.03659 to 0.96237, saving model to ../models/CNN\\Model_007_3_Best.hdf5\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.8421 - accuracy: 0.7055 - val_loss: 0.9624 - val_accuracy: 0.6743\n",
      "Epoch 4/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.7092 - accuracy: 0.7529\n",
      "Epoch 00004: val_loss improved from 0.96237 to 0.84320, saving model to ../models/CNN\\Model_007_3_Best.hdf5\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.7094 - accuracy: 0.7527 - val_loss: 0.8432 - val_accuracy: 0.7098\n",
      "Epoch 5/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.6028 - accuracy: 0.7877\n",
      "Epoch 00005: val_loss did not improve from 0.84320\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.6032 - accuracy: 0.7876 - val_loss: 0.9215 - val_accuracy: 0.7004\n",
      "Epoch 6/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.5242 - accuracy: 0.8149\n",
      "Epoch 00006: val_loss improved from 0.84320 to 0.84077, saving model to ../models/CNN\\Model_007_3_Best.hdf5\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.5241 - accuracy: 0.8149 - val_loss: 0.8408 - val_accuracy: 0.7282\n",
      "Epoch 7/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.4452 - accuracy: 0.8430\n",
      "Epoch 00007: val_loss improved from 0.84077 to 0.78792, saving model to ../models/CNN\\Model_007_3_Best.hdf5\n",
      "886/886 [==============================] - 70s 79ms/step - loss: 0.4454 - accuracy: 0.8430 - val_loss: 0.7879 - val_accuracy: 0.7484\n",
      "Epoch 8/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8660\n",
      "Epoch 00008: val_loss did not improve from 0.78792\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.3817 - accuracy: 0.8660 - val_loss: 0.7945 - val_accuracy: 0.7562\n",
      "Epoch 9/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.8859\n",
      "Epoch 00009: val_loss did not improve from 0.78792\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.3219 - accuracy: 0.8859 - val_loss: 0.8692 - val_accuracy: 0.7387\n",
      "Epoch 10/400\n",
      "885/886 [============================>.] - ETA: 0s - loss: 0.2699 - accuracy: 0.9045\n",
      "Epoch 00010: val_loss did not improve from 0.78792\n",
      "886/886 [==============================] - 69s 78ms/step - loss: 0.2699 - accuracy: 0.9045 - val_loss: 1.0016 - val_accuracy: 0.7335\n",
      "Epoch 00010: early stopping\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.8935 - accuracy: 0.7157\n",
      "Score for fold 3: loss of 0.8934809565544128; accuracy of 71.56999707221985%\n",
      "Wall time: 47min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model01 = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model01.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "\n",
    "    x_train_ = x_train_removed[train_index]\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "\n",
    "    # one hot encoding\n",
    "    y_train_onehot = to_categorical(y_train_, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_007_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    model01_history = model01.fit(x_train_, y_train_onehot,\n",
    "                          batch_size=32,\n",
    "                          epochs=400,\n",
    "                          verbose=1,\n",
    "                          validation_data=(x_valid_, y_valid_onehot),\n",
    "                          callbacks=[es_cb, cp_cb],\n",
    "                          shuffle=True)\n",
    "    \n",
    "    # inference\n",
    "    model01.load_weights(chkpt)\n",
    "    scores = model01.evaluate(x_test, y_test_onehot)\n",
    "    print(f'Score for fold {fold_no}: {model01.metrics_names[0]} of {scores[0]}; {model01.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    predict = model01.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model01_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81      1000\n",
      "           1       0.79      0.95      0.86      1000\n",
      "           2       0.84      0.49      0.62      1000\n",
      "           3       0.56      0.71      0.63      1000\n",
      "           4       0.81      0.68      0.74      1000\n",
      "           5       0.78      0.70      0.74      1000\n",
      "           6       0.82      0.84      0.83      1000\n",
      "           7       0.78      0.88      0.83      1000\n",
      "           8       0.87      0.91      0.89      1000\n",
      "           9       0.91      0.78      0.84      1000\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.79      0.78      0.78     10000\n",
      "weighted avg       0.79      0.78      0.78     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_histories = histories\n",
    "ensemble_predicts = predicts\n",
    "ensemble_predicts_ = ensemble_predicts / n_splits\n",
    "y_pred = np.argmax(ensemble_predicts_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with data augumentation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.4923 - accuracy: 0.4662\n",
      "Epoch 00001: val_loss improved from inf to 1.74528, saving model to ../models/CNN\\Model_008_1_Best.hdf5\n",
      "885/885 [==============================] - 105s 119ms/step - loss: 1.4923 - accuracy: 0.4662 - val_loss: 1.7453 - val_accuracy: 0.4349\n",
      "Epoch 2/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.1706 - accuracy: 0.5846\n",
      "Epoch 00002: val_loss improved from 1.74528 to 1.20517, saving model to ../models/CNN\\Model_008_1_Best.hdf5\n",
      "885/885 [==============================] - 127s 144ms/step - loss: 1.1706 - accuracy: 0.5846 - val_loss: 1.2052 - val_accuracy: 0.5891\n",
      "Epoch 3/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.0029 - accuracy: 0.6498\n",
      "Epoch 00003: val_loss improved from 1.20517 to 0.99155, saving model to ../models/CNN\\Model_008_1_Best.hdf5\n",
      "885/885 [==============================] - 113s 128ms/step - loss: 1.0029 - accuracy: 0.6498 - val_loss: 0.9916 - val_accuracy: 0.6534\n",
      "Epoch 4/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8953 - accuracy: 0.6887\n",
      "Epoch 00004: val_loss did not improve from 0.99155\n",
      "885/885 [==============================] - 112s 126ms/step - loss: 0.8953 - accuracy: 0.6887 - val_loss: 1.1272 - val_accuracy: 0.6522\n",
      "Epoch 5/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8240 - accuracy: 0.7119\n",
      "Epoch 00005: val_loss did not improve from 0.99155\n",
      "885/885 [==============================] - 120s 135ms/step - loss: 0.8240 - accuracy: 0.7119 - val_loss: 1.0762 - val_accuracy: 0.6538\n",
      "Epoch 6/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7703 - accuracy: 0.7301\n",
      "Epoch 00006: val_loss did not improve from 0.99155\n",
      "885/885 [==============================] - 127s 143ms/step - loss: 0.7703 - accuracy: 0.7301 - val_loss: 1.2786 - val_accuracy: 0.6225\n",
      "Epoch 00006: early stopping\n",
      "313/313 [==============================] - 14s 43ms/step - loss: 1.0763 - accuracy: 0.62453s - los\n",
      "Score for fold 1: loss of 1.0763206481933594; accuracy of 62.449997663497925%\n",
      "Epoch 1/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.4913 - accuracy: 0.4675\n",
      "Epoch 00001: val_loss improved from inf to 1.55150, saving model to ../models/CNN\\Model_008_2_Best.hdf5\n",
      "885/885 [==============================] - 95s 107ms/step - loss: 1.4913 - accuracy: 0.4675 - val_loss: 1.5515 - val_accuracy: 0.5057\n",
      "Epoch 2/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.1715 - accuracy: 0.5803\n",
      "Epoch 00002: val_loss improved from 1.55150 to 1.20341, saving model to ../models/CNN\\Model_008_2_Best.hdf5\n",
      "885/885 [==============================] - 82s 93ms/step - loss: 1.1715 - accuracy: 0.5803 - val_loss: 1.2034 - val_accuracy: 0.5832\n",
      "Epoch 3/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.0146 - accuracy: 0.6428\n",
      "Epoch 00003: val_loss improved from 1.20341 to 0.96585, saving model to ../models/CNN\\Model_008_2_Best.hdf5\n",
      "885/885 [==============================] - 84s 95ms/step - loss: 1.0146 - accuracy: 0.6428 - val_loss: 0.9659 - val_accuracy: 0.6608\n",
      "Epoch 4/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.9070 - accuracy: 0.6831\n",
      "Epoch 00004: val_loss did not improve from 0.96585\n",
      "885/885 [==============================] - 85s 96ms/step - loss: 0.9070 - accuracy: 0.6831 - val_loss: 1.0580 - val_accuracy: 0.6371\n",
      "Epoch 5/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8282 - accuracy: 0.7074\n",
      "Epoch 00005: val_loss did not improve from 0.96585\n",
      "885/885 [==============================] - 91s 103ms/step - loss: 0.8282 - accuracy: 0.7074 - val_loss: 1.0432 - val_accuracy: 0.6359\n",
      "Epoch 6/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7679 - accuracy: 0.7299\n",
      "Epoch 00006: val_loss did not improve from 0.96585\n",
      "885/885 [==============================] - 100s 113ms/step - loss: 0.7679 - accuracy: 0.7299 - val_loss: 1.2060 - val_accuracy: 0.6345\n",
      "Epoch 00006: early stopping\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 1.0322 - accuracy: 0.63310s - los\n",
      "Score for fold 2: loss of 1.0321969985961914; accuracy of 63.30999732017517%\n",
      "Epoch 1/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.4790 - accuracy: 0.4749\n",
      "Epoch 00001: val_loss improved from inf to 1.18926, saving model to ../models/CNN\\Model_008_3_Best.hdf5\n",
      "885/885 [==============================] - 94s 106ms/step - loss: 1.4790 - accuracy: 0.4749 - val_loss: 1.1893 - val_accuracy: 0.5819\n",
      "Epoch 2/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.1499 - accuracy: 0.5928\n",
      "Epoch 00002: val_loss did not improve from 1.18926\n",
      "885/885 [==============================] - 76s 86ms/step - loss: 1.1499 - accuracy: 0.5928 - val_loss: 1.2880 - val_accuracy: 0.5569\n",
      "Epoch 3/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.9926 - accuracy: 0.6527\n",
      "Epoch 00003: val_loss improved from 1.18926 to 1.01431, saving model to ../models/CNN\\Model_008_3_Best.hdf5\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 0.9926 - accuracy: 0.6527 - val_loss: 1.0143 - val_accuracy: 0.6613\n",
      "Epoch 4/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8913 - accuracy: 0.6861\n",
      "Epoch 00004: val_loss improved from 1.01431 to 0.96344, saving model to ../models/CNN\\Model_008_3_Best.hdf5\n",
      "885/885 [==============================] - 72s 81ms/step - loss: 0.8913 - accuracy: 0.6861 - val_loss: 0.9634 - val_accuracy: 0.6676\n",
      "Epoch 5/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8270 - accuracy: 0.7089\n",
      "Epoch 00005: val_loss improved from 0.96344 to 0.85108, saving model to ../models/CNN\\Model_008_3_Best.hdf5\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 0.8270 - accuracy: 0.7089 - val_loss: 0.8511 - val_accuracy: 0.7125\n",
      "Epoch 6/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7674 - accuracy: 0.7314\n",
      "Epoch 00006: val_loss did not improve from 0.85108\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 0.7674 - accuracy: 0.7314 - val_loss: 0.8557 - val_accuracy: 0.7163\n",
      "Epoch 7/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7214 - accuracy: 0.7495\n",
      "Epoch 00007: val_loss did not improve from 0.85108\n",
      "885/885 [==============================] - 73s 83ms/step - loss: 0.7214 - accuracy: 0.7495 - val_loss: 0.8916 - val_accuracy: 0.7001\n",
      "Epoch 8/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.7644\n",
      "Epoch 00008: val_loss improved from 0.85108 to 0.79307, saving model to ../models/CNN\\Model_008_3_Best.hdf5\n",
      "885/885 [==============================] - 73s 83ms/step - loss: 0.6811 - accuracy: 0.7644 - val_loss: 0.7931 - val_accuracy: 0.7397\n",
      "Epoch 9/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6458 - accuracy: 0.7728\n",
      "Epoch 00009: val_loss improved from 0.79307 to 0.72611, saving model to ../models/CNN\\Model_008_3_Best.hdf5\n",
      "885/885 [==============================] - 73s 82ms/step - loss: 0.6458 - accuracy: 0.7728 - val_loss: 0.7261 - val_accuracy: 0.7586\n",
      "Epoch 10/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6229 - accuracy: 0.7819\n",
      "Epoch 00010: val_loss did not improve from 0.72611\n",
      "885/885 [==============================] - 73s 83ms/step - loss: 0.6229 - accuracy: 0.7819 - val_loss: 0.9146 - val_accuracy: 0.7062\n",
      "Epoch 11/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5927 - accuracy: 0.7918\n",
      "Epoch 00011: val_loss did not improve from 0.72611\n",
      "885/885 [==============================] - 73s 83ms/step - loss: 0.5927 - accuracy: 0.7918 - val_loss: 0.7526 - val_accuracy: 0.7461\n",
      "Epoch 12/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5654 - accuracy: 0.8034\n",
      "Epoch 00012: val_loss did not improve from 0.72611\n",
      "885/885 [==============================] - 73s 83ms/step - loss: 0.5654 - accuracy: 0.8034 - val_loss: 0.8025 - val_accuracy: 0.7417\n",
      "Epoch 00012: early stopping\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.7673 - accuracy: 0.7403\n",
      "Score for fold 3: loss of 0.7673043012619019; accuracy of 74.02999997138977%\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model02 = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model02.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "\n",
    "    x_train_ = x_train_removed[train_index]\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "\n",
    "    # one hot encoding\n",
    "    y_train_onehot = to_categorical(y_train_, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_008_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    # create generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    "#     channel_shift_range=0.2\n",
    "    )\n",
    "\n",
    "    batch_size = 32\n",
    "    train_datagenerator = train_datagen.flow(x_train_, y_train_onehot, batch_size)\n",
    "    valid_datagenerator = ImageDataGenerator().flow(x_valid_, y_valid_onehot, batch_size)\n",
    "\n",
    "    model02_history = model02.fit_generator(train_datagenerator,\n",
    "                                  steps_per_epoch=int(len(x_train_)//batch_size),\n",
    "                                  epochs=400,\n",
    "                                  validation_data=valid_datagenerator,\n",
    "                                  validation_steps=int(len(x_valid_)//batch_size),\n",
    "                                  verbose=1,\n",
    "                                  shuffle=True,\n",
    "                                  callbacks=[es_cb, cp_cb])\n",
    "\n",
    "    # inference\n",
    "    model02.load_weights(chkpt)\n",
    "    scores = model02.evaluate(x_test, y_test_onehot)\n",
    "    print(f'Score for fold {fold_no}: {model02.metrics_names[0]} of {scores[0]}; {model02.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    predict = model02.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model02_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77      1000\n",
      "           1       0.81      0.94      0.87      1000\n",
      "           2       0.65      0.60      0.62      1000\n",
      "           3       0.56      0.70      0.62      1000\n",
      "           4       0.78      0.55      0.65      1000\n",
      "           5       0.86      0.50      0.64      1000\n",
      "           6       0.66      0.88      0.75      1000\n",
      "           7       0.77      0.82      0.79      1000\n",
      "           8       0.89      0.85      0.87      1000\n",
      "           9       0.93      0.75      0.83      1000\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.76      0.74      0.74     10000\n",
      "weighted avg       0.76      0.74      0.74     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_dataaug_histories = histories\n",
    "ensemble_dataaug_predicts = predicts\n",
    "ensemble_dataaug_predicts_ = ensemble_dataaug_predicts / n_splits\n",
    "y_pred = np.argmax(ensemble_dataaug_predicts_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with data augumentation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.4503 - accuracy: 0.4861\n",
      "Epoch 00001: val_loss improved from inf to 1.52956, saving model to ../models/CNN\\Model_014_1_Best.hdf5\n",
      "885/885 [==============================] - 112s 127ms/step - loss: 1.4503 - accuracy: 0.4861 - val_loss: 1.5296 - val_accuracy: 0.4943\n",
      "Epoch 2/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.1034 - accuracy: 0.6128\n",
      "Epoch 00002: val_loss improved from 1.52956 to 1.26390, saving model to ../models/CNN\\Model_014_1_Best.hdf5\n",
      "885/885 [==============================] - 113s 128ms/step - loss: 1.1034 - accuracy: 0.6128 - val_loss: 1.2639 - val_accuracy: 0.5716\n",
      "Epoch 3/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.9360 - accuracy: 0.6714\n",
      "Epoch 00003: val_loss improved from 1.26390 to 0.97922, saving model to ../models/CNN\\Model_014_1_Best.hdf5\n",
      "885/885 [==============================] - 113s 127ms/step - loss: 0.9360 - accuracy: 0.6714 - val_loss: 0.9792 - val_accuracy: 0.6637\n",
      "Epoch 4/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8281 - accuracy: 0.7087\n",
      "Epoch 00004: val_loss improved from 0.97922 to 0.87732, saving model to ../models/CNN\\Model_014_1_Best.hdf5\n",
      "885/885 [==============================] - 102s 115ms/step - loss: 0.8281 - accuracy: 0.7087 - val_loss: 0.8773 - val_accuracy: 0.6959\n",
      "Epoch 5/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7533 - accuracy: 0.7374\n",
      "Epoch 00005: val_loss improved from 0.87732 to 0.84288, saving model to ../models/CNN\\Model_014_1_Best.hdf5\n",
      "885/885 [==============================] - 103s 116ms/step - loss: 0.7533 - accuracy: 0.7374 - val_loss: 0.8429 - val_accuracy: 0.7152\n",
      "Epoch 6/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6812 - accuracy: 0.7610\n",
      "Epoch 00006: val_loss improved from 0.84288 to 0.78799, saving model to ../models/CNN\\Model_014_1_Best.hdf5\n",
      "885/885 [==============================] - 106s 120ms/step - loss: 0.6812 - accuracy: 0.7610 - val_loss: 0.7880 - val_accuracy: 0.7381\n",
      "Epoch 7/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6421 - accuracy: 0.7757\n",
      "Epoch 00007: val_loss did not improve from 0.78799\n",
      "885/885 [==============================] - 116s 131ms/step - loss: 0.6421 - accuracy: 0.7757 - val_loss: 0.8562 - val_accuracy: 0.7183\n",
      "Epoch 8/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5941 - accuracy: 0.7923\n",
      "Epoch 00008: val_loss did not improve from 0.78799\n",
      "885/885 [==============================] - 116s 131ms/step - loss: 0.5941 - accuracy: 0.7923 - val_loss: 1.1292 - val_accuracy: 0.6582\n",
      "Epoch 9/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5579 - accuracy: 0.8034\n",
      "Epoch 00009: val_loss improved from 0.78799 to 0.71452, saving model to ../models/CNN\\Model_014_1_Best.hdf5\n",
      "885/885 [==============================] - 106s 120ms/step - loss: 0.5579 - accuracy: 0.8034 - val_loss: 0.7145 - val_accuracy: 0.7599\n",
      "Epoch 10/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.8151\n",
      "Epoch 00010: val_loss improved from 0.71452 to 0.67086, saving model to ../models/CNN\\Model_014_1_Best.hdf5\n",
      "885/885 [==============================] - 102s 115ms/step - loss: 0.5262 - accuracy: 0.8151 - val_loss: 0.6709 - val_accuracy: 0.7767\n",
      "Epoch 11/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4896 - accuracy: 0.8284\n",
      "Epoch 00011: val_loss did not improve from 0.67086\n",
      "885/885 [==============================] - 101s 114ms/step - loss: 0.4896 - accuracy: 0.8284 - val_loss: 0.7207 - val_accuracy: 0.7673\n",
      "Epoch 12/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4654 - accuracy: 0.8355\n",
      "Epoch 00012: val_loss did not improve from 0.67086\n",
      "885/885 [==============================] - 108s 122ms/step - loss: 0.4654 - accuracy: 0.8355 - val_loss: 0.7643 - val_accuracy: 0.7612\n",
      "Epoch 13/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.8463\n",
      "Epoch 00013: val_loss did not improve from 0.67086\n",
      "885/885 [==============================] - 111s 126ms/step - loss: 0.4358 - accuracy: 0.8463 - val_loss: 0.6857 - val_accuracy: 0.7766\n",
      "Epoch 00013: early stopping\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.7340 - accuracy: 0.7605\n",
      "Score for fold 1: loss of 0.7339611053466797; accuracy of 76.05000138282776%\n",
      "Epoch 1/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.4358 - accuracy: 0.4904\n",
      "Epoch 00001: val_loss improved from inf to 2.52996, saving model to ../models/CNN\\Model_014_2_Best.hdf5\n",
      "885/885 [==============================] - 93s 106ms/step - loss: 1.4358 - accuracy: 0.4904 - val_loss: 2.5300 - val_accuracy: 0.3838\n",
      "Epoch 2/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.0899 - accuracy: 0.6110\n",
      "Epoch 00002: val_loss improved from 2.52996 to 1.66288, saving model to ../models/CNN\\Model_014_2_Best.hdf5\n",
      "885/885 [==============================] - 71s 80ms/step - loss: 1.0899 - accuracy: 0.6110 - val_loss: 1.6629 - val_accuracy: 0.5325\n",
      "Epoch 3/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.9251 - accuracy: 0.6761\n",
      "Epoch 00003: val_loss improved from 1.66288 to 0.93355, saving model to ../models/CNN\\Model_014_2_Best.hdf5\n",
      "885/885 [==============================] - 68s 77ms/step - loss: 0.9251 - accuracy: 0.6761 - val_loss: 0.9335 - val_accuracy: 0.6702\n",
      "Epoch 4/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8107 - accuracy: 0.7160\n",
      "Epoch 00004: val_loss did not improve from 0.93355\n",
      "885/885 [==============================] - 68s 77ms/step - loss: 0.8107 - accuracy: 0.7160 - val_loss: 1.0215 - val_accuracy: 0.6456\n",
      "Epoch 5/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7371 - accuracy: 0.7406\n",
      "Epoch 00005: val_loss improved from 0.93355 to 0.75507, saving model to ../models/CNN\\Model_014_2_Best.hdf5\n",
      "885/885 [==============================] - 68s 77ms/step - loss: 0.7371 - accuracy: 0.7406 - val_loss: 0.7551 - val_accuracy: 0.7410\n",
      "Epoch 6/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6716 - accuracy: 0.7670\n",
      "Epoch 00006: val_loss did not improve from 0.75507\n",
      "885/885 [==============================] - 72s 82ms/step - loss: 0.6716 - accuracy: 0.7670 - val_loss: 1.0302 - val_accuracy: 0.6742\n",
      "Epoch 7/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.7810\n",
      "Epoch 00007: val_loss did not improve from 0.75507\n",
      "885/885 [==============================] - 75s 85ms/step - loss: 0.6289 - accuracy: 0.7810 - val_loss: 0.8774 - val_accuracy: 0.7022\n",
      "Epoch 8/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5730 - accuracy: 0.7994\n",
      "Epoch 00008: val_loss improved from 0.75507 to 0.73156, saving model to ../models/CNN\\Model_014_2_Best.hdf5\n",
      "885/885 [==============================] - 75s 84ms/step - loss: 0.5730 - accuracy: 0.7994 - val_loss: 0.7316 - val_accuracy: 0.7486\n",
      "Epoch 9/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5504 - accuracy: 0.8058\n",
      "Epoch 00009: val_loss did not improve from 0.73156\n",
      "885/885 [==============================] - 75s 85ms/step - loss: 0.5504 - accuracy: 0.8058 - val_loss: 0.7608 - val_accuracy: 0.7505\n",
      "Epoch 10/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5113 - accuracy: 0.8220\n",
      "Epoch 00010: val_loss improved from 0.73156 to 0.65931, saving model to ../models/CNN\\Model_014_2_Best.hdf5\n",
      "885/885 [==============================] - 76s 85ms/step - loss: 0.5113 - accuracy: 0.8220 - val_loss: 0.6593 - val_accuracy: 0.7817\n",
      "Epoch 11/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4816 - accuracy: 0.8303\n",
      "Epoch 00011: val_loss did not improve from 0.65931\n",
      "885/885 [==============================] - 76s 86ms/step - loss: 0.4816 - accuracy: 0.8303 - val_loss: 0.7306 - val_accuracy: 0.7598\n",
      "Epoch 12/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.8380\n",
      "Epoch 00012: val_loss did not improve from 0.65931\n",
      "885/885 [==============================] - 76s 86ms/step - loss: 0.4572 - accuracy: 0.8380 - val_loss: 0.7212 - val_accuracy: 0.7748\n",
      "Epoch 13/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.8471\n",
      "Epoch 00013: val_loss did not improve from 0.65931\n",
      "885/885 [==============================] - 76s 85ms/step - loss: 0.4365 - accuracy: 0.8471 - val_loss: 0.7041 - val_accuracy: 0.7798\n",
      "Epoch 00013: early stopping\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.7653 - accuracy: 0.7496\n",
      "Score for fold 2: loss of 0.7652904987335205; accuracy of 74.95999932289124%\n",
      "Epoch 1/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.4498 - accuracy: 0.4842\n",
      "Epoch 00001: val_loss improved from inf to 1.21115, saving model to ../models/CNN\\Model_014_3_Best.hdf5\n",
      "885/885 [==============================] - 72s 81ms/step - loss: 1.4498 - accuracy: 0.4842 - val_loss: 1.2112 - val_accuracy: 0.5698\n",
      "Epoch 2/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.1118 - accuracy: 0.6077\n",
      "Epoch 00002: val_loss improved from 1.21115 to 1.17455, saving model to ../models/CNN\\Model_014_3_Best.hdf5\n",
      "885/885 [==============================] - 72s 82ms/step - loss: 1.1118 - accuracy: 0.6077 - val_loss: 1.1745 - val_accuracy: 0.5995\n",
      "Epoch 3/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.9346 - accuracy: 0.6709\n",
      "Epoch 00003: val_loss improved from 1.17455 to 0.99415, saving model to ../models/CNN\\Model_014_3_Best.hdf5\n",
      "885/885 [==============================] - 73s 82ms/step - loss: 0.9346 - accuracy: 0.6709 - val_loss: 0.9941 - val_accuracy: 0.6579\n",
      "Epoch 4/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.8181 - accuracy: 0.7118\n",
      "Epoch 00004: val_loss did not improve from 0.99415\n",
      "885/885 [==============================] - 73s 83ms/step - loss: 0.8181 - accuracy: 0.7118 - val_loss: 1.2312 - val_accuracy: 0.6102\n",
      "Epoch 5/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7368 - accuracy: 0.7423\n",
      "Epoch 00005: val_loss improved from 0.99415 to 0.89865, saving model to ../models/CNN\\Model_014_3_Best.hdf5\n",
      "885/885 [==============================] - 74s 83ms/step - loss: 0.7368 - accuracy: 0.7423 - val_loss: 0.8987 - val_accuracy: 0.7043\n",
      "Epoch 6/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6721 - accuracy: 0.7651\n",
      "Epoch 00006: val_loss improved from 0.89865 to 0.88248, saving model to ../models/CNN\\Model_014_3_Best.hdf5\n",
      "885/885 [==============================] - 74s 83ms/step - loss: 0.6721 - accuracy: 0.7651 - val_loss: 0.8825 - val_accuracy: 0.7154\n",
      "Epoch 7/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.7814\n",
      "Epoch 00007: val_loss improved from 0.88248 to 0.71446, saving model to ../models/CNN\\Model_014_3_Best.hdf5\n",
      "885/885 [==============================] - 74s 84ms/step - loss: 0.6290 - accuracy: 0.7814 - val_loss: 0.7145 - val_accuracy: 0.7590\n",
      "Epoch 8/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5832 - accuracy: 0.7969\n",
      "Epoch 00008: val_loss did not improve from 0.71446\n",
      "885/885 [==============================] - 76s 86ms/step - loss: 0.5832 - accuracy: 0.7969 - val_loss: 0.8372 - val_accuracy: 0.7229\n",
      "Epoch 9/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.8081\n",
      "Epoch 00009: val_loss improved from 0.71446 to 0.70926, saving model to ../models/CNN\\Model_014_3_Best.hdf5\n",
      "885/885 [==============================] - 76s 86ms/step - loss: 0.5534 - accuracy: 0.8081 - val_loss: 0.7093 - val_accuracy: 0.7599\n",
      "Epoch 10/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5156 - accuracy: 0.8202\n",
      "Epoch 00010: val_loss did not improve from 0.70926\n",
      "885/885 [==============================] - 75s 85ms/step - loss: 0.5156 - accuracy: 0.8202 - val_loss: 0.7310 - val_accuracy: 0.7673\n",
      "Epoch 11/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.8286\n",
      "Epoch 00011: val_loss did not improve from 0.70926\n",
      "885/885 [==============================] - 76s 85ms/step - loss: 0.4837 - accuracy: 0.8286 - val_loss: 0.7660 - val_accuracy: 0.7607\n",
      "Epoch 12/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4661 - accuracy: 0.8374\n",
      "Epoch 00012: val_loss improved from 0.70926 to 0.69794, saving model to ../models/CNN\\Model_014_3_Best.hdf5\n",
      "885/885 [==============================] - 75s 85ms/step - loss: 0.4661 - accuracy: 0.8374 - val_loss: 0.6979 - val_accuracy: 0.7745\n",
      "Epoch 13/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.8482\n",
      "Epoch 00013: val_loss improved from 0.69794 to 0.66992, saving model to ../models/CNN\\Model_014_3_Best.hdf5\n",
      "885/885 [==============================] - 76s 86ms/step - loss: 0.4373 - accuracy: 0.8482 - val_loss: 0.6699 - val_accuracy: 0.7937\n",
      "Epoch 14/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.8542\n",
      "Epoch 00014: val_loss did not improve from 0.66992\n",
      "885/885 [==============================] - 76s 86ms/step - loss: 0.4176 - accuracy: 0.8542 - val_loss: 0.6942 - val_accuracy: 0.7816\n",
      "Epoch 15/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.8616\n",
      "Epoch 00015: val_loss did not improve from 0.66992\n",
      "885/885 [==============================] - 75s 85ms/step - loss: 0.3927 - accuracy: 0.8616 - val_loss: 0.7062 - val_accuracy: 0.7771\n",
      "Epoch 16/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.8671\n",
      "Epoch 00016: val_loss improved from 0.66992 to 0.65167, saving model to ../models/CNN\\Model_014_3_Best.hdf5\n",
      "885/885 [==============================] - 75s 85ms/step - loss: 0.3799 - accuracy: 0.8671 - val_loss: 0.6517 - val_accuracy: 0.8001\n",
      "Epoch 17/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.3589 - accuracy: 0.8743\n",
      "Epoch 00017: val_loss did not improve from 0.65167\n",
      "885/885 [==============================] - 76s 86ms/step - loss: 0.3589 - accuracy: 0.8743 - val_loss: 0.6991 - val_accuracy: 0.7875\n",
      "Epoch 18/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.3498 - accuracy: 0.8795\n",
      "Epoch 00018: val_loss did not improve from 0.65167\n",
      "885/885 [==============================] - 76s 86ms/step - loss: 0.3498 - accuracy: 0.8795 - val_loss: 0.7218 - val_accuracy: 0.7869\n",
      "Epoch 19/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.8822\n",
      "Epoch 00019: val_loss improved from 0.65167 to 0.63372, saving model to ../models/CNN\\Model_014_3_Best.hdf5\n",
      "885/885 [==============================] - 77s 87ms/step - loss: 0.3369 - accuracy: 0.8822 - val_loss: 0.6337 - val_accuracy: 0.8051\n",
      "Epoch 20/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.3114 - accuracy: 0.8904\n",
      "Epoch 00020: val_loss did not improve from 0.63372\n",
      "885/885 [==============================] - 76s 86ms/step - loss: 0.3114 - accuracy: 0.8904 - val_loss: 0.6846 - val_accuracy: 0.7931\n",
      "Epoch 21/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.3067 - accuracy: 0.8910\n",
      "Epoch 00021: val_loss did not improve from 0.63372\n",
      "885/885 [==============================] - 76s 86ms/step - loss: 0.3067 - accuracy: 0.8910 - val_loss: 0.7734 - val_accuracy: 0.7798\n",
      "Epoch 22/400\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.2872 - accuracy: 0.8967\n",
      "Epoch 00022: val_loss did not improve from 0.63372\n",
      "885/885 [==============================] - 77s 86ms/step - loss: 0.2872 - accuracy: 0.8967 - val_loss: 0.7123 - val_accuracy: 0.8072\n",
      "Epoch 00022: early stopping\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.6897 - accuracy: 0.7870\n",
      "Score for fold 3: loss of 0.6896500587463379; accuracy of 78.70000004768372%\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model03 = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model03.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "\n",
    "    x_train_ = x_train_removed[train_index]\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "\n",
    "    # one hot encoding\n",
    "    y_train_onehot = to_categorical(y_train_, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_014_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    # create generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         rotation_range=10,\n",
    "#         shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "#         vertical_flip=True,\n",
    "#         width_shift_range=0.1,\n",
    "#         height_shift_range=0.1,\n",
    "        zoom_range=0.1\n",
    "#         channel_shift_range=0.2\n",
    "        )\n",
    "\n",
    "    batch_size = 32\n",
    "    train_datagenerator = train_datagen.flow(x_train_, y_train_onehot, batch_size)\n",
    "    valid_datagenerator = ImageDataGenerator().flow(x_valid_, y_valid_onehot, batch_size)\n",
    "\n",
    "    model03_history = model03.fit_generator(train_datagenerator,\n",
    "                                  steps_per_epoch=int(len(x_train_)//batch_size),\n",
    "                                  epochs=400,\n",
    "                                  validation_data=valid_datagenerator,\n",
    "                                  validation_steps=int(len(x_valid_)//batch_size),\n",
    "                                  verbose=1,\n",
    "                                  shuffle=True,\n",
    "                                  callbacks=[es_cb, cp_cb])\n",
    "\n",
    "    # inference\n",
    "    model03.load_weights(chkpt)\n",
    "    scores = model03.evaluate(x_test, y_test_onehot)\n",
    "    print(f'Score for fold {fold_no}: {model03.metrics_names[0]} of {scores[0]}; {model03.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    predict = model03.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model03_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83      1000\n",
      "           1       0.89      0.95      0.92      1000\n",
      "           2       0.82      0.63      0.71      1000\n",
      "           3       0.72      0.66      0.69      1000\n",
      "           4       0.87      0.69      0.77      1000\n",
      "           5       0.75      0.81      0.78      1000\n",
      "           6       0.75      0.92      0.83      1000\n",
      "           7       0.80      0.91      0.85      1000\n",
      "           8       0.92      0.89      0.90      1000\n",
      "           9       0.92      0.85      0.88      1000\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_dataaug_histories2 = histories\n",
    "ensemble_dataaug_predicts2 = predicts\n",
    "ensemble_dataaug_predicts2_ = ensemble_dataaug_predicts2 / n_splits\n",
    "y_pred = np.argmax(ensemble_dataaug_predicts2_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
