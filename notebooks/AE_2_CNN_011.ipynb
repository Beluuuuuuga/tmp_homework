{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE # smote\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_randvalue(value):\n",
    "    # Set a seed value\n",
    "    seed_value= value \n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "set_randvalue(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() # load data\n",
    "x_train,x_test = x_train.astype('float32')/255.0,x_test.astype('float32')/255.0 # normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit three class preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird label num is 2500\n",
      "Deer label num is 2500\n",
      "Truck label num is 2500\n",
      "Other label num is 35000\n",
      "Train label num is 42500\n",
      "(42500, 32, 32, 3)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "# No method on keras to get cifar10 category label name by categoly label?\n",
    "cifar10_labels = np.array([\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'])\n",
    "\n",
    "bird_num = np.where(cifar10_labels=='bird')\n",
    "deer_num = np.where(cifar10_labels=='deer')\n",
    "truck_num = np.where(cifar10_labels=='truck')\n",
    "\n",
    "limit_num = 2500\n",
    "\n",
    "# get limit label indexes\n",
    "bird_indexes = [i for i, label in enumerate(y_train) if label == bird_num]\n",
    "deer_indexes = [i for i, label in enumerate(y_train) if label == deer_num] \n",
    "truck_indexes = [i for i, label in enumerate(y_train) if label == truck_num] \n",
    "other_indexes = [i for i, label in enumerate(y_train) if label not in [bird_num, deer_num, truck_num]]\n",
    "\n",
    "# limit\n",
    "bird_indexes = bird_indexes[:limit_num]\n",
    "deer_indexes = deer_indexes[:limit_num]\n",
    "truck_indexes = truck_indexes[:limit_num]\n",
    "print(f'Bird label num is {len(bird_indexes)}') # 2500\n",
    "print(f'Deer label num is {len(deer_indexes)}') # 2500\n",
    "print(f'Truck label num is {len(truck_indexes)}') # 2500\n",
    "print(f'Other label num is {len(other_indexes)}') # 35000; 5000*7\n",
    "\n",
    "# merge and sort\n",
    "merge_indexes = np.concatenate([other_indexes, bird_indexes, deer_indexes, truck_indexes], 0)\n",
    "merge_indexes.sort()\n",
    "print(f'Train label num is {len(merge_indexes)}') # 42500\n",
    "\n",
    "# create three labels removed train data\n",
    "x_train_removed =  np.zeros((len(merge_indexes), 32, 32, 3))\n",
    "y_train_removed =  np.zeros(len(merge_indexes))\n",
    "\n",
    "for i, train_index in enumerate(merge_indexes):\n",
    "    x_train_removed[i] = x_train[train_index]\n",
    "    y_train_removed[i] = y_train[train_index]\n",
    "    \n",
    "print(x_train_removed.shape)\n",
    "print(y_train_removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42500, 32, 32, 3)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_removed.shape)\n",
    "print(y_train_removed.shape)\n",
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0    5000\n",
      "7.0    5000\n",
      "6.0    5000\n",
      "5.0    5000\n",
      "3.0    5000\n",
      "1.0    5000\n",
      "0.0    5000\n",
      "9.0    2500\n",
      "4.0    2500\n",
      "2.0    2500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(y_train_removed.flatten())\n",
    "print(df.value_counts())\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5000., 5000., 2500., 5000., 2500., 5000., 5000., 5000., 5000.,\n",
       "        2500.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPBUlEQVR4nO3df6zddX3H8edrrb/dbJWuYW1dm9jM1CUKuYE6lmWjWylgLH+owWzakCb9p9twMXHgP2QqCSaLqMkka6RbdU4kqKFRIjaAWfaHyEUYCpVwh2Dbga22oM6oq773x/1UTvFe7r309JxyP89HcnO+3/f38/2e9/eb3tf53u/5ntNUFZKkPvzWuBuQJI2OoS9JHTH0Jakjhr4kdcTQl6SOLB13A8/lrLPOqrVr1467DUl6Qbn33nt/UFUrZlp2Rof+2rVrmZycHHcbkvSCkuTx2ZZ5eUeSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZF6hn+SxJN9Kcn+SyVZ7dZJ9SR5pj8tbPUk+nmQqyQNJzh3YzrY2/pEk207PLkmSZrOQM/0/q6o3VdVEm78KuKOq1gN3tHmAi4H17WcHcANMv0gA1wDnA+cB15x4oZAkjcapXN7ZCuxp03uAywbqn6ppXweWJTkbuAjYV1VHq+oYsA/YcgrPL0laoPl+IreAryYp4J+rahewsqqeaMufBFa26VXAgYF1D7babPWTJNnB9F8IvPa1r51nezNbe9WXT2n9F5rHrrt0bM89rmPd4z5rdMb57+t0mW/o/3FVHUryu8C+JN8ZXFhV1V4QTll7QdkFMDEx4X/rJUlDNK/LO1V1qD0eBr7I9DX577fLNrTHw234IWDNwOqrW222uiRpROYM/SSvSPLbJ6aBzcC3gb3AiTtwtgG3tum9wLvbXTwbgafbZaDbgc1Jlrc3cDe3miRpROZzeWcl8MUkJ8b/e1V9Jck9wM1JtgOPA+9o428DLgGmgJ8CVwBU1dEkHwTuaeM+UFVHh7YnkqQ5zRn6VfUo8MYZ6j8ENs1QL2DnLNvaDexeeJuSpGHwE7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjsw79JMsSXJfki+1+XVJ7k4yleRzSV7c6i9p81Nt+dqBbVzd6g8nuWjoeyNJek4LOdO/Etg/MP9h4Pqqeh1wDNje6tuBY61+fRtHkg3A5cAbgC3AJ5IsObX2JUkLMa/QT7IauBT4ZJsPcCFwSxuyB7isTW9t87Tlm9r4rcBNVfXzqvouMAWcN4R9kCTN03zP9D8KvA/4VZt/DfBUVR1v8weBVW16FXAAoC1/uo3/dX2GdX4tyY4kk0kmjxw5Mv89kSTNac7QT/IW4HBV3TuCfqiqXVU1UVUTK1asGMVTSlI3ls5jzAXAW5NcArwU+B3gY8CyJEvb2fxq4FAbfwhYAxxMshR4FfDDgfoJg+tIkkZgzjP9qrq6qlZX1Vqm34i9s6r+ErgLeFsbtg24tU3vbfO05XdWVbX65e3unnXAeuAbQ9sTSdKc5nOmP5u/B25K8iHgPuDGVr8R+HSSKeAo0y8UVNWDSW4GHgKOAzur6pen8PySpAVaUOhX1deAr7XpR5nh7puq+hnw9lnWvxa4dqFNSpKGw0/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjoyZ+gneWmSbyT5ryQPJvmHVl+X5O4kU0k+l+TFrf6SNj/Vlq8d2NbVrf5wkotO215JkmY0nzP9nwMXVtUbgTcBW5JsBD4MXF9VrwOOAdvb+O3AsVa/vo0jyQbgcuANwBbgE0mWDHFfJElzmDP0a9pP2uyL2k8BFwK3tPoe4LI2vbXN05ZvSpJWv6mqfl5V3wWmgPOGsROSpPmZ1zX9JEuS3A8cBvYB/w08VVXH25CDwKo2vQo4ANCWPw28ZrA+wzqSpBGYV+hX1S+r6k3AaqbPzl9/uhpKsiPJZJLJI0eOnK6nkaQuLejunap6CrgLeDOwLMnStmg1cKhNHwLWALTlrwJ+OFifYZ3B59hVVRNVNbFixYqFtCdJmsN87t5ZkWRZm34Z8BfAfqbD/21t2Dbg1ja9t83Tlt9ZVdXql7e7e9YB64FvDGk/JEnzsHTuIZwN7Gl32vwWcHNVfSnJQ8BNST4E3Afc2MbfCHw6yRRwlOk7dqiqB5PcDDwEHAd2VtUvh7s7kqTnMmfoV9UDwDkz1B9lhrtvqupnwNtn2da1wLULb1OSNAx+IleSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOZPo/tTozTUxM1OTk5PNef+1VXx5iN5I0Oo9dd+nzXjfJvVU1MdMyz/QlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI3OGfpI1Se5K8lCSB5Nc2eqvTrIvySPtcXmrJ8nHk0wleSDJuQPb2tbGP5Jk2+nbLUnSTOZzpn8ceG9VbQA2AjuTbACuAu6oqvXAHW0e4GJgffvZAdwA0y8SwDXA+cB5wDUnXigkSaMxZ+hX1RNV9c02/WNgP7AK2ArsacP2AJe16a3Ap2ra14FlSc4GLgL2VdXRqjoG7AO2DHNnJEnPbUHX9JOsBc4B7gZWVtUTbdGTwMo2vQo4MLDawVabrf7s59iRZDLJ5JEjRxbSniRpDvMO/SSvBD4PvKeqfjS4rKoKqGE0VFW7qmqiqiZWrFgxjE1Kkpp5hX6SFzEd+J+pqi+08vfbZRva4+FWPwSsGVh9davNVpckjch87t4JcCOwv6o+MrBoL3DiDpxtwK0D9Xe3u3g2Ak+3y0C3A5uTLG9v4G5uNUnSiCydx5gLgHcB30pyf6u9H7gOuDnJduBx4B1t2W3AJcAU8FPgCoCqOprkg8A9bdwHquroMHZCkjQ/c4Z+Vf0nkFkWb5phfAE7Z9nWbmD3QhqUJA2Pn8iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdWTO0E+yO8nhJN8eqL06yb4kj7TH5a2eJB9PMpXkgSTnDqyzrY1/JMm207M7kqTnMp8z/X8FtjyrdhVwR1WtB+5o8wAXA+vbzw7gBph+kQCuAc4HzgOuOfFCIUkanTlDv6r+Azj6rPJWYE+b3gNcNlD/VE37OrAsydnARcC+qjpaVceAffzmC4kk6TR7vtf0V1bVE236SWBlm14FHBgYd7DVZqv/hiQ7kkwmmTxy5MjzbE+SNJNTfiO3qgqoIfRyYnu7qmqiqiZWrFgxrM1Kknj+of/9dtmG9ni41Q8BawbGrW612eqSpBF6vqG/FzhxB8424NaB+rvbXTwbgafbZaDbgc1Jlrc3cDe3miRphJbONSDJZ4E/Bc5KcpDpu3CuA25Osh14HHhHG34bcAkwBfwUuAKgqo4m+SBwTxv3gap69pvDkqTTbM7Qr6p3zrJo0wxjC9g5y3Z2A7sX1J0kaaj8RK4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVk5KGfZEuSh5NMJblq1M8vST0baegnWQL8E3AxsAF4Z5INo+xBkno26jP984Cpqnq0qn4B3ARsHXEPktStpSN+vlXAgYH5g8D5gwOS7AB2tNmfJHn4FJ7vLOAHp7D+YuKxOJnH4xkei5OdEccjHz6l1X9/tgWjDv05VdUuYNcwtpVksqomhrGtFzqPxck8Hs/wWJxssR+PUV/eOQSsGZhf3WqSpBEYdejfA6xPsi7Ji4HLgb0j7kGSujXSyztVdTzJXwO3A0uA3VX14Gl8yqFcJlokPBYn83g8w2NxskV9PFJV4+5BkjQifiJXkjpi6EtSRxZl6PtVD89IsibJXUkeSvJgkivH3dO4JVmS5L4kXxp3L+OWZFmSW5J8J8n+JG8ed0/jlOTv2u/Jt5N8NslLx93TsC260PerHn7DceC9VbUB2Ajs7Px4AFwJ7B93E2eIjwFfqarXA2+k4+OSZBXwt8BEVf0h0zebXD7eroZv0YU+ftXDSarqiar6Zpv+MdO/1KvG29X4JFkNXAp8cty9jFuSVwF/AtwIUFW/qKqnxtrU+C0FXpZkKfBy4H/G3M/QLcbQn+mrHroNuUFJ1gLnAHePuZVx+ijwPuBXY+7jTLAOOAL8S7vc9ckkrxh3U+NSVYeAfwS+BzwBPF1VXx1vV8O3GENfM0jySuDzwHuq6kfj7mcckrwFOFxV9467lzPEUuBc4IaqOgf4X6Db98CSLGf6qsA64PeAVyT5q/F2NXyLMfT9qodnSfIipgP/M1X1hXH3M0YXAG9N8hjTl/0uTPJv421prA4CB6vqxF9+tzD9ItCrPwe+W1VHqur/gC8AfzTmnoZuMYa+X/UwIEmYvma7v6o+Mu5+xqmqrq6q1VW1lul/F3dW1aI7k5uvqnoSOJDkD1ppE/DQGFsat+8BG5O8vP3ebGIRvrF9xn3L5qkaw1c9nOkuAN4FfCvJ/a32/qq6bXwt6QzyN8Bn2gnSo8AVY+5nbKrq7iS3AN9k+q63+1iEX8ng1zBIUkcW4+UdSdIsDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkf8H/qXrrqTsK5oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot data labels\n",
    "plt.hist(y_train_removed.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load AE models weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Norm Model\n",
    "def create_AE01_model(k_size):\n",
    "    input_img = Input(shape=(32, 32, 3))  # 0\n",
    "    conv1 = Conv2D(64, (k_size, k_size), padding='same', name=\"Dense_AE01_1\")(input_img) # 1\n",
    "    conv1 = BatchNormalization(name=\"BN_AE01_1\")(conv1) # 2\n",
    "    conv1 = Activation('relu', name=\"Relu_AE01_1\")(conv1) # 3\n",
    "        \n",
    "    decoded = Conv2D(3, (k_size, k_size), padding='same', name=\"Dense_AE01_2\")(conv1) # 4\n",
    "    decoded = BatchNormalization(name=\"BN_AE01_2\")(decoded) # 5\n",
    "    decoded = Activation('relu', name=\"Relu_AE01_2\")(decoded) # 6\n",
    "    return Model(input_img, decoded)\n",
    "\n",
    "class AE01():\n",
    "    def __init__(self, ksize, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.autoencoder = create_AE01_model(ksize)\n",
    "        self.encoder = None\n",
    "\n",
    "    def compile(self, optimizer='adam', loss='binary_crossentropy'):\n",
    "        self.autoencoder.compile(optimizer=self.optimizer, loss=loss)\n",
    "\n",
    "    def train(self, x_train=None, x_test=None, epochs=1, batch_size=32, shuffle=True):\n",
    "        es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "        ae_model_path = '../models/AE/AE01_AE_Best.hdf5'\n",
    "        cp_cb = ModelCheckpoint(filepath = ae_model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "       \n",
    "        history = self.autoencoder.fit(x_train, x_train,\n",
    "                             epochs=epochs,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=shuffle,\n",
    "                             callbacks=[es_cb, cp_cb],\n",
    "                             validation_data=(x_test, x_test))\n",
    "        \n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        \n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        encode_model_path = '../models/AE/AE01_Encoder_Best.hdf5'\n",
    "        self.encoder.save(encode_model_path)\n",
    "        return history\n",
    "    \n",
    "    def load_weights(self, ae_model_path, encode_model_path):\n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        self.encoder.load_weights(encode_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "Dense_AE01_1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "BN_AE01_1 (BatchNormalizatio (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "Relu_AE01_1 (Activation)     (None, 32, 32, 64)        0         \n",
      "=================================================================\n",
      "Total params: 2,048\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_ksize = 3\n",
    "ae_optimizer = 'rmsprop'\n",
    "stack01 = AE01(ae_ksize, ae_optimizer)\n",
    "stack01.load_weights('../models/AE/AE01_AE_Best.hdf5', '../models/AE/AE01_Encoder_Best.hdf5')\n",
    "stack01.encoder.trainable = False\n",
    "stack01.encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model AE to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_StackedAE01_CNN01_model(encoder):\n",
    "    input_img = encoder.input\n",
    "    output = encoder.layers[-1].output # 32,32,64\n",
    "    x = Conv2D(64,(3,3),padding = \"same\",activation= \"relu\")(output)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) # 16,16,64\n",
    "    \n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) # 8,8,128\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    y = Dense(10,activation = \"softmax\")(x)\n",
    "\n",
    "    return Model(input_img, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train SMOTE without data augumentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1039/1042 [============================>.] - ETA: 0s - loss: 1.3606 - accuracy: 0.5090\n",
      "Epoch 00001: val_loss improved from inf to 1.53881, saving model to ../models/CNN\\Model_023_1_Best.hdf5\n",
      "1042/1042 [==============================] - 7s 7ms/step - loss: 1.3608 - accuracy: 0.5092 - val_loss: 1.5388 - val_accuracy: 0.4863\n",
      "Epoch 2/400\n",
      "1042/1042 [==============================] - ETA: 0s - loss: 0.9534 - accuracy: 0.6628\n",
      "Epoch 00002: val_loss improved from 1.53881 to 0.94970, saving model to ../models/CNN\\Model_023_1_Best.hdf5\n",
      "1042/1042 [==============================] - 7s 6ms/step - loss: 0.9534 - accuracy: 0.6628 - val_loss: 0.9497 - val_accuracy: 0.6679\n",
      "Epoch 3/400\n",
      "1035/1042 [============================>.] - ETA: 0s - loss: 0.7598 - accuracy: 0.7342\n",
      "Epoch 00003: val_loss improved from 0.94970 to 0.88596, saving model to ../models/CNN\\Model_023_1_Best.hdf5\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.7597 - accuracy: 0.7342 - val_loss: 0.8860 - val_accuracy: 0.6959\n",
      "Epoch 4/400\n",
      "1034/1042 [============================>.] - ETA: 0s - loss: 0.6310 - accuracy: 0.7792\n",
      "Epoch 00004: val_loss improved from 0.88596 to 0.78419, saving model to ../models/CNN\\Model_023_1_Best.hdf5\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.6309 - accuracy: 0.7793 - val_loss: 0.7842 - val_accuracy: 0.7340\n",
      "Epoch 5/400\n",
      "1040/1042 [============================>.] - ETA: 0s - loss: 0.5267 - accuracy: 0.8152\n",
      "Epoch 00005: val_loss did not improve from 0.78419\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.5268 - accuracy: 0.8151 - val_loss: 0.8081 - val_accuracy: 0.7270\n",
      "Epoch 6/400\n",
      "1042/1042 [==============================] - ETA: 0s - loss: 0.4383 - accuracy: 0.8473\n",
      "Epoch 00006: val_loss did not improve from 0.78419\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.4383 - accuracy: 0.8473 - val_loss: 0.9644 - val_accuracy: 0.7161\n",
      "Epoch 7/400\n",
      "1042/1042 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.8707\n",
      "Epoch 00007: val_loss did not improve from 0.78419\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.3689 - accuracy: 0.8707 - val_loss: 0.8320 - val_accuracy: 0.7444\n",
      "Epoch 00007: early stopping\n",
      "443/443 [==============================] - 1s 2ms/step - loss: 0.7842 - accuracy: 0.7340\n",
      "Score for fold 1: loss of 0.7841938138008118; accuracy of 73.39591979980469%\n",
      "Epoch 1/400\n",
      "1036/1042 [============================>.] - ETA: 0s - loss: 1.3440 - accuracy: 0.5207\n",
      "Epoch 00001: val_loss improved from inf to 1.66884, saving model to ../models/CNN\\Model_023_2_Best.hdf5\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 1.3420 - accuracy: 0.5215 - val_loss: 1.6688 - val_accuracy: 0.4621\n",
      "Epoch 2/400\n",
      "1032/1042 [============================>.] - ETA: 0s - loss: 0.9449 - accuracy: 0.6676\n",
      "Epoch 00002: val_loss improved from 1.66884 to 1.05722, saving model to ../models/CNN\\Model_023_2_Best.hdf5\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.9438 - accuracy: 0.6680 - val_loss: 1.0572 - val_accuracy: 0.6250\n",
      "Epoch 3/400\n",
      "1032/1042 [============================>.] - ETA: 0s - loss: 0.7561 - accuracy: 0.7356\n",
      "Epoch 00003: val_loss improved from 1.05722 to 0.86167, saving model to ../models/CNN\\Model_023_2_Best.hdf5\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.7554 - accuracy: 0.7360 - val_loss: 0.8617 - val_accuracy: 0.7004\n",
      "Epoch 4/400\n",
      "1034/1042 [============================>.] - ETA: 0s - loss: 0.6283 - accuracy: 0.7802\n",
      "Epoch 00004: val_loss did not improve from 0.86167\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.6274 - accuracy: 0.7805 - val_loss: 1.1610 - val_accuracy: 0.6363\n",
      "Epoch 5/400\n",
      "1034/1042 [============================>.] - ETA: 0s - loss: 0.5305 - accuracy: 0.8151\n",
      "Epoch 00005: val_loss did not improve from 0.86167\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.5307 - accuracy: 0.8150 - val_loss: 1.1954 - val_accuracy: 0.6498\n",
      "Epoch 6/400\n",
      "1035/1042 [============================>.] - ETA: 0s - loss: 0.4394 - accuracy: 0.8468\n",
      "Epoch 00006: val_loss did not improve from 0.86167\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.4399 - accuracy: 0.8466 - val_loss: 1.0016 - val_accuracy: 0.6902\n",
      "Epoch 00006: early stopping\n",
      "443/443 [==============================] - 1s 2ms/step - loss: 0.8617 - accuracy: 0.7004\n",
      "Score for fold 2: loss of 0.8616734147071838; accuracy of 70.04305720329285%\n",
      "Epoch 1/400\n",
      "1039/1042 [============================>.] - ETA: 0s - loss: 1.3485 - accuracy: 0.5176\n",
      "Epoch 00001: val_loss improved from inf to 1.59501, saving model to ../models/CNN\\Model_023_3_Best.hdf5\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 1.3485 - accuracy: 0.5177 - val_loss: 1.5950 - val_accuracy: 0.4521\n",
      "Epoch 2/400\n",
      "1033/1042 [============================>.] - ETA: 0s - loss: 0.9470 - accuracy: 0.6660\n",
      "Epoch 00002: val_loss improved from 1.59501 to 1.22709, saving model to ../models/CNN\\Model_023_3_Best.hdf5\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.9469 - accuracy: 0.6662 - val_loss: 1.2271 - val_accuracy: 0.5784\n",
      "Epoch 3/400\n",
      "1033/1042 [============================>.] - ETA: 0s - loss: 0.7615 - accuracy: 0.7312\n",
      "Epoch 00003: val_loss improved from 1.22709 to 1.04656, saving model to ../models/CNN\\Model_023_3_Best.hdf5\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.7613 - accuracy: 0.7314 - val_loss: 1.0466 - val_accuracy: 0.6572\n",
      "Epoch 4/400\n",
      "1038/1042 [============================>.] - ETA: 0s - loss: 0.6292 - accuracy: 0.7777\n",
      "Epoch 00004: val_loss improved from 1.04656 to 0.98256, saving model to ../models/CNN\\Model_023_3_Best.hdf5\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.6287 - accuracy: 0.7780 - val_loss: 0.9826 - val_accuracy: 0.6674\n",
      "Epoch 5/400\n",
      "1041/1042 [============================>.] - ETA: 0s - loss: 0.5285 - accuracy: 0.8172\n",
      "Epoch 00005: val_loss improved from 0.98256 to 0.87323, saving model to ../models/CNN\\Model_023_3_Best.hdf5\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.5285 - accuracy: 0.8171 - val_loss: 0.8732 - val_accuracy: 0.7219\n",
      "Epoch 6/400\n",
      "1041/1042 [============================>.] - ETA: 0s - loss: 0.4331 - accuracy: 0.8504\n",
      "Epoch 00006: val_loss did not improve from 0.87323\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.4329 - accuracy: 0.8504 - val_loss: 0.8955 - val_accuracy: 0.7224\n",
      "Epoch 7/400\n",
      "1040/1042 [============================>.] - ETA: 0s - loss: 0.3634 - accuracy: 0.8730\n",
      "Epoch 00007: val_loss improved from 0.87323 to 0.84354, saving model to ../models/CNN\\Model_023_3_Best.hdf5\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.3637 - accuracy: 0.8728 - val_loss: 0.8435 - val_accuracy: 0.7418\n",
      "Epoch 8/400\n",
      "1034/1042 [============================>.] - ETA: 0s - loss: 0.3083 - accuracy: 0.8908\n",
      "Epoch 00008: val_loss did not improve from 0.84354\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.3081 - accuracy: 0.8909 - val_loss: 0.9181 - val_accuracy: 0.7323\n",
      "Epoch 9/400\n",
      "1040/1042 [============================>.] - ETA: 0s - loss: 0.2619 - accuracy: 0.9066\n",
      "Epoch 00009: val_loss improved from 0.84354 to 0.83724, saving model to ../models/CNN\\Model_023_3_Best.hdf5\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.2618 - accuracy: 0.9066 - val_loss: 0.8372 - val_accuracy: 0.7636\n",
      "Epoch 10/400\n",
      "1039/1042 [============================>.] - ETA: 0s - loss: 0.2212 - accuracy: 0.9230\n",
      "Epoch 00010: val_loss did not improve from 0.83724\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.2210 - accuracy: 0.9230 - val_loss: 0.8501 - val_accuracy: 0.7610\n",
      "Epoch 11/400\n",
      "1037/1042 [============================>.] - ETA: 0s - loss: 0.1884 - accuracy: 0.9333\n",
      "Epoch 00011: val_loss did not improve from 0.83724\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.1883 - accuracy: 0.9333 - val_loss: 0.9650 - val_accuracy: 0.7559\n",
      "Epoch 12/400\n",
      "1033/1042 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.9419\n",
      "Epoch 00012: val_loss did not improve from 0.83724\n",
      "1042/1042 [==============================] - 6s 6ms/step - loss: 0.1682 - accuracy: 0.9419 - val_loss: 1.0639 - val_accuracy: 0.7501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00012: early stopping\n",
      "443/443 [==============================] - 1s 2ms/step - loss: 0.8372 - accuracy: 0.7636\n",
      "Score for fold 3: loss of 0.8372433185577393; accuracy of 76.35888457298279%\n",
      "Wall time: 14min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "cv_acc = 0\n",
    "cv_f1 = 0\n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model01 = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model01.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "\n",
    "    x_train_ = x_train_removed[train_index]\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "    \n",
    "    # over sampling smote\n",
    "    sm = SMOTE(random_state=42)\n",
    "    x_train_smote = x_train_.reshape(x_train_.shape[0],\n",
    "                                    x_train_.shape[1]*x_train_.shape[2]*x_train_.shape[3])\n",
    "    y_train_smote = y_train_.reshape(y_train_.shape[0])\n",
    "    x_train_smote, y_train_smote = SMOTE().fit_resample(x_train_smote, y_train_smote)\n",
    "    \n",
    "    x_train_smote = x_train_smote.reshape((x_train_smote.shape[0], \n",
    "                                           x_train_removed.shape[1], \n",
    "                                           x_train_removed.shape[2], \n",
    "                                           x_train_removed.shape[3]))\n",
    "\n",
    "    # one hot encoding\n",
    "    y_train_onehot_smote = to_categorical(y_train_smote, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_023_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    model01_history = model01.fit(x_train_smote, y_train_onehot_smote,\n",
    "                          batch_size=32,\n",
    "                          epochs=400,\n",
    "                          verbose=1,\n",
    "                          validation_data=(x_valid_, y_valid_onehot),\n",
    "                          callbacks=[es_cb, cp_cb],\n",
    "                          shuffle=True)\n",
    "    \n",
    "    # inference\n",
    "    model01.load_weights(chkpt)\n",
    "    scores = model01.evaluate(x_valid_, y_valid_onehot)\n",
    "    \n",
    "    # CV value\n",
    "    cv_acc += scores[1]*100\n",
    "    y_valid_pred =  model01.predict(x_valid_)\n",
    "    y_valid_pred = np.argmax(y_valid_pred, axis=1)\n",
    "    cv_f1 += f1_score(y_valid_, y_valid_pred, average='macro')*100\n",
    "    \n",
    "    print(f'Score for fold {fold_no}: {model01.metrics_names[0]} of {scores[0]}; {model01.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    predict = model01.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model01_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79      1000\n",
      "           1       0.73      0.96      0.83      1000\n",
      "           2       0.74      0.60      0.66      1000\n",
      "           3       0.67      0.59      0.63      1000\n",
      "           4       0.79      0.68      0.73      1000\n",
      "           5       0.72      0.74      0.73      1000\n",
      "           6       0.73      0.86      0.79      1000\n",
      "           7       0.79      0.86      0.83      1000\n",
      "           8       0.89      0.83      0.86      1000\n",
      "           9       0.91      0.75      0.82      1000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.77      0.77     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_histories = histories\n",
    "ensemble_predicts = predicts\n",
    "ensemble_predicts_ = ensemble_predicts / n_splits\n",
    "y_pred = np.argmax(ensemble_predicts_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ACC is 73.0,n_splits CV macro F1 is 71.0\n"
     ]
    }
   ],
   "source": [
    "print(f'CV ACC is {cv_acc//n_splits},n_splits CV macro F1 is {cv_f1//n_splits}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train SMOTE with data augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 1.4013 - accuracy: 0.4990\n",
      "Epoch 00001: val_loss improved from inf to 1.27974, saving model to ../models/CNN\\Model_024_1_Best.hdf5\n",
      "1041/1041 [==============================] - 10s 10ms/step - loss: 1.4009 - accuracy: 0.4990 - val_loss: 1.2797 - val_accuracy: 0.5602\n",
      "Epoch 2/400\n",
      "1035/1041 [============================>.] - ETA: 0s - loss: 1.0405 - accuracy: 0.6303\n",
      "Epoch 00002: val_loss improved from 1.27974 to 1.02669, saving model to ../models/CNN\\Model_024_1_Best.hdf5\n",
      "1041/1041 [==============================] - 10s 10ms/step - loss: 1.0393 - accuracy: 0.6306 - val_loss: 1.0267 - val_accuracy: 0.6454\n",
      "Epoch 3/400\n",
      "1037/1041 [============================>.] - ETA: 0s - loss: 0.8817 - accuracy: 0.6888\n",
      "Epoch 00003: val_loss improved from 1.02669 to 1.00696, saving model to ../models/CNN\\Model_024_1_Best.hdf5\n",
      "1041/1041 [==============================] - 10s 10ms/step - loss: 0.8820 - accuracy: 0.6886 - val_loss: 1.0070 - val_accuracy: 0.6570\n",
      "Epoch 4/400\n",
      "1035/1041 [============================>.] - ETA: 0s - loss: 0.7662 - accuracy: 0.7302\n",
      "Epoch 00004: val_loss did not improve from 1.00696\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.7666 - accuracy: 0.7304 - val_loss: 1.1493 - val_accuracy: 0.6147\n",
      "Epoch 5/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.7574\n",
      "Epoch 00005: val_loss improved from 1.00696 to 0.90508, saving model to ../models/CNN\\Model_024_1_Best.hdf5\n",
      "1041/1041 [==============================] - 14s 14ms/step - loss: 0.6908 - accuracy: 0.7574 - val_loss: 0.9051 - val_accuracy: 0.6952\n",
      "Epoch 6/400\n",
      "1039/1041 [============================>.] - ETA: 0s - loss: 0.6301 - accuracy: 0.7808\n",
      "Epoch 00006: val_loss did not improve from 0.90508\n",
      "1041/1041 [==============================] - 13s 12ms/step - loss: 0.6300 - accuracy: 0.7807 - val_loss: 0.9548 - val_accuracy: 0.6828\n",
      "Epoch 7/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.5773 - accuracy: 0.7982\n",
      "Epoch 00007: val_loss improved from 0.90508 to 0.82038, saving model to ../models/CNN\\Model_024_1_Best.hdf5\n",
      "1041/1041 [==============================] - 14s 14ms/step - loss: 0.5773 - accuracy: 0.7982 - val_loss: 0.8204 - val_accuracy: 0.7332\n",
      "Epoch 8/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.5400 - accuracy: 0.8097\n",
      "Epoch 00008: val_loss did not improve from 0.82038\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.5400 - accuracy: 0.8098 - val_loss: 0.9395 - val_accuracy: 0.6989\n",
      "Epoch 9/400\n",
      "1039/1041 [============================>.] - ETA: 0s - loss: 0.4964 - accuracy: 0.8255\n",
      "Epoch 00009: val_loss improved from 0.82038 to 0.74310, saving model to ../models/CNN\\Model_024_1_Best.hdf5\n",
      "1041/1041 [==============================] - 13s 13ms/step - loss: 0.4966 - accuracy: 0.8256 - val_loss: 0.7431 - val_accuracy: 0.7605\n",
      "Epoch 10/400\n",
      "1040/1041 [============================>.] - ETA: 0s - loss: 0.4641 - accuracy: 0.8370\n",
      "Epoch 00010: val_loss did not improve from 0.74310\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.4644 - accuracy: 0.8369 - val_loss: 0.8035 - val_accuracy: 0.7523\n",
      "Epoch 11/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.4417 - accuracy: 0.8433\n",
      "Epoch 00011: val_loss did not improve from 0.74310\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.4417 - accuracy: 0.8433 - val_loss: 0.9160 - val_accuracy: 0.7270\n",
      "Epoch 12/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.4118 - accuracy: 0.8563\n",
      "Epoch 00012: val_loss did not improve from 0.74310\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.4124 - accuracy: 0.8560 - val_loss: 0.8368 - val_accuracy: 0.7498\n",
      "Epoch 00012: early stopping\n",
      "443/443 [==============================] - 1s 3ms/step - loss: 0.7425 - accuracy: 0.7606\n",
      "Score for fold 1: loss of 0.7425298690795898; accuracy of 76.06409192085266%\n",
      "Epoch 1/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 1.4272 - accuracy: 0.4849\n",
      "Epoch 00001: val_loss improved from inf to 1.57489, saving model to ../models/CNN\\Model_024_2_Best.hdf5\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 1.4255 - accuracy: 0.4856 - val_loss: 1.5749 - val_accuracy: 0.4637\n",
      "Epoch 2/400\n",
      "1040/1041 [============================>.] - ETA: 0s - loss: 1.0569 - accuracy: 0.6245\n",
      "Epoch 00002: val_loss improved from 1.57489 to 1.03877, saving model to ../models/CNN\\Model_024_2_Best.hdf5\n",
      "1041/1041 [==============================] - 10s 9ms/step - loss: 1.0570 - accuracy: 0.6245 - val_loss: 1.0388 - val_accuracy: 0.6377\n",
      "Epoch 3/400\n",
      "1040/1041 [============================>.] - ETA: 0s - loss: 0.8919 - accuracy: 0.6857\n",
      "Epoch 00003: val_loss did not improve from 1.03877\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.8916 - accuracy: 0.6859 - val_loss: 1.0421 - val_accuracy: 0.6531\n",
      "Epoch 4/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.7767 - accuracy: 0.7254\n",
      "Epoch 00004: val_loss improved from 1.03877 to 0.89763, saving model to ../models/CNN\\Model_024_2_Best.hdf5\n",
      "1041/1041 [==============================] - 10s 9ms/step - loss: 0.7767 - accuracy: 0.7254 - val_loss: 0.8976 - val_accuracy: 0.6963\n",
      "Epoch 5/400\n",
      "1035/1041 [============================>.] - ETA: 0s - loss: 0.7024 - accuracy: 0.7530\n",
      "Epoch 00005: val_loss improved from 0.89763 to 0.86136, saving model to ../models/CNN\\Model_024_2_Best.hdf5\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.7024 - accuracy: 0.7530 - val_loss: 0.8614 - val_accuracy: 0.7041\n",
      "Epoch 6/400\n",
      "1037/1041 [============================>.] - ETA: 0s - loss: 0.6373 - accuracy: 0.7756\n",
      "Epoch 00006: val_loss improved from 0.86136 to 0.82679, saving model to ../models/CNN\\Model_024_2_Best.hdf5\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.6373 - accuracy: 0.7755 - val_loss: 0.8268 - val_accuracy: 0.7260\n",
      "Epoch 7/400\n",
      "1037/1041 [============================>.] - ETA: 0s - loss: 0.5824 - accuracy: 0.7951\n",
      "Epoch 00007: val_loss improved from 0.82679 to 0.82464, saving model to ../models/CNN\\Model_024_2_Best.hdf5\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.5819 - accuracy: 0.7954 - val_loss: 0.8246 - val_accuracy: 0.7389\n",
      "Epoch 8/400\n",
      "1035/1041 [============================>.] - ETA: 0s - loss: 0.5451 - accuracy: 0.8096\n",
      "Epoch 00008: val_loss improved from 0.82464 to 0.73136, saving model to ../models/CNN\\Model_024_2_Best.hdf5\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.5456 - accuracy: 0.8094 - val_loss: 0.7314 - val_accuracy: 0.7571\n",
      "Epoch 9/400\n",
      "1039/1041 [============================>.] - ETA: 0s - loss: 0.5107 - accuracy: 0.8191\n",
      "Epoch 00009: val_loss did not improve from 0.73136\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.5107 - accuracy: 0.8191 - val_loss: 0.8290 - val_accuracy: 0.7347\n",
      "Epoch 10/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 0.4663 - accuracy: 0.8351\n",
      "Epoch 00010: val_loss did not improve from 0.73136\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.4666 - accuracy: 0.8350 - val_loss: 0.7760 - val_accuracy: 0.7507\n",
      "Epoch 11/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.4463 - accuracy: 0.8435\n",
      "Epoch 00011: val_loss did not improve from 0.73136\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.4465 - accuracy: 0.8435 - val_loss: 0.7518 - val_accuracy: 0.7600\n",
      "Epoch 00011: early stopping\n",
      "443/443 [==============================] - 1s 3ms/step - loss: 0.7320 - accuracy: 0.7570\n",
      "Score for fold 2: loss of 0.731985330581665; accuracy of 75.69704055786133%\n",
      "Epoch 1/400\n",
      "1035/1041 [============================>.] - ETA: 0s - loss: 1.3912 - accuracy: 0.5001\n",
      "Epoch 00001: val_loss improved from inf to 1.20963, saving model to ../models/CNN\\Model_024_3_Best.hdf5\n",
      "1041/1041 [==============================] - 10s 9ms/step - loss: 1.3894 - accuracy: 0.5006 - val_loss: 1.2096 - val_accuracy: 0.5732\n",
      "Epoch 2/400\n",
      "1037/1041 [============================>.] - ETA: 0s - loss: 1.0362 - accuracy: 0.6360\n",
      "Epoch 00002: val_loss improved from 1.20963 to 1.11526, saving model to ../models/CNN\\Model_024_3_Best.hdf5\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 1.0362 - accuracy: 0.6362 - val_loss: 1.1153 - val_accuracy: 0.6053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.8816 - accuracy: 0.6888\n",
      "Epoch 00003: val_loss improved from 1.11526 to 1.02191, saving model to ../models/CNN\\Model_024_3_Best.hdf5\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.8818 - accuracy: 0.6885 - val_loss: 1.0219 - val_accuracy: 0.6588\n",
      "Epoch 4/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.7759 - accuracy: 0.7257\n",
      "Epoch 00004: val_loss improved from 1.02191 to 0.97255, saving model to ../models/CNN\\Model_024_3_Best.hdf5\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.7759 - accuracy: 0.7257 - val_loss: 0.9726 - val_accuracy: 0.6840\n",
      "Epoch 5/400\n",
      "1039/1041 [============================>.] - ETA: 0s - loss: 0.6953 - accuracy: 0.7570\n",
      "Epoch 00005: val_loss improved from 0.97255 to 0.88231, saving model to ../models/CNN\\Model_024_3_Best.hdf5\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.6957 - accuracy: 0.7569 - val_loss: 0.8823 - val_accuracy: 0.6990\n",
      "Epoch 6/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.6337 - accuracy: 0.7772\n",
      "Epoch 00006: val_loss improved from 0.88231 to 0.77972, saving model to ../models/CNN\\Model_024_3_Best.hdf5\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.6337 - accuracy: 0.7772 - val_loss: 0.7797 - val_accuracy: 0.7406\n",
      "Epoch 7/400\n",
      "1035/1041 [============================>.] - ETA: 0s - loss: 0.5791 - accuracy: 0.7982\n",
      "Epoch 00007: val_loss did not improve from 0.77972\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.5786 - accuracy: 0.7983 - val_loss: 0.8346 - val_accuracy: 0.7273\n",
      "Epoch 8/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.5416 - accuracy: 0.8102\n",
      "Epoch 00008: val_loss improved from 0.77972 to 0.74552, saving model to ../models/CNN\\Model_024_3_Best.hdf5\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.5416 - accuracy: 0.8102 - val_loss: 0.7455 - val_accuracy: 0.7538\n",
      "Epoch 9/400\n",
      "1035/1041 [============================>.] - ETA: 0s - loss: 0.5058 - accuracy: 0.8240\n",
      "Epoch 00009: val_loss improved from 0.74552 to 0.71481, saving model to ../models/CNN\\Model_024_3_Best.hdf5\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.5056 - accuracy: 0.8241 - val_loss: 0.7148 - val_accuracy: 0.7704\n",
      "Epoch 10/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.4708 - accuracy: 0.8336\n",
      "Epoch 00010: val_loss did not improve from 0.71481\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.4708 - accuracy: 0.8336 - val_loss: 0.9193 - val_accuracy: 0.7373\n",
      "Epoch 11/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.4352 - accuracy: 0.8458\n",
      "Epoch 00011: val_loss improved from 0.71481 to 0.69436, saving model to ../models/CNN\\Model_024_3_Best.hdf5\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.4352 - accuracy: 0.8458 - val_loss: 0.6944 - val_accuracy: 0.7824\n",
      "Epoch 12/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.8545\n",
      "Epoch 00012: val_loss did not improve from 0.69436\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.4130 - accuracy: 0.8544 - val_loss: 0.8383 - val_accuracy: 0.7507\n",
      "Epoch 13/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.3896 - accuracy: 0.8635\n",
      "Epoch 00013: val_loss did not improve from 0.69436\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.3896 - accuracy: 0.8635 - val_loss: 0.7591 - val_accuracy: 0.7754\n",
      "Epoch 14/400\n",
      "1035/1041 [============================>.] - ETA: 0s - loss: 0.3774 - accuracy: 0.8677\n",
      "Epoch 00014: val_loss did not improve from 0.69436\n",
      "1041/1041 [==============================] - 9s 9ms/step - loss: 0.3770 - accuracy: 0.8679 - val_loss: 0.7695 - val_accuracy: 0.7781\n",
      "Epoch 00014: early stopping\n",
      "443/443 [==============================] - 1s 3ms/step - loss: 0.6946 - accuracy: 0.7824\n",
      "Score for fold 3: loss of 0.6946128010749817; accuracy of 78.23662161827087%\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "cv_acc = 0\n",
    "cv_f1 = 0\n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model02 = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model02.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "\n",
    "    x_train_ = x_train_removed[train_index]\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "\n",
    "    # over sampling smote\n",
    "    sm = SMOTE(random_state=42)\n",
    "    x_train_smote = x_train_.reshape(x_train_.shape[0],\n",
    "                                    x_train_.shape[1]*x_train_.shape[2]*x_train_.shape[3])\n",
    "    y_train_smote = y_train_.reshape(y_train_.shape[0])\n",
    "    x_train_smote, y_train_smote = SMOTE().fit_resample(x_train_smote, y_train_smote)\n",
    "    \n",
    "    x_train_smote = x_train_smote.reshape((x_train_smote.shape[0], \n",
    "                                           x_train_removed.shape[1], \n",
    "                                           x_train_removed.shape[2], \n",
    "                                           x_train_removed.shape[3]))\n",
    "\n",
    "    # one hot encoding\n",
    "    y_train_onehot_smote = to_categorical(y_train_smote, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_024_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    # create generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         rotation_range=10,\n",
    "#         shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "#         vertical_flip=True,\n",
    "#         width_shift_range=0.1,\n",
    "#         height_shift_range=0.1,\n",
    "        zoom_range=0.1\n",
    "#         channel_shift_range=0.2\n",
    "        )\n",
    "\n",
    "    batch_size = 32\n",
    "    train_datagenerator = train_datagen.flow(x_train_smote, y_train_onehot_smote, batch_size)\n",
    "    valid_datagenerator = ImageDataGenerator().flow(x_valid_, y_valid_onehot, batch_size)\n",
    "\n",
    "    model02_history = model02.fit_generator(train_datagenerator,\n",
    "                                  steps_per_epoch=int(len(x_train_smote)//batch_size),\n",
    "                                  epochs=400,\n",
    "                                  validation_data=valid_datagenerator,\n",
    "                                  validation_steps=int(len(x_valid_)//batch_size),\n",
    "                                  verbose=1,\n",
    "                                  shuffle=True,\n",
    "                                  callbacks=[es_cb, cp_cb])\n",
    "\n",
    "    # inference\n",
    "    model02.load_weights(chkpt)\n",
    "    scores = model02.evaluate(x_valid_, y_valid_onehot)\n",
    "    \n",
    "    # CV value\n",
    "    cv_acc += scores[1]*100\n",
    "    y_valid_pred =  model02.predict(x_valid_)\n",
    "    y_valid_pred = np.argmax(y_valid_pred, axis=1)\n",
    "    cv_f1 += f1_score(y_valid_, y_valid_pred, average='macro')*100\n",
    "    \n",
    "    print(f'Score for fold {fold_no}: {model02.metrics_names[0]} of {scores[0]}; {model02.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    # oof prediction\n",
    "    predict = model02.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model02_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84      1000\n",
      "           1       0.90      0.93      0.91      1000\n",
      "           2       0.82      0.65      0.72      1000\n",
      "           3       0.64      0.73      0.68      1000\n",
      "           4       0.91      0.62      0.73      1000\n",
      "           5       0.78      0.76      0.77      1000\n",
      "           6       0.71      0.92      0.80      1000\n",
      "           7       0.80      0.90      0.85      1000\n",
      "           8       0.92      0.90      0.91      1000\n",
      "           9       0.90      0.86      0.88      1000\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.82      0.81      0.81     10000\n",
      "weighted avg       0.82      0.81      0.81     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_dataaug_histories = histories\n",
    "ensemble_dataaug_predicts = predicts\n",
    "ensemble_dataaug_predicts_ = ensemble_dataaug_predicts / n_splits\n",
    "y_pred = np.argmax(ensemble_dataaug_predicts_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ACC is 76.0, CV macro F1 is 75.0\n"
     ]
    }
   ],
   "source": [
    "print(f'CV ACC is {cv_acc//n_splits}, CV macro F1 is {cv_f1//n_splits}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
