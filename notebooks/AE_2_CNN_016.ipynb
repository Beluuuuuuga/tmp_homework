{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_randvalue(value):\n",
    "    # Set a seed value\n",
    "    seed_value= value \n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "set_randvalue(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() # load data\n",
    "x_train,x_test = x_train.astype('float32')/255.0,x_test.astype('float32')/255.0 # normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit three class preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird label num is 2500\n",
      "Deer label num is 2500\n",
      "Truck label num is 2500\n",
      "Other label num is 35000\n",
      "Train label num is 42500\n",
      "(42500, 32, 32, 3)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "# No method on keras to get cifar10 category label name by categoly label?\n",
    "cifar10_labels = np.array([\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'])\n",
    "\n",
    "bird_num = np.where(cifar10_labels=='bird')\n",
    "deer_num = np.where(cifar10_labels=='deer')\n",
    "truck_num = np.where(cifar10_labels=='truck')\n",
    "\n",
    "limit_num = 2500\n",
    "\n",
    "# get limit label indexes\n",
    "bird_indexes = [i for i, label in enumerate(y_train) if label == bird_num]\n",
    "deer_indexes = [i for i, label in enumerate(y_train) if label == deer_num] \n",
    "truck_indexes = [i for i, label in enumerate(y_train) if label == truck_num] \n",
    "other_indexes = [i for i, label in enumerate(y_train) if label not in [bird_num, deer_num, truck_num]]\n",
    "\n",
    "# limit\n",
    "bird_indexes = bird_indexes[:limit_num]\n",
    "deer_indexes = deer_indexes[:limit_num]\n",
    "truck_indexes = truck_indexes[:limit_num]\n",
    "print(f'Bird label num is {len(bird_indexes)}') # 2500\n",
    "print(f'Deer label num is {len(deer_indexes)}') # 2500\n",
    "print(f'Truck label num is {len(truck_indexes)}') # 2500\n",
    "print(f'Other label num is {len(other_indexes)}') # 35000; 5000*7\n",
    "\n",
    "# merge and sort\n",
    "merge_indexes = np.concatenate([other_indexes, bird_indexes, deer_indexes, truck_indexes], 0)\n",
    "merge_indexes.sort()\n",
    "print(f'Train label num is {len(merge_indexes)}') # 42500\n",
    "\n",
    "# create three labels removed train data\n",
    "x_train_removed =  np.zeros((len(merge_indexes), 32, 32, 3))\n",
    "y_train_removed =  np.zeros(len(merge_indexes))\n",
    "\n",
    "for i, train_index in enumerate(merge_indexes):\n",
    "    x_train_removed[i] = x_train[train_index]\n",
    "    y_train_removed[i] = y_train[train_index]\n",
    "    \n",
    "print(x_train_removed.shape)\n",
    "print(y_train_removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0    5000\n",
      "7.0    5000\n",
      "6.0    5000\n",
      "5.0    5000\n",
      "3.0    5000\n",
      "1.0    5000\n",
      "0.0    5000\n",
      "9.0    2500\n",
      "4.0    2500\n",
      "2.0    2500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df = pd.DataFrame(y_train_removed.flatten())\n",
    "df = pd.DataFrame(y_train_removed.flatten())\n",
    "print(df.value_counts())\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5000., 5000., 2500., 5000., 2500., 5000., 5000., 5000., 5000.,\n",
       "        2500.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot data labels\n",
    "plt.hist(y_train_removed.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load AE models weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Norm Model\n",
    "def create_AE01_model(k_size):\n",
    "    input_img = Input(shape=(32, 32, 3))  # 0\n",
    "    conv1 = Conv2D(64, (k_size, k_size), padding='same', name=\"Dense_AE01_1\")(input_img) # 1\n",
    "    conv1 = BatchNormalization(name=\"BN_AE01_1\")(conv1) # 2\n",
    "    conv1 = Activation('relu', name=\"Relu_AE01_1\")(conv1) # 3\n",
    "        \n",
    "    decoded = Conv2D(3, (k_size, k_size), padding='same', name=\"Dense_AE01_2\")(conv1) # 4\n",
    "    decoded = BatchNormalization(name=\"BN_AE01_2\")(decoded) # 5\n",
    "    decoded = Activation('relu', name=\"Relu_AE01_2\")(decoded) # 6\n",
    "    return Model(input_img, decoded)\n",
    "\n",
    "class AE01():\n",
    "    def __init__(self, ksize, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.autoencoder = create_AE01_model(ksize)\n",
    "        self.encoder = None\n",
    "\n",
    "    def compile(self, optimizer='adam', loss='binary_crossentropy'):\n",
    "        self.autoencoder.compile(optimizer=self.optimizer, loss=loss)\n",
    "\n",
    "    def train(self, x_train=None, x_test=None, epochs=1, batch_size=32, shuffle=True):\n",
    "        es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "        ae_model_path = '../models/AE/AE01_AE_Best.hdf5'\n",
    "        cp_cb = ModelCheckpoint(filepath = ae_model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "       \n",
    "        history = self.autoencoder.fit(x_train, x_train,\n",
    "                             epochs=epochs,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=shuffle,\n",
    "                             callbacks=[es_cb, cp_cb],\n",
    "                             validation_data=(x_test, x_test))\n",
    "        \n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        \n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        encode_model_path = '../models/AE/AE01_Encoder_Best.hdf5'\n",
    "        self.encoder.save(encode_model_path)\n",
    "        return history\n",
    "    \n",
    "    def load_weights(self, ae_model_path, encode_model_path):\n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        self.encoder.load_weights(encode_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "Dense_AE01_1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "BN_AE01_1 (BatchNormalizatio (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "Relu_AE01_1 (Activation)     (None, 32, 32, 64)        0         \n",
      "=================================================================\n",
      "Total params: 2,048\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_ksize = 3\n",
    "ae_optimizer = 'rmsprop'\n",
    "stack01 = AE01(ae_ksize, ae_optimizer)\n",
    "stack01.load_weights('../models/AE/AE01_AE_Best.hdf5', '../models/AE/AE01_Encoder_Best.hdf5')\n",
    "stack01.encoder.trainable = False\n",
    "stack01.encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model AE to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_StackedAE01_CNN01_model(encoder):\n",
    "    input_img = encoder.input\n",
    "    output = encoder.layers[-1].output # 32,32,64\n",
    "    x = Conv2D(64,(3,3),padding = \"same\",activation= \"relu\")(output) # 2\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64,(3,3),padding = \"same\",activation= \"relu\")(x) # 3\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64,(3,3),padding = \"same\",activation= \"relu\")(x) # 4\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) # 16,16,64\n",
    "    \n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x) # 5\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x) # 6\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x) # 7\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) # 8,8,128\n",
    "\n",
    "    x = Conv2D(256,(3,3),padding = \"same\",activation= \"relu\")(x) # 8\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(256,(3,3),padding = \"same\",activation= \"relu\")(x) # 9\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(256,(3,3),padding = \"same\",activation= \"relu\")(x) # 10\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256)(x) # 11\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    y = Dense(10,activation = \"softmax\")(x) # 12\n",
    "\n",
    "    return Model(input_img, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Over sampling with data augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target label num is 3334, and total label num is 33336\n",
      "Epoch 1/400\n",
      "1039/1041 [============================>.] - ETA: 0s - loss: 1.5871 - accuracy: 0.4165\n",
      "Epoch 00001: val_loss improved from inf to 1.49587, saving model to ../models/CNN\\Model_034_1_Best.hdf5\n",
      "1041/1041 [==============================] - 12s 11ms/step - loss: 1.5865 - accuracy: 0.4168 - val_loss: 1.4959 - val_accuracy: 0.4955\n",
      "Epoch 2/400\n",
      "1040/1041 [============================>.] - ETA: 0s - loss: 1.1096 - accuracy: 0.6074\n",
      "Epoch 00002: val_loss improved from 1.49587 to 0.91750, saving model to ../models/CNN\\Model_034_1_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 1.1095 - accuracy: 0.6076 - val_loss: 0.9175 - val_accuracy: 0.6766\n",
      "Epoch 3/400\n",
      "1039/1041 [============================>.] - ETA: 0s - loss: 0.8397 - accuracy: 0.7071\n",
      "Epoch 00003: val_loss did not improve from 0.91750\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.8395 - accuracy: 0.7072 - val_loss: 1.4220 - val_accuracy: 0.5993\n",
      "Epoch 4/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 0.6858 - accuracy: 0.7597\n",
      "Epoch 00004: val_loss improved from 0.91750 to 0.70483, saving model to ../models/CNN\\Model_034_1_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.6858 - accuracy: 0.7598 - val_loss: 0.7048 - val_accuracy: 0.7570\n",
      "Epoch 5/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.5863 - accuracy: 0.7990\n",
      "Epoch 00005: val_loss improved from 0.70483 to 0.63227, saving model to ../models/CNN\\Model_034_1_Best.hdf5\n",
      "1041/1041 [==============================] - 12s 11ms/step - loss: 0.5863 - accuracy: 0.7990 - val_loss: 0.6323 - val_accuracy: 0.7838\n",
      "Epoch 6/400\n",
      "1039/1041 [============================>.] - ETA: 0s - loss: 0.5132 - accuracy: 0.8249\n",
      "Epoch 00006: val_loss improved from 0.63227 to 0.57984, saving model to ../models/CNN\\Model_034_1_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.5133 - accuracy: 0.8248 - val_loss: 0.5798 - val_accuracy: 0.8020\n",
      "Epoch 7/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 0.4444 - accuracy: 0.8485\n",
      "Epoch 00007: val_loss improved from 0.57984 to 0.57727, saving model to ../models/CNN\\Model_034_1_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.4448 - accuracy: 0.8483 - val_loss: 0.5773 - val_accuracy: 0.8117\n",
      "Epoch 8/400\n",
      "1039/1041 [============================>.] - ETA: 0s - loss: 0.3984 - accuracy: 0.8643\n",
      "Epoch 00008: val_loss improved from 0.57727 to 0.34898, saving model to ../models/CNN\\Model_034_1_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.3983 - accuracy: 0.8642 - val_loss: 0.3490 - val_accuracy: 0.8791\n",
      "Epoch 9/400\n",
      "1037/1041 [============================>.] - ETA: 0s - loss: 0.3598 - accuracy: 0.8763\n",
      "Epoch 00009: val_loss did not improve from 0.34898\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.3598 - accuracy: 0.8763 - val_loss: 0.3802 - val_accuracy: 0.8714\n",
      "Epoch 10/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 0.3149 - accuracy: 0.8905\n",
      "Epoch 00010: val_loss did not improve from 0.34898\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.3151 - accuracy: 0.8904 - val_loss: 0.3568 - val_accuracy: 0.8824\n",
      "Epoch 11/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.2857 - accuracy: 0.9009\n",
      "Epoch 00011: val_loss did not improve from 0.34898\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.2854 - accuracy: 0.9010 - val_loss: 0.3952 - val_accuracy: 0.8713\n",
      "Epoch 00011: early stopping\n",
      "443/443 [==============================] - 2s 4ms/step - loss: 0.3495 - accuracy: 0.8789\n",
      "Score for fold 1: loss of 0.3495228588581085; accuracy of 87.89440393447876%\n",
      "Target label num is 3333, and total label num is 33331\n",
      "Epoch 1/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 1.5889 - accuracy: 0.4182\n",
      "Epoch 00001: val_loss improved from inf to 1.52092, saving model to ../models/CNN\\Model_034_2_Best.hdf5\n",
      "1041/1041 [==============================] - 12s 11ms/step - loss: 1.5889 - accuracy: 0.4182 - val_loss: 1.5209 - val_accuracy: 0.4560\n",
      "Epoch 2/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 1.1354 - accuracy: 0.5948\n",
      "Epoch 00002: val_loss improved from 1.52092 to 1.02362, saving model to ../models/CNN\\Model_034_2_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 1.1352 - accuracy: 0.5948 - val_loss: 1.0236 - val_accuracy: 0.6304\n",
      "Epoch 3/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.8644 - accuracy: 0.6987\n",
      "Epoch 00003: val_loss improved from 1.02362 to 0.79583, saving model to ../models/CNN\\Model_034_2_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.8636 - accuracy: 0.6990 - val_loss: 0.7958 - val_accuracy: 0.7309\n",
      "Epoch 4/400\n",
      "1039/1041 [============================>.] - ETA: 0s - loss: 0.6953 - accuracy: 0.7589\n",
      "Epoch 00004: val_loss improved from 0.79583 to 0.60280, saving model to ../models/CNN\\Model_034_2_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.6955 - accuracy: 0.7587 - val_loss: 0.6028 - val_accuracy: 0.7916\n",
      "Epoch 5/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.6000 - accuracy: 0.7945\n",
      "Epoch 00005: val_loss did not improve from 0.60280\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.6000 - accuracy: 0.7945 - val_loss: 0.7418 - val_accuracy: 0.7410\n",
      "Epoch 6/400\n",
      "1037/1041 [============================>.] - ETA: 0s - loss: 0.5084 - accuracy: 0.8220\n",
      "Epoch 00006: val_loss did not improve from 0.60280\n",
      "1041/1041 [==============================] - 12s 11ms/step - loss: 0.5081 - accuracy: 0.8221 - val_loss: 0.6496 - val_accuracy: 0.7803\n",
      "Epoch 7/400\n",
      "1037/1041 [============================>.] - ETA: 0s - loss: 0.4524 - accuracy: 0.8455\n",
      "Epoch 00007: val_loss improved from 0.60280 to 0.45159, saving model to ../models/CNN\\Model_034_2_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.4519 - accuracy: 0.8458 - val_loss: 0.4516 - val_accuracy: 0.8494\n",
      "Epoch 8/400\n",
      "1040/1041 [============================>.] - ETA: 0s - loss: 0.3983 - accuracy: 0.8622\n",
      "Epoch 00008: val_loss improved from 0.45159 to 0.43341, saving model to ../models/CNN\\Model_034_2_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.3981 - accuracy: 0.8622 - val_loss: 0.4334 - val_accuracy: 0.8528\n",
      "Epoch 9/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.3540 - accuracy: 0.8798\n",
      "Epoch 00009: val_loss did not improve from 0.43341\n",
      "1041/1041 [==============================] - 12s 11ms/step - loss: 0.3540 - accuracy: 0.8798 - val_loss: 0.4353 - val_accuracy: 0.8535\n",
      "Epoch 10/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.3148 - accuracy: 0.8936\n",
      "Epoch 00010: val_loss improved from 0.43341 to 0.35913, saving model to ../models/CNN\\Model_034_2_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.3145 - accuracy: 0.8937 - val_loss: 0.3591 - val_accuracy: 0.8798\n",
      "Epoch 11/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 0.2823 - accuracy: 0.9029\n",
      "Epoch 00011: val_loss improved from 0.35913 to 0.31775, saving model to ../models/CNN\\Model_034_2_Best.hdf5\n",
      "1041/1041 [==============================] - 12s 11ms/step - loss: 0.2825 - accuracy: 0.9028 - val_loss: 0.3177 - val_accuracy: 0.8958\n",
      "Epoch 12/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 0.2532 - accuracy: 0.9124\n",
      "Epoch 00012: val_loss did not improve from 0.31775\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.2534 - accuracy: 0.9124 - val_loss: 0.3385 - val_accuracy: 0.8891\n",
      "Epoch 13/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 0.2345 - accuracy: 0.9202\n",
      "Epoch 00013: val_loss improved from 0.31775 to 0.29861, saving model to ../models/CNN\\Model_034_2_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.2345 - accuracy: 0.9202 - val_loss: 0.2986 - val_accuracy: 0.9017\n",
      "Epoch 14/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.9297\n",
      "Epoch 00014: val_loss did not improve from 0.29861\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.2075 - accuracy: 0.9297 - val_loss: 0.3716 - val_accuracy: 0.8845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/400\n",
      "1040/1041 [============================>.] - ETA: 0s - loss: 0.1908 - accuracy: 0.9343\n",
      "Epoch 00015: val_loss improved from 0.29861 to 0.26326, saving model to ../models/CNN\\Model_034_2_Best.hdf5\n",
      "1041/1041 [==============================] - 12s 11ms/step - loss: 0.1909 - accuracy: 0.9343 - val_loss: 0.2633 - val_accuracy: 0.9159\n",
      "Epoch 16/400\n",
      "1037/1041 [============================>.] - ETA: 0s - loss: 0.1760 - accuracy: 0.9385\n",
      "Epoch 00016: val_loss did not improve from 0.26326\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.1759 - accuracy: 0.9386 - val_loss: 0.2896 - val_accuracy: 0.9104\n",
      "Epoch 17/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.1675 - accuracy: 0.9417\n",
      "Epoch 00017: val_loss improved from 0.26326 to 0.25430, saving model to ../models/CNN\\Model_034_2_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.1677 - accuracy: 0.9416 - val_loss: 0.2543 - val_accuracy: 0.9232\n",
      "Epoch 18/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9474\n",
      "Epoch 00018: val_loss did not improve from 0.25430\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.1508 - accuracy: 0.9474 - val_loss: 0.3456 - val_accuracy: 0.8988\n",
      "Epoch 19/400\n",
      "1039/1041 [============================>.] - ETA: 0s - loss: 0.1404 - accuracy: 0.9520\n",
      "Epoch 00019: val_loss did not improve from 0.25430\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.1404 - accuracy: 0.9520 - val_loss: 0.3970 - val_accuracy: 0.8899\n",
      "Epoch 20/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.1318 - accuracy: 0.9545\n",
      "Epoch 00020: val_loss did not improve from 0.25430\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.1318 - accuracy: 0.9545 - val_loss: 0.2667 - val_accuracy: 0.9223\n",
      "Epoch 00020: early stopping\n",
      "443/443 [==============================] - 2s 4ms/step - loss: 0.2539 - accuracy: 0.9233\n",
      "Score for fold 2: loss of 0.2538985013961792; accuracy of 92.33430027961731%\n",
      "Target label num is 3333, and total label num is 33333\n",
      "Epoch 1/400\n",
      "1039/1041 [============================>.] - ETA: 0s - loss: 1.5852 - accuracy: 0.4234\n",
      "Epoch 00001: val_loss improved from inf to 1.49084, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 12s 11ms/step - loss: 1.5847 - accuracy: 0.4236 - val_loss: 1.4908 - val_accuracy: 0.4717\n",
      "Epoch 2/400\n",
      "1037/1041 [============================>.] - ETA: 0s - loss: 1.1513 - accuracy: 0.5916\n",
      "Epoch 00002: val_loss improved from 1.49084 to 1.12646, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 1.1508 - accuracy: 0.5917 - val_loss: 1.1265 - val_accuracy: 0.6041\n",
      "Epoch 3/400\n",
      "1040/1041 [============================>.] - ETA: 0s - loss: 0.8786 - accuracy: 0.6937\n",
      "Epoch 00003: val_loss improved from 1.12646 to 0.86370, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.8786 - accuracy: 0.6936 - val_loss: 0.8637 - val_accuracy: 0.6928\n",
      "Epoch 4/400\n",
      "1040/1041 [============================>.] - ETA: 0s - loss: 0.7152 - accuracy: 0.7522\n",
      "Epoch 00004: val_loss improved from 0.86370 to 0.70043, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 12s 11ms/step - loss: 0.7151 - accuracy: 0.7523 - val_loss: 0.7004 - val_accuracy: 0.7563\n",
      "Epoch 5/400\n",
      "1037/1041 [============================>.] - ETA: 0s - loss: 0.6068 - accuracy: 0.7906\n",
      "Epoch 00005: val_loss improved from 0.70043 to 0.54921, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.6063 - accuracy: 0.7907 - val_loss: 0.5492 - val_accuracy: 0.8086\n",
      "Epoch 6/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 0.5242 - accuracy: 0.8213\n",
      "Epoch 00006: val_loss improved from 0.54921 to 0.51477, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.5244 - accuracy: 0.8213 - val_loss: 0.5148 - val_accuracy: 0.8240\n",
      "Epoch 7/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.4584 - accuracy: 0.8428\n",
      "Epoch 00007: val_loss did not improve from 0.51477\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.4584 - accuracy: 0.8428 - val_loss: 0.5170 - val_accuracy: 0.8250\n",
      "Epoch 8/400\n",
      "1037/1041 [============================>.] - ETA: 0s - loss: 0.4083 - accuracy: 0.8619\n",
      "Epoch 00008: val_loss improved from 0.51477 to 0.47198, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.4088 - accuracy: 0.8618 - val_loss: 0.4720 - val_accuracy: 0.8389\n",
      "Epoch 9/400\n",
      "1037/1041 [============================>.] - ETA: 0s - loss: 0.3612 - accuracy: 0.8773\n",
      "Epoch 00009: val_loss improved from 0.47198 to 0.42584, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.3610 - accuracy: 0.8774 - val_loss: 0.4258 - val_accuracy: 0.8541\n",
      "Epoch 10/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.3229 - accuracy: 0.8894\n",
      "Epoch 00010: val_loss improved from 0.42584 to 0.40232, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.3229 - accuracy: 0.8894 - val_loss: 0.4023 - val_accuracy: 0.8647\n",
      "Epoch 11/400\n",
      "1037/1041 [============================>.] - ETA: 0s - loss: 0.2916 - accuracy: 0.9013\n",
      "Epoch 00011: val_loss improved from 0.40232 to 0.40141, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.2912 - accuracy: 0.9015 - val_loss: 0.4014 - val_accuracy: 0.8640\n",
      "Epoch 12/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.2598 - accuracy: 0.9114\n",
      "Epoch 00012: val_loss improved from 0.40141 to 0.33131, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.2595 - accuracy: 0.9113 - val_loss: 0.3313 - val_accuracy: 0.8889\n",
      "Epoch 13/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.9183\n",
      "Epoch 00013: val_loss improved from 0.33131 to 0.31643, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.2418 - accuracy: 0.9183 - val_loss: 0.3164 - val_accuracy: 0.8978\n",
      "Epoch 14/400\n",
      "1038/1041 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 0.9249\n",
      "Epoch 00014: val_loss did not improve from 0.31643\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.2199 - accuracy: 0.9249 - val_loss: 0.7429 - val_accuracy: 0.8081\n",
      "Epoch 15/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.2055 - accuracy: 0.9292\n",
      "Epoch 00015: val_loss did not improve from 0.31643\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.2055 - accuracy: 0.9291 - val_loss: 0.3252 - val_accuracy: 0.8971\n",
      "Epoch 16/400\n",
      "1040/1041 [============================>.] - ETA: 0s - loss: 0.1796 - accuracy: 0.9389\n",
      "Epoch 00016: val_loss improved from 0.31643 to 0.30608, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.1797 - accuracy: 0.9389 - val_loss: 0.3061 - val_accuracy: 0.9050\n",
      "Epoch 17/400\n",
      "1039/1041 [============================>.] - ETA: 0s - loss: 0.1728 - accuracy: 0.9398\n",
      "Epoch 00017: val_loss improved from 0.30608 to 0.25227, saving model to ../models/CNN\\Model_034_3_Best.hdf5\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.1727 - accuracy: 0.9399 - val_loss: 0.2523 - val_accuracy: 0.9198\n",
      "Epoch 18/400\n",
      "1040/1041 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9452\n",
      "Epoch 00018: val_loss did not improve from 0.25227\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.1567 - accuracy: 0.9452 - val_loss: 0.2869 - val_accuracy: 0.9136\n",
      "Epoch 19/400\n",
      "1041/1041 [==============================] - ETA: 0s - loss: 0.1455 - accuracy: 0.9494\n",
      "Epoch 00019: val_loss did not improve from 0.25227\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.1455 - accuracy: 0.9494 - val_loss: 0.2879 - val_accuracy: 0.9157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/400\n",
      "1036/1041 [============================>.] - ETA: 0s - loss: 0.1404 - accuracy: 0.9521\n",
      "Epoch 00020: val_loss did not improve from 0.25227\n",
      "1041/1041 [==============================] - 11s 11ms/step - loss: 0.1405 - accuracy: 0.9521 - val_loss: 0.3358 - val_accuracy: 0.9060\n",
      "Epoch 00020: early stopping\n",
      "443/443 [==============================] - 2s 4ms/step - loss: 0.2524 - accuracy: 0.9197\n",
      "Score for fold 3: loss of 0.2524416744709015; accuracy of 91.96668267250061%\n",
      "Wall time: 10min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cifar10_labels = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck']\n",
    "\n",
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "cv_acc = 0\n",
    "cv_f1 = 0 \n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model02 = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model02.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "\n",
    "    # get target label num\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    df_train = pd.DataFrame(y_train_, columns=['label'])\n",
    "    target_index = df_train[df_train['label'] == cifar10_labels.index('dog')].index # bird label\n",
    "    limit_num = len(target_index)\n",
    "\n",
    "    # concat nate for over sampling\n",
    "    train_index_oversampling = np.concatenate([\n",
    "        # target label\n",
    "        df_train[df_train['label'] == cifar10_labels.index('bird')].sample(limit_num, random_state=42, replace=True).index.values, # bird\n",
    "        df_train[df_train['label'] == cifar10_labels.index('deer')].sample(limit_num, random_state=42, replace=True).index.values, # deer\n",
    "        df_train[df_train['label'] == cifar10_labels.index('truck')].sample(limit_num, random_state=42, replace=True).index.values, # truck\n",
    "        # other label\n",
    "        df_train[df_train['label'] == cifar10_labels.index('airplane')].index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('automobile')].index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('cat')].index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('dog')].index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('frog')].index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('horse')].index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('ship')].index.values\n",
    "    ])\n",
    "\n",
    "    print(f'Target label num is {limit_num}, and total label num is {len(train_index_oversampling)}')\n",
    "    \n",
    "    x_train_ = x_train_removed[train_index_oversampling]\n",
    "    y_train_ = y_train_removed[train_index_oversampling]\n",
    "    \n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "\n",
    "    # one hot encoding\n",
    "    y_train_onehot = to_categorical(y_train_, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_034_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    # create generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         rotation_range=10,\n",
    "#         shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "#         vertical_flip=True,\n",
    "#         width_shift_range=0.1,\n",
    "#         height_shift_range=0.1,\n",
    "        zoom_range=0.1\n",
    "#         channel_shift_range=0.2\n",
    "        )\n",
    "\n",
    "    batch_size = 32\n",
    "    train_datagenerator = train_datagen.flow(x_train_, y_train_onehot, batch_size)\n",
    "    valid_datagenerator = ImageDataGenerator().flow(x_valid_, y_valid_onehot, batch_size)\n",
    "\n",
    "    model02_history = model02.fit_generator(train_datagenerator,\n",
    "                                  steps_per_epoch=int(len(x_train_)//batch_size),\n",
    "                                  epochs=400,\n",
    "                                  validation_data=valid_datagenerator,\n",
    "                                  validation_steps=int(len(x_valid_)//batch_size),\n",
    "                                  verbose=1,\n",
    "                                  shuffle=True,\n",
    "                                  callbacks=[es_cb, cp_cb])\n",
    "\n",
    "    # inference\n",
    "    model02.load_weights(chkpt)\n",
    "    scores = model02.evaluate(x_valid_, y_valid_onehot)\n",
    "    \n",
    "    # CV value\n",
    "    cv_acc += scores[1]*100\n",
    "    y_valid_pred =  model02.predict(x_valid_)\n",
    "    y_valid_pred = np.argmax(y_valid_pred, axis=1)\n",
    "    cv_f1 += f1_score(y_valid_, y_valid_pred, average='macro')*100\n",
    "    \n",
    "    print(f'Score for fold {fold_no}: {model02.metrics_names[0]} of {scores[0]}; {model02.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    predict = model02.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model02_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      1000\n",
      "           1       0.93      0.95      0.94      1000\n",
      "           2       0.90      0.73      0.81      1000\n",
      "           3       0.74      0.79      0.77      1000\n",
      "           4       0.87      0.84      0.86      1000\n",
      "           5       0.81      0.84      0.83      1000\n",
      "           6       0.85      0.93      0.89      1000\n",
      "           7       0.91      0.92      0.92      1000\n",
      "           8       0.96      0.93      0.94      1000\n",
      "           9       0.91      0.93      0.92      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_dataaug_histories = histories\n",
    "ensemble_dataaug_predicts = predicts\n",
    "ensemble_dataaug_predicts_ = ensemble_dataaug_predicts / n_splits\n",
    "y_pred = np.argmax(ensemble_dataaug_predicts_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ACC is 90.0,n_splits CV macro F1 is 90.0\n"
     ]
    }
   ],
   "source": [
    "print(f'CV ACC is {cv_acc//n_splits},n_splits CV macro F1 is {cv_f1//n_splits}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
