{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "short-humanitarian",
   "metadata": {},
   "source": [
    "# Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "manufactured-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "planned-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_randvalue(value):\n",
    "    # Set a seed value\n",
    "    seed_value= value \n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "set_randvalue(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-skill",
   "metadata": {},
   "source": [
    "## Dataset preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quarterly-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() # load data\n",
    "x_train,x_test = x_train.astype('float32')/255.0,x_test.astype('float32')/255.0 # normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reliable-philippines",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "moderate-effort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-vitamin",
   "metadata": {},
   "source": [
    "#### Limit three class preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "chief-weapon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird label num is 2500\n",
      "Deer label num is 2500\n",
      "Truck label num is 2500\n",
      "Other label num is 35000\n",
      "Train label num is 42500\n",
      "(42500, 32, 32, 3)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "# No method on keras to get cifar10 category label name by categoly label?\n",
    "cifar10_labels = np.array([\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'])\n",
    "\n",
    "bird_num = np.where(cifar10_labels=='bird')\n",
    "deer_num = np.where(cifar10_labels=='deer')\n",
    "truck_num = np.where(cifar10_labels=='truck')\n",
    "\n",
    "limit_num = 2500\n",
    "\n",
    "# get limit label indexes\n",
    "bird_indexes = [i for i, label in enumerate(y_train) if label == bird_num]\n",
    "deer_indexes = [i for i, label in enumerate(y_train) if label == deer_num] \n",
    "truck_indexes = [i for i, label in enumerate(y_train) if label == truck_num] \n",
    "other_indexes = [i for i, label in enumerate(y_train) if label not in [bird_num, deer_num, truck_num]]\n",
    "\n",
    "# limit\n",
    "bird_indexes = bird_indexes[:limit_num]\n",
    "deer_indexes = deer_indexes[:limit_num]\n",
    "truck_indexes = truck_indexes[:limit_num]\n",
    "print(f'Bird label num is {len(bird_indexes)}') # 2500\n",
    "print(f'Deer label num is {len(deer_indexes)}') # 2500\n",
    "print(f'Truck label num is {len(truck_indexes)}') # 2500\n",
    "print(f'Other label num is {len(other_indexes)}') # 35000; 5000*7\n",
    "\n",
    "# merge and sort\n",
    "merge_indexes = np.concatenate([other_indexes, bird_indexes, deer_indexes, truck_indexes], 0)\n",
    "merge_indexes.sort()\n",
    "print(f'Train label num is {len(merge_indexes)}') # 42500\n",
    "\n",
    "# create three labels removed train data\n",
    "x_train_removed =  np.zeros((len(merge_indexes), 32, 32, 3))\n",
    "y_train_removed =  np.zeros(len(merge_indexes))\n",
    "\n",
    "for i, train_index in enumerate(merge_indexes):\n",
    "    x_train_removed[i] = x_train[train_index]\n",
    "    y_train_removed[i] = y_train[train_index]\n",
    "    \n",
    "print(x_train_removed.shape)\n",
    "print(y_train_removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "horizontal-swift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train.shape\n",
    "# df_train = pd.DataFrame(y_train, columns=['label'])\n",
    "# index = df_train[df_train['label'] == 2].index\n",
    "# len(index)\n",
    "bird_num[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-bhutan",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "floral-hormone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target label num is 7500\n",
      "Other label num is 35000\n"
     ]
    }
   ],
   "source": [
    "# merge and sort\n",
    "target_indexes = np.concatenate([bird_indexes, deer_indexes, truck_indexes], 0)\n",
    "target_indexes.sort()\n",
    "print(f'Target label num is {len(target_indexes)}') # 7500\n",
    "print(f'Other label num is {len(other_indexes)}') # 35000\n",
    "\n",
    "# create three labels removed train data\n",
    "x_train_target =  np.zeros((len(target_indexes), 32, 32, 3))\n",
    "y_train_target =  np.zeros(len(target_indexes))\n",
    "\n",
    "for i, train_index in enumerate(target_indexes):\n",
    "    x_train_target[i] = x_train[train_index]\n",
    "    y_train_target[i] = y_train[train_index]\n",
    "\n",
    "x_train_other =  np.zeros((len(other_indexes), 32, 32, 3))\n",
    "y_train_other =  np.zeros(len(other_indexes))\n",
    "\n",
    "for i, train_index in enumerate(other_indexes):\n",
    "    x_train_other[i] = x_train[train_index]\n",
    "    y_train_other[i] = y_train[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opened-regression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    5000\n",
      "1.0    5000\n",
      "3.0    5000\n",
      "5.0    5000\n",
      "6.0    5000\n",
      "7.0    5000\n",
      "8.0    5000\n",
      "2.0    2500\n",
      "4.0    2500\n",
      "9.0    2500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df = pd.DataFrame(y_train_removed.flatten())\n",
    "df = pd.DataFrame(y_train_removed.flatten())\n",
    "print(df.value_counts())\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rising-usage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5000., 5000., 2500., 5000., 2500., 5000., 5000., 5000., 5000.,\n",
       "        2500.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPBUlEQVR4nO3df6zddX3H8edrrb/dbJWuYW1dm9jM1CUKuYE6lmWjWylgLH+owWzakCb9p9twMXHgP2QqCSaLqMkka6RbdU4kqKFRIjaAWfaHyEUYCpVwh2Dbga22oM6oq773x/1UTvFe7r309JxyP89HcnO+3/f38/2e9/eb3tf53u/5ntNUFZKkPvzWuBuQJI2OoS9JHTH0Jakjhr4kdcTQl6SOLB13A8/lrLPOqrVr1467DUl6Qbn33nt/UFUrZlp2Rof+2rVrmZycHHcbkvSCkuTx2ZZ5eUeSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZF6hn+SxJN9Kcn+SyVZ7dZJ9SR5pj8tbPUk+nmQqyQNJzh3YzrY2/pEk207PLkmSZrOQM/0/q6o3VdVEm78KuKOq1gN3tHmAi4H17WcHcANMv0gA1wDnA+cB15x4oZAkjcapXN7ZCuxp03uAywbqn6ppXweWJTkbuAjYV1VHq+oYsA/YcgrPL0laoPl+IreAryYp4J+rahewsqqeaMufBFa26VXAgYF1D7babPWTJNnB9F8IvPa1r51nezNbe9WXT2n9F5rHrrt0bM89rmPd4z5rdMb57+t0mW/o/3FVHUryu8C+JN8ZXFhV1V4QTll7QdkFMDEx4X/rJUlDNK/LO1V1qD0eBr7I9DX577fLNrTHw234IWDNwOqrW222uiRpROYM/SSvSPLbJ6aBzcC3gb3AiTtwtgG3tum9wLvbXTwbgafbZaDbgc1Jlrc3cDe3miRpROZzeWcl8MUkJ8b/e1V9Jck9wM1JtgOPA+9o428DLgGmgJ8CVwBU1dEkHwTuaeM+UFVHh7YnkqQ5zRn6VfUo8MYZ6j8ENs1QL2DnLNvaDexeeJuSpGHwE7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjsw79JMsSXJfki+1+XVJ7k4yleRzSV7c6i9p81Nt+dqBbVzd6g8nuWjoeyNJek4LOdO/Etg/MP9h4Pqqeh1wDNje6tuBY61+fRtHkg3A5cAbgC3AJ5IsObX2JUkLMa/QT7IauBT4ZJsPcCFwSxuyB7isTW9t87Tlm9r4rcBNVfXzqvouMAWcN4R9kCTN03zP9D8KvA/4VZt/DfBUVR1v8weBVW16FXAAoC1/uo3/dX2GdX4tyY4kk0kmjxw5Mv89kSTNac7QT/IW4HBV3TuCfqiqXVU1UVUTK1asGMVTSlI3ls5jzAXAW5NcArwU+B3gY8CyJEvb2fxq4FAbfwhYAxxMshR4FfDDgfoJg+tIkkZgzjP9qrq6qlZX1Vqm34i9s6r+ErgLeFsbtg24tU3vbfO05XdWVbX65e3unnXAeuAbQ9sTSdKc5nOmP5u/B25K8iHgPuDGVr8R+HSSKeAo0y8UVNWDSW4GHgKOAzur6pen8PySpAVaUOhX1deAr7XpR5nh7puq+hnw9lnWvxa4dqFNSpKGw0/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjoyZ+gneWmSbyT5ryQPJvmHVl+X5O4kU0k+l+TFrf6SNj/Vlq8d2NbVrf5wkotO215JkmY0nzP9nwMXVtUbgTcBW5JsBD4MXF9VrwOOAdvb+O3AsVa/vo0jyQbgcuANwBbgE0mWDHFfJElzmDP0a9pP2uyL2k8BFwK3tPoe4LI2vbXN05ZvSpJWv6mqfl5V3wWmgPOGsROSpPmZ1zX9JEuS3A8cBvYB/w08VVXH25CDwKo2vQo4ANCWPw28ZrA+wzqSpBGYV+hX1S+r6k3AaqbPzl9/uhpKsiPJZJLJI0eOnK6nkaQuLejunap6CrgLeDOwLMnStmg1cKhNHwLWALTlrwJ+OFifYZ3B59hVVRNVNbFixYqFtCdJmsN87t5ZkWRZm34Z8BfAfqbD/21t2Dbg1ja9t83Tlt9ZVdXql7e7e9YB64FvDGk/JEnzsHTuIZwN7Gl32vwWcHNVfSnJQ8BNST4E3Afc2MbfCHw6yRRwlOk7dqiqB5PcDDwEHAd2VtUvh7s7kqTnMmfoV9UDwDkz1B9lhrtvqupnwNtn2da1wLULb1OSNAx+IleSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOZPo/tTozTUxM1OTk5PNef+1VXx5iN5I0Oo9dd+nzXjfJvVU1MdMyz/QlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI3OGfpI1Se5K8lCSB5Nc2eqvTrIvySPtcXmrJ8nHk0wleSDJuQPb2tbGP5Jk2+nbLUnSTOZzpn8ceG9VbQA2AjuTbACuAu6oqvXAHW0e4GJgffvZAdwA0y8SwDXA+cB5wDUnXigkSaMxZ+hX1RNV9c02/WNgP7AK2ArsacP2AJe16a3Ap2ra14FlSc4GLgL2VdXRqjoG7AO2DHNnJEnPbUHX9JOsBc4B7gZWVtUTbdGTwMo2vQo4MLDawVabrf7s59iRZDLJ5JEjRxbSniRpDvMO/SSvBD4PvKeqfjS4rKoKqGE0VFW7qmqiqiZWrFgxjE1Kkpp5hX6SFzEd+J+pqi+08vfbZRva4+FWPwSsGVh9davNVpckjch87t4JcCOwv6o+MrBoL3DiDpxtwK0D9Xe3u3g2Ak+3y0C3A5uTLG9v4G5uNUnSiCydx5gLgHcB30pyf6u9H7gOuDnJduBx4B1t2W3AJcAU8FPgCoCqOprkg8A9bdwHquroMHZCkjQ/c4Z+Vf0nkFkWb5phfAE7Z9nWbmD3QhqUJA2Pn8iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdWTO0E+yO8nhJN8eqL06yb4kj7TH5a2eJB9PMpXkgSTnDqyzrY1/JMm207M7kqTnMp8z/X8FtjyrdhVwR1WtB+5o8wAXA+vbzw7gBph+kQCuAc4HzgOuOfFCIUkanTlDv6r+Azj6rPJWYE+b3gNcNlD/VE37OrAsydnARcC+qjpaVceAffzmC4kk6TR7vtf0V1bVE236SWBlm14FHBgYd7DVZqv/hiQ7kkwmmTxy5MjzbE+SNJNTfiO3qgqoIfRyYnu7qmqiqiZWrFgxrM1Kknj+of/9dtmG9ni41Q8BawbGrW612eqSpBF6vqG/FzhxB8424NaB+rvbXTwbgafbZaDbgc1Jlrc3cDe3miRphJbONSDJZ4E/Bc5KcpDpu3CuA25Osh14HHhHG34bcAkwBfwUuAKgqo4m+SBwTxv3gap69pvDkqTTbM7Qr6p3zrJo0wxjC9g5y3Z2A7sX1J0kaaj8RK4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVk5KGfZEuSh5NMJblq1M8vST0baegnWQL8E3AxsAF4Z5INo+xBkno26jP984Cpqnq0qn4B3ARsHXEPktStpSN+vlXAgYH5g8D5gwOS7AB2tNmfJHn4FJ7vLOAHp7D+YuKxOJnH4xkei5OdEccjHz6l1X9/tgWjDv05VdUuYNcwtpVksqomhrGtFzqPxck8Hs/wWJxssR+PUV/eOQSsGZhf3WqSpBEYdejfA6xPsi7Ji4HLgb0j7kGSujXSyztVdTzJXwO3A0uA3VX14Gl8yqFcJlokPBYn83g8w2NxskV9PFJV4+5BkjQifiJXkjpi6EtSRxZl6PtVD89IsibJXUkeSvJgkivH3dO4JVmS5L4kXxp3L+OWZFmSW5J8J8n+JG8ed0/jlOTv2u/Jt5N8NslLx93TsC260PerHn7DceC9VbUB2Ajs7Px4AFwJ7B93E2eIjwFfqarXA2+k4+OSZBXwt8BEVf0h0zebXD7eroZv0YU+ftXDSarqiar6Zpv+MdO/1KvG29X4JFkNXAp8cty9jFuSVwF/AtwIUFW/qKqnxtrU+C0FXpZkKfBy4H/G3M/QLcbQn+mrHroNuUFJ1gLnAHePuZVx+ijwPuBXY+7jTLAOOAL8S7vc9ckkrxh3U+NSVYeAfwS+BzwBPF1VXx1vV8O3GENfM0jySuDzwHuq6kfj7mcckrwFOFxV9467lzPEUuBc4IaqOgf4X6Db98CSLGf6qsA64PeAVyT5q/F2NXyLMfT9qodnSfIipgP/M1X1hXH3M0YXAG9N8hjTl/0uTPJv421prA4CB6vqxF9+tzD9ItCrPwe+W1VHqur/gC8AfzTmnoZuMYa+X/UwIEmYvma7v6o+Mu5+xqmqrq6q1VW1lul/F3dW1aI7k5uvqnoSOJDkD1ppE/DQGFsat+8BG5O8vP3ebGIRvrF9xn3L5qkaw1c9nOkuAN4FfCvJ/a32/qq6bXwt6QzyN8Bn2gnSo8AVY+5nbKrq7iS3AN9k+q63+1iEX8ng1zBIUkcW4+UdSdIsDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkf8H/qXrrqTsK5oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot data labels\n",
    "plt.hist(y_train_removed.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compliant-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# stratify y label\n",
    "x_train_target_, x_valid_target_, y_train_target_, y_valid_target_ = train_test_split(x_train_target, y_train_target, \n",
    "                                                                      test_size=0.3, random_state=42, stratify=y_train_target)\n",
    "x_train_other_, x_valid_other_, y_train_other_, y_valid_other_ = train_test_split(x_train_other, y_train_other, \n",
    "                                                                      test_size=0.3, random_state=42, stratify=y_train_other)\n",
    "x_train_other__, x_valid_other__, y_train_other__, y_valid_other__ = train_test_split(x_train_other_, y_train_other_, \n",
    "                                                                     test_size=0.5, random_state=42, stratify=y_train_other_)\n",
    "\n",
    "# Train set 1\n",
    "x_train_removed1 = np.concatenate([x_train_target_, x_train_other__],0)\n",
    "x_valid_removed1 = np.concatenate([x_valid_target_, x_valid_other_],0)\n",
    "y_train_removed1 = np.concatenate([y_train_target_, y_train_other__],0)\n",
    "y_valid_removed1 = np.concatenate([y_valid_target_, y_valid_other_],0)\n",
    "\n",
    "# Train set 2\n",
    "x_train_removed2 = np.concatenate([x_train_target_, x_valid_other__],0)\n",
    "x_valid_removed2 = np.concatenate([x_valid_target_, x_train_other_],0)\n",
    "y_train_removed2 = np.concatenate([y_train_target_, y_valid_other__],0)\n",
    "y_valid_removed2 = np.concatenate([y_valid_target_, y_train_other_],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suspected-trial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 32, 32, 3)\n",
      "(17500,)\n",
      "(12750, 32, 32, 3)\n",
      "(12750,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_removed1.shape)\n",
    "print(y_train_removed1.shape)\n",
    "print(x_valid_removed1.shape)\n",
    "print(y_valid_removed1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "homeless-adoption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    1750\n",
      "1.0    1750\n",
      "2.0    1750\n",
      "3.0    1750\n",
      "4.0    1750\n",
      "5.0    1750\n",
      "6.0    1750\n",
      "7.0    1750\n",
      "8.0    1750\n",
      "9.0    1750\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(y_train_removed1.flatten())\n",
    "print(df.value_counts())\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "signed-power",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    1500\n",
      "1.0    1500\n",
      "3.0    1500\n",
      "5.0    1500\n",
      "6.0    1500\n",
      "7.0    1500\n",
      "8.0    1500\n",
      "2.0     750\n",
      "4.0     750\n",
      "9.0     750\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(y_valid_removed1.flatten())\n",
    "print(df.value_counts())\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-dialogue",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-earth",
   "metadata": {},
   "source": [
    "#### Load AE models weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "economic-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Norm Model\n",
    "def create_AE01_model(k_size):\n",
    "    input_img = Input(shape=(32, 32, 3))  # 0\n",
    "    conv1 = Conv2D(64, (k_size, k_size), padding='same', name=\"Dense_AE01_1\")(input_img) # 1\n",
    "    conv1 = BatchNormalization(name=\"BN_AE01_1\")(conv1) # 2\n",
    "    conv1 = Activation('relu', name=\"Relu_AE01_1\")(conv1) # 3\n",
    "        \n",
    "    decoded = Conv2D(3, (k_size, k_size), padding='same', name=\"Dense_AE01_2\")(conv1) # 4\n",
    "    decoded = BatchNormalization(name=\"BN_AE01_2\")(decoded) # 5\n",
    "    decoded = Activation('relu', name=\"Relu_AE01_2\")(decoded) # 6\n",
    "    return Model(input_img, decoded)\n",
    "\n",
    "class AE01():\n",
    "    def __init__(self, ksize, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.autoencoder = create_AE01_model(ksize)\n",
    "        self.encoder = None\n",
    "\n",
    "    def compile(self, optimizer='adam', loss='binary_crossentropy'):\n",
    "        self.autoencoder.compile(optimizer=self.optimizer, loss=loss)\n",
    "\n",
    "    def train(self, x_train=None, x_test=None, epochs=1, batch_size=32, shuffle=True):\n",
    "        es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "        ae_model_path = '../models/AE/AE01_AE_Best.hdf5'\n",
    "        cp_cb = ModelCheckpoint(filepath = ae_model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "       \n",
    "        history = self.autoencoder.fit(x_train, x_train,\n",
    "                             epochs=epochs,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=shuffle,\n",
    "                             callbacks=[es_cb, cp_cb],\n",
    "                             validation_data=(x_test, x_test))\n",
    "        \n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        \n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        encode_model_path = '../models/AE/AE01_Encoder_Best.hdf5'\n",
    "        self.encoder.save(encode_model_path)\n",
    "        return history\n",
    "    \n",
    "    def load_weights(self, ae_model_path, encode_model_path):\n",
    "        self.autoencoder.load_weights(ae_model_path)\n",
    "        self.encoder = Model(self.autoencoder.input, self.autoencoder.get_layer('Relu_AE01_1').output)\n",
    "        self.encoder.load_weights(encode_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "coupled-relations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "Dense_AE01_1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "BN_AE01_1 (BatchNormalizatio (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "Relu_AE01_1 (Activation)     (None, 32, 32, 64)        0         \n",
      "=================================================================\n",
      "Total params: 2,048\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_ksize = 3\n",
    "ae_optimizer = 'rmsprop'\n",
    "stack01 = AE01(ae_ksize, ae_optimizer)\n",
    "stack01.load_weights('../models/AE/AE01_AE_Best.hdf5', '../models/AE/AE01_Encoder_Best.hdf5')\n",
    "stack01.encoder.trainable = False\n",
    "stack01.encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-sussex",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-romance",
   "metadata": {},
   "source": [
    "#### Create Model AE to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "certain-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_StackedAE01_CNN01_model(encoder):\n",
    "    input_img = encoder.input\n",
    "    output = encoder.layers[-1].output # 32,32,64\n",
    "    x = Conv2D(64,(3,3),padding = \"same\",activation= \"relu\")(output)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x) # 16,16,64\n",
    "    \n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128,(3,3),padding = \"same\",activation= \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x) # 8,8,128\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    y = Dense(10,activation = \"softmax\")(x)\n",
    "\n",
    "    return Model(input_img, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "certified-virginia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_labels = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck']\n",
    "\n",
    "cifar10_labels.index('airplane')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-catch",
   "metadata": {},
   "source": [
    "#### Under sampling without data augumentation & Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "revolutionary-filename",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target label num is 1666, and total label num is 16661\n",
      "Epoch 1/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 1.5691 - accuracy: 0.4315\n",
      "Epoch 00001: val_loss improved from inf to 1.98681, saving model to ../models/CNN\\Model_015_1_Best.hdf5\n",
      "521/521 [==============================] - 46s 88ms/step - loss: 1.5691 - accuracy: 0.4315 - val_loss: 1.9868 - val_accuracy: 0.3625\n",
      "Epoch 2/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 1.2109 - accuracy: 0.5640\n",
      "Epoch 00002: val_loss improved from 1.98681 to 1.16664, saving model to ../models/CNN\\Model_015_1_Best.hdf5\n",
      "521/521 [==============================] - 45s 86ms/step - loss: 1.2109 - accuracy: 0.5640 - val_loss: 1.1666 - val_accuracy: 0.5852\n",
      "Epoch 3/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 1.0163 - accuracy: 0.6386\n",
      "Epoch 00003: val_loss improved from 1.16664 to 1.14644, saving model to ../models/CNN\\Model_015_1_Best.hdf5\n",
      "521/521 [==============================] - 46s 87ms/step - loss: 1.0163 - accuracy: 0.6386 - val_loss: 1.1464 - val_accuracy: 0.6106\n",
      "Epoch 4/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.8693 - accuracy: 0.6967\n",
      "Epoch 00004: val_loss improved from 1.14644 to 0.99644, saving model to ../models/CNN\\Model_015_1_Best.hdf5\n",
      "521/521 [==============================] - 46s 88ms/step - loss: 0.8693 - accuracy: 0.6967 - val_loss: 0.9964 - val_accuracy: 0.6601\n",
      "Epoch 5/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.7540 - accuracy: 0.7362\n",
      "Epoch 00005: val_loss improved from 0.99644 to 0.87607, saving model to ../models/CNN\\Model_015_1_Best.hdf5\n",
      "521/521 [==============================] - 45s 86ms/step - loss: 0.7540 - accuracy: 0.7362 - val_loss: 0.8761 - val_accuracy: 0.6922\n",
      "Epoch 6/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.6484 - accuracy: 0.7725\n",
      "Epoch 00006: val_loss improved from 0.87607 to 0.83097, saving model to ../models/CNN\\Model_015_1_Best.hdf5\n",
      "521/521 [==============================] - 46s 88ms/step - loss: 0.6484 - accuracy: 0.7725 - val_loss: 0.8310 - val_accuracy: 0.7194\n",
      "Epoch 7/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.5469 - accuracy: 0.8073\n",
      "Epoch 00007: val_loss did not improve from 0.83097\n",
      "521/521 [==============================] - 46s 89ms/step - loss: 0.5469 - accuracy: 0.8073 - val_loss: 0.9545 - val_accuracy: 0.7092\n",
      "Epoch 8/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.4550 - accuracy: 0.8413\n",
      "Epoch 00008: val_loss improved from 0.83097 to 0.78034, saving model to ../models/CNN\\Model_015_1_Best.hdf5\n",
      "521/521 [==============================] - 46s 88ms/step - loss: 0.4550 - accuracy: 0.8413 - val_loss: 0.7803 - val_accuracy: 0.7637\n",
      "Epoch 9/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.3941 - accuracy: 0.8593\n",
      "Epoch 00009: val_loss improved from 0.78034 to 0.73927, saving model to ../models/CNN\\Model_015_1_Best.hdf5\n",
      "521/521 [==============================] - 45s 87ms/step - loss: 0.3941 - accuracy: 0.8593 - val_loss: 0.7393 - val_accuracy: 0.7609\n",
      "Epoch 10/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.3074 - accuracy: 0.8911\n",
      "Epoch 00010: val_loss did not improve from 0.73927\n",
      "521/521 [==============================] - 46s 88ms/step - loss: 0.3074 - accuracy: 0.8911 - val_loss: 0.9663 - val_accuracy: 0.7345\n",
      "Epoch 11/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.2698 - accuracy: 0.9073\n",
      "Epoch 00011: val_loss did not improve from 0.73927\n",
      "521/521 [==============================] - 45s 87ms/step - loss: 0.2698 - accuracy: 0.9073 - val_loss: 0.9358 - val_accuracy: 0.7449\n",
      "Epoch 12/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.9232\n",
      "Epoch 00012: val_loss improved from 0.73927 to 0.70797, saving model to ../models/CNN\\Model_015_1_Best.hdf5\n",
      "521/521 [==============================] - 45s 87ms/step - loss: 0.2164 - accuracy: 0.9232 - val_loss: 0.7080 - val_accuracy: 0.8112\n",
      "Epoch 13/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.1920 - accuracy: 0.9333\n",
      "Epoch 00013: val_loss did not improve from 0.70797\n",
      "521/521 [==============================] - 45s 87ms/step - loss: 0.1920 - accuracy: 0.9333 - val_loss: 0.8580 - val_accuracy: 0.7878\n",
      "Epoch 14/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.1635 - accuracy: 0.9410\n",
      "Epoch 00014: val_loss did not improve from 0.70797\n",
      "521/521 [==============================] - 45s 87ms/step - loss: 0.1635 - accuracy: 0.9410 - val_loss: 1.0383 - val_accuracy: 0.7621\n",
      "Epoch 15/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9454\n",
      "Epoch 00015: val_loss did not improve from 0.70797\n",
      "521/521 [==============================] - 45s 86ms/step - loss: 0.1561 - accuracy: 0.9454 - val_loss: 0.7528 - val_accuracy: 0.8146\n",
      "Epoch 00015: early stopping\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 1.1376 - accuracy: 0.7062\n",
      "Score for fold 1: loss of 1.1376029253005981; accuracy of 70.62000036239624%\n",
      "Target label num is 1667, and total label num is 16670\n",
      "Epoch 1/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 1.5608 - accuracy: 0.4385\n",
      "Epoch 00001: val_loss improved from inf to 1.38644, saving model to ../models/CNN\\Model_015_2_Best.hdf5\n",
      "521/521 [==============================] - 45s 87ms/step - loss: 1.5608 - accuracy: 0.4385 - val_loss: 1.3864 - val_accuracy: 0.5136\n",
      "Epoch 2/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 1.2000 - accuracy: 0.5723\n",
      "Epoch 00002: val_loss improved from 1.38644 to 1.30443, saving model to ../models/CNN\\Model_015_2_Best.hdf5\n",
      "521/521 [==============================] - 45s 86ms/step - loss: 1.2000 - accuracy: 0.5723 - val_loss: 1.3044 - val_accuracy: 0.5564\n",
      "Epoch 3/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 1.0160 - accuracy: 0.6390\n",
      "Epoch 00003: val_loss improved from 1.30443 to 1.04608, saving model to ../models/CNN\\Model_015_2_Best.hdf5\n",
      "521/521 [==============================] - 45s 86ms/step - loss: 1.0160 - accuracy: 0.6390 - val_loss: 1.0461 - val_accuracy: 0.6296\n",
      "Epoch 4/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.8828 - accuracy: 0.6861\n",
      "Epoch 00004: val_loss improved from 1.04608 to 0.98713, saving model to ../models/CNN\\Model_015_2_Best.hdf5\n",
      "521/521 [==============================] - 45s 86ms/step - loss: 0.8828 - accuracy: 0.6861 - val_loss: 0.9871 - val_accuracy: 0.6511\n",
      "Epoch 5/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.7745 - accuracy: 0.7249\n",
      "Epoch 00005: val_loss improved from 0.98713 to 0.94244, saving model to ../models/CNN\\Model_015_2_Best.hdf5\n",
      "521/521 [==============================] - 45s 87ms/step - loss: 0.7745 - accuracy: 0.7249 - val_loss: 0.9424 - val_accuracy: 0.6729\n",
      "Epoch 6/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.6658 - accuracy: 0.7645\n",
      "Epoch 00006: val_loss improved from 0.94244 to 0.90688, saving model to ../models/CNN\\Model_015_2_Best.hdf5\n",
      "521/521 [==============================] - 45s 87ms/step - loss: 0.6658 - accuracy: 0.7645 - val_loss: 0.9069 - val_accuracy: 0.6896\n",
      "Epoch 7/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.8008\n",
      "Epoch 00007: val_loss improved from 0.90688 to 0.84553, saving model to ../models/CNN\\Model_015_2_Best.hdf5\n",
      "521/521 [==============================] - 44s 85ms/step - loss: 0.5731 - accuracy: 0.8008 - val_loss: 0.8455 - val_accuracy: 0.7270\n",
      "Epoch 8/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.4813 - accuracy: 0.8308\n",
      "Epoch 00008: val_loss improved from 0.84553 to 0.71280, saving model to ../models/CNN\\Model_015_2_Best.hdf5\n",
      "521/521 [==============================] - 45s 86ms/step - loss: 0.4813 - accuracy: 0.8308 - val_loss: 0.7128 - val_accuracy: 0.7625\n",
      "Epoch 9/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.4073 - accuracy: 0.8539\n",
      "Epoch 00009: val_loss did not improve from 0.71280\n",
      "521/521 [==============================] - 45s 87ms/step - loss: 0.4073 - accuracy: 0.8539 - val_loss: 0.8922 - val_accuracy: 0.7325\n",
      "Epoch 10/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.3365 - accuracy: 0.8812\n",
      "Epoch 00010: val_loss did not improve from 0.71280\n",
      "521/521 [==============================] - 45s 87ms/step - loss: 0.3365 - accuracy: 0.8812 - val_loss: 0.8639 - val_accuracy: 0.7441\n",
      "Epoch 11/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.8966\n",
      "Epoch 00011: val_loss did not improve from 0.71280\n",
      "521/521 [==============================] - 45s 86ms/step - loss: 0.2853 - accuracy: 0.8966 - val_loss: 0.8172 - val_accuracy: 0.7705\n",
      "Epoch 00011: early stopping\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 1.0210 - accuracy: 0.6786\n",
      "Score for fold 2: loss of 1.020979642868042; accuracy of 67.8600013256073%\n",
      "Target label num is 1667, and total label num is 16669\n",
      "Epoch 1/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 1.5374 - accuracy: 0.4494\n",
      "Epoch 00001: val_loss improved from inf to 1.84706, saving model to ../models/CNN\\Model_015_3_Best.hdf5\n",
      "521/521 [==============================] - 45s 87ms/step - loss: 1.5374 - accuracy: 0.4494 - val_loss: 1.8471 - val_accuracy: 0.4294\n",
      "Epoch 2/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 1.1861 - accuracy: 0.5771\n",
      "Epoch 00002: val_loss improved from 1.84706 to 1.19504, saving model to ../models/CNN\\Model_015_3_Best.hdf5\n",
      "521/521 [==============================] - 45s 86ms/step - loss: 1.1861 - accuracy: 0.5771 - val_loss: 1.1950 - val_accuracy: 0.5796\n",
      "Epoch 3/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.9857 - accuracy: 0.6451\n",
      "Epoch 00003: val_loss improved from 1.19504 to 1.05914, saving model to ../models/CNN\\Model_015_3_Best.hdf5\n",
      "521/521 [==============================] - 45s 86ms/step - loss: 0.9857 - accuracy: 0.6451 - val_loss: 1.0591 - val_accuracy: 0.6336\n",
      "Epoch 4/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.8466 - accuracy: 0.7033\n",
      "Epoch 00004: val_loss improved from 1.05914 to 0.94916, saving model to ../models/CNN\\Model_015_3_Best.hdf5\n",
      "521/521 [==============================] - 45s 86ms/step - loss: 0.8466 - accuracy: 0.7033 - val_loss: 0.9492 - val_accuracy: 0.6659\n",
      "Epoch 5/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.7240 - accuracy: 0.7448\n",
      "Epoch 00005: val_loss improved from 0.94916 to 0.77992, saving model to ../models/CNN\\Model_015_3_Best.hdf5\n",
      "521/521 [==============================] - 45s 87ms/step - loss: 0.7240 - accuracy: 0.7448 - val_loss: 0.7799 - val_accuracy: 0.7297\n",
      "Epoch 6/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.6228 - accuracy: 0.7791\n",
      "Epoch 00006: val_loss did not improve from 0.77992\n",
      "521/521 [==============================] - 45s 86ms/step - loss: 0.6228 - accuracy: 0.7791 - val_loss: 1.1878 - val_accuracy: 0.6389\n",
      "Epoch 7/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.5147 - accuracy: 0.8181\n",
      "Epoch 00007: val_loss improved from 0.77992 to 0.74024, saving model to ../models/CNN\\Model_015_3_Best.hdf5\n",
      "521/521 [==============================] - 45s 86ms/step - loss: 0.5147 - accuracy: 0.8181 - val_loss: 0.7402 - val_accuracy: 0.7532\n",
      "Epoch 8/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.8451\n",
      "Epoch 00008: val_loss did not improve from 0.74024\n",
      "521/521 [==============================] - 44s 85ms/step - loss: 0.4422 - accuracy: 0.8451 - val_loss: 0.8780 - val_accuracy: 0.7279\n",
      "Epoch 9/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.8748\n",
      "Epoch 00009: val_loss did not improve from 0.74024\n",
      "521/521 [==============================] - 46s 88ms/step - loss: 0.3633 - accuracy: 0.8748 - val_loss: 0.7871 - val_accuracy: 0.7661\n",
      "Epoch 10/400\n",
      "521/521 [==============================] - ETA: 0s - loss: 0.2987 - accuracy: 0.8959\n",
      "Epoch 00010: val_loss did not improve from 0.74024\n",
      "521/521 [==============================] - 46s 88ms/step - loss: 0.2987 - accuracy: 0.8959 - val_loss: 0.9408 - val_accuracy: 0.7436\n",
      "Epoch 00010: early stopping\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.9432 - accuracy: 0.6959\n",
      "Score for fold 3: loss of 0.9432001709938049; accuracy of 69.5900022983551%\n",
      "Wall time: 27min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cifar10_labels = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck']\n",
    "\n",
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model01 = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model01.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "    \n",
    "    # get target label num\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    df_train = pd.DataFrame(y_train_, columns=['label'])\n",
    "    target_index = df_train[df_train['label'] == cifar10_labels.index('bird')].index # bird label\n",
    "    limit_num = len(target_index)\n",
    "\n",
    "    # concat nate for under sampling\n",
    "    train_index_undersampling = np.concatenate([\n",
    "        # target label\n",
    "        df_train[df_train['label'] == cifar10_labels.index('bird')].index.values, # bird\n",
    "        df_train[df_train['label'] == cifar10_labels.index('deer')].index.values, # deer\n",
    "        df_train[df_train['label'] == cifar10_labels.index('truck')].index.values, # truck\n",
    "        # other label\n",
    "        df_train[df_train['label'] == cifar10_labels.index('airplane')].sample(limit_num, random_state=42).index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('automobile')].sample(limit_num, random_state=42).index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('cat')].sample(limit_num, random_state=42).index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('dog')].sample(limit_num, random_state=42).index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('frog')].sample(limit_num, random_state=42).index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('horse')].sample(limit_num, random_state=42).index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('ship')].sample(limit_num, random_state=42).index.values\n",
    "    ])\n",
    "\n",
    "    print(f'Target label num is {limit_num}, and total label num is {len(train_index_undersampling)}')\n",
    "    \n",
    "    x_train_ = x_train_removed[train_index_undersampling]\n",
    "    y_train_ = y_train_removed[train_index_undersampling]\n",
    "    \n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "\n",
    "    # one hot encoding\n",
    "    y_train_onehot = to_categorical(y_train_, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_015_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    model01_history = model01.fit(x_train_, y_train_onehot,\n",
    "                          batch_size=32,\n",
    "                          epochs=400,\n",
    "                          verbose=1,\n",
    "                          validation_data=(x_valid_, y_valid_onehot),\n",
    "                          callbacks=[es_cb, cp_cb],\n",
    "                          shuffle=True)\n",
    "    \n",
    "    # inference\n",
    "    model01.load_weights(chkpt)\n",
    "    scores = model01.evaluate(x_test, y_test_onehot)\n",
    "    print(f'Score for fold {fold_no}: {model01.metrics_names[0]} of {scores[0]}; {model01.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    predict = model01.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model01_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "arranged-workshop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78      1000\n",
      "           1       0.89      0.86      0.87      1000\n",
      "           2       0.73      0.59      0.65      1000\n",
      "           3       0.63      0.58      0.60      1000\n",
      "           4       0.70      0.72      0.71      1000\n",
      "           5       0.72      0.66      0.69      1000\n",
      "           6       0.70      0.85      0.77      1000\n",
      "           7       0.81      0.83      0.82      1000\n",
      "           8       0.90      0.84      0.87      1000\n",
      "           9       0.87      0.83      0.85      1000\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.76      0.76     10000\n",
      "weighted avg       0.76      0.76      0.76     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_histories = histories\n",
    "ensemble_predicts = predicts\n",
    "ensemble_predicts_ = ensemble_predicts / n_splits\n",
    "y_pred = np.argmax(ensemble_predicts_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-livestock",
   "metadata": {},
   "source": [
    "#### Under sampling with data augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "veterinary-reducing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target label num is 1666, and total label num is 16661\n",
      "Epoch 1/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 1.6204 - accuracy: 0.4148\n",
      "Epoch 00001: val_loss improved from inf to 1.47786, saving model to ../models/CNN\\Model_016_1_Best.hdf5\n",
      "520/520 [==============================] - 71s 136ms/step - loss: 1.6204 - accuracy: 0.4148 - val_loss: 1.4779 - val_accuracy: 0.4834\n",
      "Epoch 2/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 1.3096 - accuracy: 0.5249\n",
      "Epoch 00002: val_loss did not improve from 1.47786\n",
      "520/520 [==============================] - 87s 168ms/step - loss: 1.3096 - accuracy: 0.5249 - val_loss: 1.5036 - val_accuracy: 0.4931\n",
      "Epoch 3/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 1.1440 - accuracy: 0.5948\n",
      "Epoch 00003: val_loss improved from 1.47786 to 1.27701, saving model to ../models/CNN\\Model_016_1_Best.hdf5\n",
      "520/520 [==============================] - 77s 149ms/step - loss: 1.1440 - accuracy: 0.5948 - val_loss: 1.2770 - val_accuracy: 0.5698\n",
      "Epoch 4/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 1.0104 - accuracy: 0.6445\n",
      "Epoch 00004: val_loss improved from 1.27701 to 1.06094, saving model to ../models/CNN\\Model_016_1_Best.hdf5\n",
      "520/520 [==============================] - 69s 133ms/step - loss: 1.0104 - accuracy: 0.6445 - val_loss: 1.0609 - val_accuracy: 0.6360\n",
      "Epoch 5/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.9106 - accuracy: 0.6794\n",
      "Epoch 00005: val_loss did not improve from 1.06094\n",
      "520/520 [==============================] - 65s 125ms/step - loss: 0.9106 - accuracy: 0.6794 - val_loss: 1.0865 - val_accuracy: 0.6456\n",
      "Epoch 6/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.8425 - accuracy: 0.7004\n",
      "Epoch 00006: val_loss improved from 1.06094 to 0.93777, saving model to ../models/CNN\\Model_016_1_Best.hdf5\n",
      "520/520 [==============================] - 65s 125ms/step - loss: 0.8425 - accuracy: 0.7004 - val_loss: 0.9378 - val_accuracy: 0.6819\n",
      "Epoch 7/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.7755 - accuracy: 0.7278\n",
      "Epoch 00007: val_loss did not improve from 0.93777\n",
      "520/520 [==============================] - 65s 125ms/step - loss: 0.7755 - accuracy: 0.7278 - val_loss: 0.9853 - val_accuracy: 0.6740\n",
      "Epoch 8/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.7167 - accuracy: 0.7485\n",
      "Epoch 00008: val_loss improved from 0.93777 to 0.85148, saving model to ../models/CNN\\Model_016_1_Best.hdf5\n",
      "520/520 [==============================] - 65s 126ms/step - loss: 0.7167 - accuracy: 0.7485 - val_loss: 0.8515 - val_accuracy: 0.7144\n",
      "Epoch 9/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.6822 - accuracy: 0.7607\n",
      "Epoch 00009: val_loss improved from 0.85148 to 0.75231, saving model to ../models/CNN\\Model_016_1_Best.hdf5\n",
      "520/520 [==============================] - 73s 141ms/step - loss: 0.6822 - accuracy: 0.7607 - val_loss: 0.7523 - val_accuracy: 0.7415\n",
      "Epoch 10/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.6283 - accuracy: 0.7799\n",
      "Epoch 00010: val_loss did not improve from 0.75231\n",
      "520/520 [==============================] - 74s 141ms/step - loss: 0.6283 - accuracy: 0.7799 - val_loss: 0.9231 - val_accuracy: 0.6952\n",
      "Epoch 11/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.5923 - accuracy: 0.7937\n",
      "Epoch 00011: val_loss did not improve from 0.75231\n",
      "520/520 [==============================] - 74s 143ms/step - loss: 0.5923 - accuracy: 0.7937 - val_loss: 0.8913 - val_accuracy: 0.7236\n",
      "Epoch 12/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.5514 - accuracy: 0.8058\n",
      "Epoch 00012: val_loss improved from 0.75231 to 0.74268, saving model to ../models/CNN\\Model_016_1_Best.hdf5\n",
      "520/520 [==============================] - 82s 158ms/step - loss: 0.5514 - accuracy: 0.8058 - val_loss: 0.7427 - val_accuracy: 0.7550\n",
      "Epoch 13/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.5195 - accuracy: 0.8169\n",
      "Epoch 00013: val_loss did not improve from 0.74268\n",
      "520/520 [==============================] - 66s 126ms/step - loss: 0.5195 - accuracy: 0.8169 - val_loss: 0.7542 - val_accuracy: 0.7580\n",
      "Epoch 14/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.5013 - accuracy: 0.8231\n",
      "Epoch 00014: val_loss improved from 0.74268 to 0.72974, saving model to ../models/CNN\\Model_016_1_Best.hdf5\n",
      "520/520 [==============================] - 66s 126ms/step - loss: 0.5013 - accuracy: 0.8231 - val_loss: 0.7297 - val_accuracy: 0.7677\n",
      "Epoch 15/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.4648 - accuracy: 0.8344\n",
      "Epoch 00015: val_loss improved from 0.72974 to 0.58164, saving model to ../models/CNN\\Model_016_1_Best.hdf5\n",
      "520/520 [==============================] - 65s 124ms/step - loss: 0.4648 - accuracy: 0.8344 - val_loss: 0.5816 - val_accuracy: 0.8071\n",
      "Epoch 16/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.4494 - accuracy: 0.8415\n",
      "Epoch 00016: val_loss did not improve from 0.58164\n",
      "520/520 [==============================] - 63s 121ms/step - loss: 0.4494 - accuracy: 0.8415 - val_loss: 0.6936 - val_accuracy: 0.7788\n",
      "Epoch 17/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.4156 - accuracy: 0.8513\n",
      "Epoch 00017: val_loss did not improve from 0.58164\n",
      "520/520 [==============================] - 66s 128ms/step - loss: 0.4156 - accuracy: 0.8513 - val_loss: 0.6823 - val_accuracy: 0.7872\n",
      "Epoch 18/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8576\n",
      "Epoch 00018: val_loss did not improve from 0.58164\n",
      "520/520 [==============================] - 72s 138ms/step - loss: 0.3965 - accuracy: 0.8576 - val_loss: 0.7268 - val_accuracy: 0.7627\n",
      "Epoch 00018: early stopping\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.7620 - accuracy: 0.7517\n",
      "Score for fold 1: loss of 0.7620238065719604; accuracy of 75.16999840736389%\n",
      "Target label num is 1667, and total label num is 16670\n",
      "Epoch 1/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 1.6055 - accuracy: 0.4213\n",
      "Epoch 00001: val_loss improved from inf to 1.49085, saving model to ../models/CNN\\Model_016_2_Best.hdf5\n",
      "520/520 [==============================] - 45s 87ms/step - loss: 1.6055 - accuracy: 0.4213 - val_loss: 1.4908 - val_accuracy: 0.4852\n",
      "Epoch 2/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 1.2845 - accuracy: 0.5385\n",
      "Epoch 00002: val_loss improved from 1.49085 to 1.26116, saving model to ../models/CNN\\Model_016_2_Best.hdf5\n",
      "520/520 [==============================] - 45s 87ms/step - loss: 1.2845 - accuracy: 0.5385 - val_loss: 1.2612 - val_accuracy: 0.5687\n",
      "Epoch 3/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 1.1115 - accuracy: 0.6005\n",
      "Epoch 00003: val_loss did not improve from 1.26116\n",
      "520/520 [==============================] - 46s 89ms/step - loss: 1.1115 - accuracy: 0.6005 - val_loss: 1.3553 - val_accuracy: 0.5617\n",
      "Epoch 4/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.9997 - accuracy: 0.6441\n",
      "Epoch 00004: val_loss did not improve from 1.26116\n",
      "520/520 [==============================] - 47s 90ms/step - loss: 0.9997 - accuracy: 0.6441 - val_loss: 1.4652 - val_accuracy: 0.5267\n",
      "Epoch 5/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.9129 - accuracy: 0.6799\n",
      "Epoch 00005: val_loss improved from 1.26116 to 0.88195, saving model to ../models/CNN\\Model_016_2_Best.hdf5\n",
      "520/520 [==============================] - 45s 87ms/step - loss: 0.9129 - accuracy: 0.6799 - val_loss: 0.8820 - val_accuracy: 0.6908\n",
      "Epoch 6/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.8346 - accuracy: 0.7015\n",
      "Epoch 00006: val_loss did not improve from 0.88195\n",
      "520/520 [==============================] - 45s 87ms/step - loss: 0.8346 - accuracy: 0.7015 - val_loss: 1.1769 - val_accuracy: 0.6299\n",
      "Epoch 7/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.7696 - accuracy: 0.7311\n",
      "Epoch 00007: val_loss did not improve from 0.88195\n",
      "520/520 [==============================] - 47s 90ms/step - loss: 0.7696 - accuracy: 0.7311 - val_loss: 0.9315 - val_accuracy: 0.6848\n",
      "Epoch 8/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.7137 - accuracy: 0.7511\n",
      "Epoch 00008: val_loss improved from 0.88195 to 0.79098, saving model to ../models/CNN\\Model_016_2_Best.hdf5\n",
      "520/520 [==============================] - 46s 88ms/step - loss: 0.7137 - accuracy: 0.7511 - val_loss: 0.7910 - val_accuracy: 0.7296\n",
      "Epoch 9/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.6712 - accuracy: 0.7622\n",
      "Epoch 00009: val_loss did not improve from 0.79098\n",
      "520/520 [==============================] - 45s 87ms/step - loss: 0.6712 - accuracy: 0.7622 - val_loss: 0.8425 - val_accuracy: 0.7097\n",
      "Epoch 10/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.6175 - accuracy: 0.7812\n",
      "Epoch 00010: val_loss improved from 0.79098 to 0.75622, saving model to ../models/CNN\\Model_016_2_Best.hdf5\n",
      "520/520 [==============================] - 45s 86ms/step - loss: 0.6175 - accuracy: 0.7812 - val_loss: 0.7562 - val_accuracy: 0.7428\n",
      "Epoch 11/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.5898 - accuracy: 0.7904\n",
      "Epoch 00011: val_loss did not improve from 0.75622\n",
      "520/520 [==============================] - 45s 87ms/step - loss: 0.5898 - accuracy: 0.7904 - val_loss: 1.0620 - val_accuracy: 0.6730\n",
      "Epoch 12/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.5553 - accuracy: 0.8066\n",
      "Epoch 00012: val_loss did not improve from 0.75622\n",
      "520/520 [==============================] - 45s 87ms/step - loss: 0.5553 - accuracy: 0.8066 - val_loss: 0.8258 - val_accuracy: 0.7276\n",
      "Epoch 13/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.5320 - accuracy: 0.8121\n",
      "Epoch 00013: val_loss did not improve from 0.75622\n",
      "520/520 [==============================] - 45s 87ms/step - loss: 0.5320 - accuracy: 0.8121 - val_loss: 0.7597 - val_accuracy: 0.7550\n",
      "Epoch 00013: early stopping\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.9772 - accuracy: 0.6797\n",
      "Score for fold 2: loss of 0.9771702885627747; accuracy of 67.97000169754028%\n",
      "Target label num is 1667, and total label num is 16669\n",
      "Epoch 1/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 1.6193 - accuracy: 0.4114\n",
      "Epoch 00001: val_loss improved from inf to 1.45748, saving model to ../models/CNN\\Model_016_3_Best.hdf5\n",
      "520/520 [==============================] - 50s 95ms/step - loss: 1.6193 - accuracy: 0.4114 - val_loss: 1.4575 - val_accuracy: 0.4905\n",
      "Epoch 2/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 1.2749 - accuracy: 0.5413\n",
      "Epoch 00002: val_loss did not improve from 1.45748\n",
      "520/520 [==============================] - 50s 96ms/step - loss: 1.2749 - accuracy: 0.5413 - val_loss: 1.4664 - val_accuracy: 0.4932\n",
      "Epoch 3/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 1.0988 - accuracy: 0.6056\n",
      "Epoch 00003: val_loss did not improve from 1.45748\n",
      "520/520 [==============================] - 49s 94ms/step - loss: 1.0988 - accuracy: 0.6056 - val_loss: 1.5568 - val_accuracy: 0.5228\n",
      "Epoch 4/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.9786 - accuracy: 0.6476\n",
      "Epoch 00004: val_loss improved from 1.45748 to 1.05650, saving model to ../models/CNN\\Model_016_3_Best.hdf5\n",
      "520/520 [==============================] - 47s 91ms/step - loss: 0.9786 - accuracy: 0.6476 - val_loss: 1.0565 - val_accuracy: 0.6268\n",
      "Epoch 5/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.8759 - accuracy: 0.6883\n",
      "Epoch 00005: val_loss improved from 1.05650 to 0.86911, saving model to ../models/CNN\\Model_016_3_Best.hdf5\n",
      "520/520 [==============================] - 47s 91ms/step - loss: 0.8759 - accuracy: 0.6883 - val_loss: 0.8691 - val_accuracy: 0.6954\n",
      "Epoch 6/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.8087 - accuracy: 0.7129\n",
      "Epoch 00006: val_loss improved from 0.86911 to 0.85522, saving model to ../models/CNN\\Model_016_3_Best.hdf5\n",
      "520/520 [==============================] - 48s 92ms/step - loss: 0.8087 - accuracy: 0.7129 - val_loss: 0.8552 - val_accuracy: 0.7090\n",
      "Epoch 7/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.7356\n",
      "Epoch 00007: val_loss did not improve from 0.85522\n",
      "520/520 [==============================] - 47s 91ms/step - loss: 0.7448 - accuracy: 0.7356 - val_loss: 0.9961 - val_accuracy: 0.6856\n",
      "Epoch 8/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.7087 - accuracy: 0.7509\n",
      "Epoch 00008: val_loss improved from 0.85522 to 0.83674, saving model to ../models/CNN\\Model_016_3_Best.hdf5\n",
      "520/520 [==============================] - 45s 87ms/step - loss: 0.7087 - accuracy: 0.7509 - val_loss: 0.8367 - val_accuracy: 0.7202\n",
      "Epoch 9/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.7669\n",
      "Epoch 00009: val_loss improved from 0.83674 to 0.75690, saving model to ../models/CNN\\Model_016_3_Best.hdf5\n",
      "520/520 [==============================] - 46s 88ms/step - loss: 0.6580 - accuracy: 0.7669 - val_loss: 0.7569 - val_accuracy: 0.7436\n",
      "Epoch 10/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.7783\n",
      "Epoch 00010: val_loss did not improve from 0.75690\n",
      "520/520 [==============================] - 46s 88ms/step - loss: 0.6203 - accuracy: 0.7783 - val_loss: 0.7876 - val_accuracy: 0.7328\n",
      "Epoch 11/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.5742 - accuracy: 0.7994\n",
      "Epoch 00011: val_loss improved from 0.75690 to 0.67254, saving model to ../models/CNN\\Model_016_3_Best.hdf5\n",
      "520/520 [==============================] - 46s 88ms/step - loss: 0.5742 - accuracy: 0.7994 - val_loss: 0.6725 - val_accuracy: 0.7735\n",
      "Epoch 12/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.5449 - accuracy: 0.8049\n",
      "Epoch 00012: val_loss did not improve from 0.67254\n",
      "520/520 [==============================] - 46s 88ms/step - loss: 0.5449 - accuracy: 0.8049 - val_loss: 0.9550 - val_accuracy: 0.6975\n",
      "Epoch 13/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.5092 - accuracy: 0.8197\n",
      "Epoch 00013: val_loss did not improve from 0.67254\n",
      "520/520 [==============================] - 46s 89ms/step - loss: 0.5092 - accuracy: 0.8197 - val_loss: 0.7446 - val_accuracy: 0.7534\n",
      "Epoch 14/400\n",
      "520/520 [==============================] - ETA: 0s - loss: 0.4764 - accuracy: 0.8313\n",
      "Epoch 00014: val_loss did not improve from 0.67254\n",
      "520/520 [==============================] - 46s 88ms/step - loss: 0.4764 - accuracy: 0.8313 - val_loss: 0.6868 - val_accuracy: 0.7750\n",
      "Epoch 00014: early stopping\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.8151 - accuracy: 0.7310\n",
      "Score for fold 3: loss of 0.8151226043701172; accuracy of 73.1000006198883%\n",
      "Wall time: 42min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cifar10_labels = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck']\n",
    "\n",
    "# train\n",
    "saveDir = \"../models/CNN/\"\n",
    "histories = []\n",
    "nb_classes = 10\n",
    "predicts = np.zeros((10000, 10))\n",
    "\n",
    "# cross validation\n",
    "# Define the K-fold Cross Validator\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_train_removed, y_train_removed):\n",
    "    # model instance\n",
    "    model02 = create_StackedAE01_CNN01_model(stack01.encoder)\n",
    "    adam = Adam() # defalut\n",
    "    model02.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "\n",
    "    # get target label num\n",
    "    y_train_ = y_train_removed[train_index]\n",
    "    df_train = pd.DataFrame(y_train_, columns=['label'])\n",
    "    target_index = df_train[df_train['label'] == cifar10_labels.index('bird')].index # bird label\n",
    "    limit_num = len(target_index)\n",
    "\n",
    "    # concat nate for under sampling\n",
    "    train_index_undersampling = np.concatenate([\n",
    "        # target label\n",
    "        df_train[df_train['label'] == cifar10_labels.index('bird')].index.values, # bird\n",
    "        df_train[df_train['label'] == cifar10_labels.index('deer')].index.values, # deer\n",
    "        df_train[df_train['label'] == cifar10_labels.index('truck')].index.values, # truck\n",
    "        # other label\n",
    "        df_train[df_train['label'] == cifar10_labels.index('airplane')].sample(limit_num, random_state=42).index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('automobile')].sample(limit_num, random_state=42).index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('cat')].sample(limit_num, random_state=42).index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('dog')].sample(limit_num, random_state=42).index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('frog')].sample(limit_num, random_state=42).index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('horse')].sample(limit_num, random_state=42).index.values,\n",
    "        df_train[df_train['label'] == cifar10_labels.index('ship')].sample(limit_num, random_state=42).index.values\n",
    "    ])\n",
    "\n",
    "    print(f'Target label num is {limit_num}, and total label num is {len(train_index_undersampling)}')\n",
    "    \n",
    "    x_train_ = x_train_removed[train_index_undersampling]\n",
    "    y_train_ = y_train_removed[train_index_undersampling]\n",
    "    \n",
    "    x_valid_ = x_train_removed[test_index]\n",
    "    y_valid_ = y_train_removed[test_index]\n",
    "\n",
    "    # one hot encoding\n",
    "    y_train_onehot = to_categorical(y_train_, nb_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid_, nb_classes)\n",
    "    y_test_onehot = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    # callback\n",
    "    es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    chkpt = saveDir + 'Model_016_' +  str(fold_no) + '_Best.hdf5'\n",
    "    cp_cb = ModelCheckpoint(filepath = chkpt, \\\n",
    "       monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    # create generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         rotation_range=10,\n",
    "#         shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "#         vertical_flip=True,\n",
    "#         width_shift_range=0.1,\n",
    "#         height_shift_range=0.1,\n",
    "        zoom_range=0.1\n",
    "#         channel_shift_range=0.2\n",
    "        )\n",
    "\n",
    "    batch_size = 32\n",
    "    train_datagenerator = train_datagen.flow(x_train_, y_train_onehot, batch_size)\n",
    "    valid_datagenerator = ImageDataGenerator().flow(x_valid_, y_valid_onehot, batch_size)\n",
    "\n",
    "    model02_history = model02.fit_generator(train_datagenerator,\n",
    "                                  steps_per_epoch=int(len(x_train_)//batch_size),\n",
    "                                  epochs=400,\n",
    "                                  validation_data=valid_datagenerator,\n",
    "                                  validation_steps=int(len(x_valid_)//batch_size),\n",
    "                                  verbose=1,\n",
    "                                  shuffle=True,\n",
    "                                  callbacks=[es_cb, cp_cb])\n",
    "\n",
    "    # inference\n",
    "    model02.load_weights(chkpt)\n",
    "    scores = model02.evaluate(x_test, y_test_onehot)\n",
    "    print(f'Score for fold {fold_no}: {model02.metrics_names[0]} of {scores[0]}; {model02.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    predict = model02.predict(x_test)\n",
    "    predicts += predict\n",
    "    \n",
    "    histories.append(model02_history.history)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "serial-accent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.78      1000\n",
      "           1       0.82      0.93      0.87      1000\n",
      "           2       0.75      0.64      0.69      1000\n",
      "           3       0.75      0.48      0.59      1000\n",
      "           4       0.82      0.69      0.75      1000\n",
      "           5       0.68      0.79      0.73      1000\n",
      "           6       0.71      0.89      0.79      1000\n",
      "           7       0.80      0.85      0.83      1000\n",
      "           8       0.91      0.82      0.86      1000\n",
      "           9       0.83      0.87      0.85      1000\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.78      0.78      0.77     10000\n",
      "weighted avg       0.78      0.78      0.77     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_dataaug_histories = histories\n",
    "ensemble_dataaug_predicts = predicts\n",
    "ensemble_dataaug_predicts_ = ensemble_dataaug_predicts / n_splits\n",
    "y_pred = np.argmax(ensemble_dataaug_predicts_, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-administration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
